{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#  mplfinance Date iLoc Transform\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows multiple outputs from a single jupyter notebook cell:\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.7a18'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mplfinance as mpf\n",
    "mpf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/SP500_NOV2019_Hist.csv',index_col=0,parse_dates=True)\n",
    "df = pd.read_csv('../data/yahoofinance-SPY-20200901-20210113.csv',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uses for DateIlocTransform\n",
    "\n",
    "#### All uses are for `show_nontrading=False` only:\n",
    "\n",
    "- `.to_date()` &nbsp; location *to* date: &nbsp; for tick label formatting.\n",
    "- `.to_iloc()` &nbsp; date *to* location: &nbsp; for `xticks` placement.\n",
    "- `.to_iloc()` &nbsp; date *to* location: &nbsp; for `xlim` placement.\n",
    "- `.to_iloc()` &nbsp; date *to* location: &nbsp; for `lines` placement.\n",
    "\n",
    "---\n",
    "\n",
    "- It seems to me that  \n",
    "  - **interpolation** may be better using the actual datetime series (rather than the linear formula), whereas \n",
    "  - **extrapolation** *will require* the linear formula.\n",
    "    - Or for \"known\" cases may be able to use **date calculations**, for example:\n",
    "      - quartile(0.65) == quartile(0.50) == quartile(0.35) == \"known\" frequency.\n",
    "      - intraday with consistent trading hours in data\n",
    "      - daily with weekends missing (maybe someday allow users to supply holidays)\n",
    "      - weekly, monthly, yearly, etc. are simple?\n",
    "  - need to run some tests to see which, if either, is better.\n",
    "- Keep in mind, while testing, that `xlim` values will affect `xticks` placement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesFrequency:\n",
    "\n",
    "    def __init__(self,dfreq='B',ifreq='H',weekmask=None,open_time='09:30',close_time='16:00'):\n",
    "        self._dfreq  = dfreq\n",
    "        self._ifreq  = ifreq\n",
    "        self._wmask  = weekmask\n",
    "        self._topen  = pd.Timestamp(open_time)\n",
    "        self._tclose = pd.Timestamp(close_time)\n",
    "\n",
    "    def __repr__(self):\n",
    "        s  = self.__class__.__name__\n",
    "        s += \"(d='\"+str(self._dfreq)+\"'\"\n",
    "        s += \", i='\"+str(self._ifreq)+\"'\"\n",
    "        s += \", w='\"+str(self._wmask)+\"'\"\n",
    "        s += \", o='\"+str(self._topen.strftime('%H:%M:%S'))+\"'\"\n",
    "        s += \", c='\"+str(self._tclose.strftime('%H:%M:%S'))+\"'\"\n",
    "        s += \")\"\n",
    "        return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _timedelta_to_freqabbr(td):\n",
    "    if not isinstance(td,pd.Timedelta): return None\n",
    "    hours   = int(round(td.seconds/(60*60)))\n",
    "    minutes = int(round(td.seconds%(60*60)/60))\n",
    "    seconds = int(round(td.seconds%60))\n",
    "    if td.microseconds/1000 >= 500:\n",
    "        seconds += 1.\n",
    "    # If only one of hours, minutes, or seconds is\n",
    "    # non-zero, then we can use an abbreviation.\n",
    "    if minutes == seconds == 0:\n",
    "        freq = str(hours)+'H'\n",
    "    elif hours == seconds == 0:\n",
    "        freq = str(minutes)+'T'\n",
    "    elif hours == minutes == 0:\n",
    "        freq = str(seconds)+'S'\n",
    "    else:\n",
    "        freq = None\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _infer_weekmask(ix):\n",
    "    weekdaydf = pd.DataFrame(dict(date=ix,dayofweek=[d.dayofweek for d in ix]))\n",
    "    weekdays  = weekdaydf.groupby('dayofweek').count()\n",
    "    c = weekdays.columns[0]\n",
    "    cutoff = 0.25 * weekdays[c].max()\n",
    "    days = weekdays[ weekdays[c] > cutoff].index.values\n",
    "    #print('days=',days)\n",
    "    weekmask = [day in days for day in range(7)]\n",
    "    print('weekmask=',weekmask)\n",
    "    return weekmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _infer_frequency(data,trace=False):\n",
    "    '''\n",
    "    Infer the frequency of a pandas.DatetimeIndex\n",
    "    even if that DatetimeIndex contains some gaps.\n",
    "    \n",
    "    Args:\n",
    "        data:  DataFrame with a DatetimeIndex, or\n",
    "               Series with a DatetimeIndex, or\n",
    "               DatetimeIndex\n",
    "\n",
    "    Returns:\n",
    "        freq:  Inferred frequency of type `class TimeSeriesFrequency`\n",
    "    '''\n",
    "    if isinstance(data,(pd.core.frame.DataFrame,pd.core.frame.DataFrame)):\n",
    "        if not isinstance(data.index,pd.core.indexes.datetimes.DatetimeIndex):\n",
    "            raise TypeError('DataFrame or Series must have DatetimeIndex to infer frequency')\n",
    "        dts = data.index.to_series()\n",
    "    elif isinstance(data,pd.core.indexes.datetimes.DatetimeIndex):\n",
    "        dts = data.to_series()\n",
    "    else:\n",
    "        raise TypeError('Input must be DataFrame, Series, or DatetimeIndex')\n",
    "        \n",
    "    # At this point `dts` is a datetime series\n",
    "    \n",
    "    if not dts.is_monotonic: dts = dts[::-1]\n",
    "    if not dts.is_monotonic: raise ValueError('data is not monotonic!')\n",
    "    diff = dts.diff(1)\n",
    "    vc = diff.value_counts()\n",
    "    basefreq = vc.idxmax()\n",
    "    ifreq = None\n",
    "    if basefreq.days < 1:\n",
    "        abbr  = _timedelta_to_freqabbr(basefreq)\n",
    "        ifreq = basefreq if abbr is None else abbr\n",
    "        dfreq = 'B'\n",
    "        print(data.iloc[[0,1,2,-3,-2,-1]])\n",
    "    elif basefreq.days == 1:\n",
    "        dfreq = 'B'\n",
    "        # infer weekmask:\n",
    "        mask = _infer_weekmask(dts.index)\n",
    "    elif basefreq.days >= 6 and basefreq.days <= 8:\n",
    "        dfreq = 'W'\n",
    "    elif basefreq.days >= 28 and basefreq.days <= 31:\n",
    "        dfreq = 'M'\n",
    "    elif basefreq.days >=(3*28) and basefreq.days <= (3*31):\n",
    "        dfreq = 'Q'\n",
    "    elif basefreq.days >=(12*28) and basefreq.days <= (12*31):\n",
    "        dfreq = 'Y'\n",
    "    else:\n",
    "        dfreq = None\n",
    "    if trace:\n",
    "        print('\\nvc(value counts)=')\n",
    "        print(vc)\n",
    "        print('dfreq =',dfreq,'\\n')\n",
    "    return TimeSeriesFrequency(ifreq=ifreq,dfreq=dfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.dates as mdates\n",
    "from mplfinance._utils import _date_to_mdate\n",
    "    \n",
    "class DateIlocTransform:\n",
    "    '''Create a transform object that can transform from a Datetime to a DatetimeIndex location, \n",
    "    and/or from index location to Datetime.  Requires a Pandas DatetimeIndex upon creation.\n",
    "    \n",
    "    If `date` does not exactly match a date in the series then interpolate between two dates.\n",
    "    If `date` is outside the range of dates in the series, then extrapolate.\n",
    "    \n",
    "    The are two ways to extrapolate.  The preferred way is to determine the frequency of the\n",
    "    input DatetimeIndex, and extrapolate the DatetimeIndex itself.  Then we treat the extrapolated\n",
    "    DatetimeIndex as if it were the original index and just match or interpolate as needed.\n",
    "    If we cannot determine the frequency of the original DatetimeIndex then we determine, via least\n",
    "    squares fit, a linear relationship between the dates and the index locations, and use that linear\n",
    "    equation to extrapolate.\n",
    "\n",
    "    By default, to save calculation time, we do not extrapolate at all, but simply fail to transform\n",
    "    if the caller requests transformation of data outside the range of the input DatetimeIndex.\n",
    "    Another way to say this is that, by default, the extrapolation limits are set to the limits \n",
    "    (start and end) of the inputted DatetimeIndex.\n",
    "\n",
    "    The user optionally can call `.set_extrapolation_limits()` which will trigger frequency inference\n",
    "    and extrapolation of the DatetimeIndex (or, if the frequency cannot be inferred, trigger the least \n",
    "    squares linear fit described above).  The user can than transform data within the newly specified \n",
    "    extrapolation limits\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,dtindex):\n",
    "        if not isinstance(dtindex,pd.DatetimeIndex):\n",
    "            raise TypeError('Need `pandas.DatetimeIndex`, but got \"'+str(type(dtindex))+'\"')\n",
    "        if not len(dtindex) > 1:\n",
    "            raise ValueError('`dtindex` must have length of at least 2.')\n",
    "        self._inferred_frequency = _infer_frequency(dtindex)\n",
    "        \n",
    "        self._extrapolation_limits = (0,len(dtindex))\n",
    "        \n",
    "        ixlist = np.linspace(0,len(dtindex),len(dtindex)+1)[0:-1]\n",
    "        self._to_iloc_series = pd.Series(ixlist,index=dtindex)\n",
    "        self._to_date_series = pd.Series(dtindex.values,index=ixlist)\n",
    "        #dtseries = dtindex.to_series()\n",
    "        #self._lsslope, self._lsyicpt = self._lsq_linear(dtseries)\n",
    "        #self._epslope, self._epyicpt = self._ep_linear(dtseries)\n",
    "\n",
    "    def to_iloc(self,date):\n",
    "        i1s = self._to_iloc_series.loc[:date]\n",
    "        i1  = i1s[-1] if len(i1s) > 0 else float('nan') # else need to extrapolate\n",
    "        i2s = self._to_iloc_series.loc[date:]\n",
    "        i2  = i2s[ 0] if len(i2s) > 0 else float('nan') # else need to extrapolate\n",
    "        #print('\\ndate,i1,i2=',date,i1,i2)\n",
    "        loc1 = i1\n",
    "        loc2 = i2\n",
    "        d1 = self._to_date_series.iloc[int(round(i1,0))]\n",
    "        d2 = self._to_date_series.iloc[int(round(i2,0))]\n",
    "        #print('date,i1,i2,d1,d2=',date,i1,i2,d1,d2)\n",
    "        # if iloc is between two dates, linearly interpolate between those dates:\n",
    "        loc = ((date-d1)/(d2-d1))*(loc2-loc1) + loc1 if d1 != d2 else loc1\n",
    "        #print('loc1,loc2,loc=',loc1,loc2,loc)\n",
    "        return loc\n",
    "\n",
    "    \n",
    "    def to_datetime(self,iloc):\n",
    "        #self._to_date_series = pd.Series(dtindex.values,index=range(len(dtindex))) \n",
    "        d1s = self._to_date_series.loc[:iloc]\n",
    "        print('len(d1s)=',len(d1s))\n",
    "        d1  = d1s.iloc[-1] if len(d1s) > 0 else float('nan') # else should extrapolate\n",
    "        d2s = self._to_date_series.loc[iloc:]\n",
    "        print('len(d2s)=',len(d2s))\n",
    "        d2  = d2s.iloc[ 0] if len(d2s) > 0 else float('nan') # else should extrapolate\n",
    "        if d1 == d2:\n",
    "            return d1\n",
    "        print('d1,d2=',d1,d2)\n",
    "        loc1 = int(round(self._to_iloc_series.loc[d1],0))\n",
    "        loc2 = int(round(self._to_iloc_series.loc[d2],0))\n",
    "        #print('\\nd1,d2=',d1.date().day,d2.date().day,\n",
    "        #      ' iloc,loc1,loc2=',iloc,loc1,loc2)\n",
    "        #print('\\nd1,d2,(d2-d1),type(d2-d1)=',d1,d2,d2-d1,type(d2-d1))\n",
    "        # d1,d2= 8 11  iloc,loc1,loc2= 5.333333333333333 5 6\n",
    "        # d1,d2,(d2-d1)= 2019-11-08 00:00:00 2019-11-11 00:00:00 3 days 00:00:00\n",
    "        # Timestamp('2019-11-08 23:59:59.999999999')\n",
    "        # d = ((iloc-loc1)/(loc2-loc1))*(d2-d1) + d1\n",
    "        d = ((iloc-loc1)*(d2-d1)) + d1\n",
    "        return d.round('s')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-01</th>\n",
       "      <td>350.209991</td>\n",
       "      <td>352.709991</td>\n",
       "      <td>349.239990</td>\n",
       "      <td>352.600006</td>\n",
       "      <td>349.703522</td>\n",
       "      <td>54999300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-02</th>\n",
       "      <td>354.670013</td>\n",
       "      <td>358.750000</td>\n",
       "      <td>353.429993</td>\n",
       "      <td>357.700012</td>\n",
       "      <td>354.761627</td>\n",
       "      <td>69540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-03</th>\n",
       "      <td>355.869995</td>\n",
       "      <td>356.380005</td>\n",
       "      <td>342.589996</td>\n",
       "      <td>345.390015</td>\n",
       "      <td>342.552765</td>\n",
       "      <td>148011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-04</th>\n",
       "      <td>346.130005</td>\n",
       "      <td>347.829987</td>\n",
       "      <td>334.869995</td>\n",
       "      <td>342.570007</td>\n",
       "      <td>339.755890</td>\n",
       "      <td>139156300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-08</th>\n",
       "      <td>336.709991</td>\n",
       "      <td>342.640015</td>\n",
       "      <td>332.880005</td>\n",
       "      <td>333.209991</td>\n",
       "      <td>330.472778</td>\n",
       "      <td>114465300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2020-09-01  350.209991  352.709991  349.239990  352.600006  349.703522   \n",
       "2020-09-02  354.670013  358.750000  353.429993  357.700012  354.761627   \n",
       "2020-09-03  355.869995  356.380005  342.589996  345.390015  342.552765   \n",
       "2020-09-04  346.130005  347.829987  334.869995  342.570007  339.755890   \n",
       "2020-09-08  336.709991  342.640015  332.880005  333.209991  330.472778   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2020-09-01   54999300  \n",
       "2020-09-02   69540000  \n",
       "2020-09-03  148011100  \n",
       "2020-09-04  139156300  \n",
       "2020-09-08  114465300  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>369.709991</td>\n",
       "      <td>376.980011</td>\n",
       "      <td>369.119995</td>\n",
       "      <td>373.549988</td>\n",
       "      <td>373.549988</td>\n",
       "      <td>107997700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>376.100006</td>\n",
       "      <td>379.899994</td>\n",
       "      <td>375.910004</td>\n",
       "      <td>379.100006</td>\n",
       "      <td>379.100006</td>\n",
       "      <td>68766800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>380.589996</td>\n",
       "      <td>381.489990</td>\n",
       "      <td>377.100006</td>\n",
       "      <td>381.260010</td>\n",
       "      <td>381.260010</td>\n",
       "      <td>71677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-11</th>\n",
       "      <td>377.850006</td>\n",
       "      <td>380.579987</td>\n",
       "      <td>377.720001</td>\n",
       "      <td>378.690002</td>\n",
       "      <td>378.690002</td>\n",
       "      <td>51176700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-12</th>\n",
       "      <td>378.890015</td>\n",
       "      <td>379.859985</td>\n",
       "      <td>376.359985</td>\n",
       "      <td>378.769989</td>\n",
       "      <td>378.769989</td>\n",
       "      <td>52445000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2021-01-06  369.709991  376.980011  369.119995  373.549988  373.549988   \n",
       "2021-01-07  376.100006  379.899994  375.910004  379.100006  379.100006   \n",
       "2021-01-08  380.589996  381.489990  377.100006  381.260010  381.260010   \n",
       "2021-01-11  377.850006  380.579987  377.720001  378.690002  378.690002   \n",
       "2021-01-12  378.890015  379.859985  376.359985  378.769989  378.769989   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2021-01-06  107997700  \n",
       "2021-01-07   68766800  \n",
       "2021-01-08   71677200  \n",
       "2021-01-11   51176700  \n",
       "2021-01-12   52445000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekmask= [True, True, True, True, True, False, False]\n"
     ]
    }
   ],
   "source": [
    "t = DateIlocTransform(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekmask= [True, True, True, True, True, False, False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimeSeriesFrequency(d='B', i='None', w='None', o='09:30:00', c='16:00:00')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = _infer_frequency(df.index)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixtemp = pd.DatetimeIndex([df.index[j] for j in range(0,len(df.index),2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesFrequency(d='None', i='None', w='None', o='09:30:00', c='16:00:00')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = _infer_frequency(ixtemp)\n",
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start= 2020-09-01 00:00:00  end= 2021-01-12 00:00:00\n",
      "bday_freq= B  iday_freq= None  weekmask= None\n",
      "open_time= 2021-05-28 09:30:00  close_time= 2021-05-28 16:00:00\n"
     ]
    }
   ],
   "source": [
    "ixt = time_series_index(start=df.index[0],end=df.index[-1],freq=f)\n",
    "ixt.name = 'Generated'\n",
    "s1 = df.index.to_series()\n",
    "s2 = ixt.to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-07</th>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-26</th>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-11-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-25</th>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-12-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Generated\n",
       "2020-09-07  NaT 2020-09-07\n",
       "2020-11-26  NaT 2020-11-26\n",
       "2020-12-25  NaT 2020-12-25\n",
       "2021-01-01  NaT 2021-01-01"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [DatetimeIndex(['2020-09-07', '2020-11-26', '2020-12-25', '2021-01-01'], dtype='datetime64[ns]', freq=None)] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-428a5f10466e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m select \u001b[38;5;241m=\u001b[39m xdf[xdf\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m      4\u001b[0m select\n\u001b[0;32m----> 5\u001b[0m \u001b[48;5;17ms1\u001b[49m\u001b[48;5;17m[\u001b[49m\u001b[48;5;17mselect\u001b[49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17mindex\u001b[49m\u001b[48;5;17m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#s2[select.index]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m xdf\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    905\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_values(key)\n\u001b[0;32m--> 908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;48;5;17mself\u001b[39;49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17m_get_with\u001b[49m\u001b[48;5;17m(\u001b[49m\u001b[48;5;17mkey\u001b[49m\u001b[48;5;17m)\u001b[49m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[key]\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# handle the dup indexing case GH#4246\u001b[39;00m\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;48;5;17mself\u001b[39;49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17mloc\u001b[49m\u001b[48;5;17m[\u001b[49m\u001b[48;5;17mkey\u001b[49m\u001b[48;5;17m]\u001b[49m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    876\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    878\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 879\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;48;5;17mself\u001b[39;49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17m_getitem_axis\u001b[49m\u001b[48;5;17m(\u001b[49m\u001b[48;5;17mmaybe_callable\u001b[49m\u001b[48;5;17m,\u001b[49m\u001b[48;5;17m \u001b[49m\u001b[48;5;17maxis\u001b[49m\u001b[38;5;241;48;5;17m=\u001b[39;49m\u001b[48;5;17maxis\u001b[49m\u001b[48;5;17m)\u001b[49m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;48;5;17mself\u001b[39;49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17m_getitem_iterable\u001b[49m\u001b[48;5;17m(\u001b[49m\u001b[48;5;17mkey\u001b[49m\u001b[48;5;17m,\u001b[49m\u001b[48;5;17m \u001b[49m\u001b[48;5;17maxis\u001b[49m\u001b[38;5;241;48;5;17m=\u001b[39;49m\u001b[48;5;17maxis\u001b[49m\u001b[48;5;17m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1037\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;48;5;17mself\u001b[39;49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17m_get_listlike_indexer\u001b[49m\u001b[48;5;17m(\u001b[49m\u001b[48;5;17mkey\u001b[49m\u001b[48;5;17m,\u001b[49m\u001b[48;5;17m \u001b[49m\u001b[48;5;17maxis\u001b[49m\u001b[48;5;17m,\u001b[49m\u001b[48;5;17m \u001b[49m\u001b[48;5;17mraise_missing\u001b[49m\u001b[38;5;241;48;5;17m=\u001b[39;49m\u001b[38;5;28;48;5;17;01mFalse\u001b[39;49;00m\u001b[48;5;17m)\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1039\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1252\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 1254\u001b[0m \u001b[38;5;28;48;5;17mself\u001b[39;49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17m_validate_read_indexer\u001b[49m\u001b[48;5;17m(\u001b[49m\u001b[48;5;17mkeyarr\u001b[49m\u001b[48;5;17m,\u001b[49m\u001b[48;5;17m \u001b[49m\u001b[48;5;17mindexer\u001b[49m\u001b[48;5;17m,\u001b[49m\u001b[48;5;17m \u001b[49m\u001b[48;5;17maxis\u001b[49m\u001b[48;5;17m,\u001b[49m\u001b[48;5;17m \u001b[49m\u001b[48;5;17mraise_missing\u001b[49m\u001b[38;5;241;48;5;17m=\u001b[39;49m\u001b[48;5;17mraise_missing\u001b[49m\u001b[48;5;17m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_LocIndexer._validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m   1297\u001b[0m     axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;66;03m# We (temporarily) allow for some missing keys with .loc, except in\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;66;03m# some cases (e.g. setting) in which \"raise_missing\" will be False\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_missing:\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [DatetimeIndex(['2020-09-07', '2020-11-26', '2020-12-25', '2021-01-01'], dtype='datetime64[ns]', freq=None)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "xdf = pd.DataFrame([df.index.to_series(),ixt.to_series()]).T\n",
    "len(xdf)\n",
    "select = xdf[xdf.isna().any(axis=1)]\n",
    "select\n",
    "s1[select.index]\n",
    "#s2[select.index]\n",
    "xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-09-01', '2020-09-02', '2020-09-03', '2020-09-04',\n",
       "               '2020-09-08', '2020-09-09', '2020-09-10', '2020-09-11',\n",
       "               '2020-09-14', '2020-09-15', '2020-09-16', '2020-09-17',\n",
       "               '2020-09-18', '2020-09-21', '2020-09-22', '2020-09-23',\n",
       "               '2020-09-24', '2020-09-25', '2020-09-28', '2020-09-29',\n",
       "               '2020-09-30', '2020-10-01', '2020-10-02', '2020-10-05',\n",
       "               '2020-10-06', '2020-10-07', '2020-10-08', '2020-10-09',\n",
       "               '2020-10-13', '2020-10-14', '2020-10-15', '2020-10-16',\n",
       "               '2020-10-19', '2020-10-20', '2020-10-21', '2020-10-22',\n",
       "               '2020-10-23', '2020-10-26', '2020-10-27', '2020-10-28',\n",
       "               '2020-10-29', '2020-10-30', '2020-11-02', '2020-11-03',\n",
       "               '2020-11-04', '2020-11-05', '2020-11-06', '2020-11-09',\n",
       "               '2020-11-10', '2020-11-12', '2020-11-13', '2020-11-16',\n",
       "               '2020-11-17', '2020-11-18', '2020-11-19', '2020-11-20',\n",
       "               '2020-11-23', '2020-11-24', '2020-11-25', '2020-11-27',\n",
       "               '2020-11-30', '2020-12-01', '2020-12-02', '2020-12-03',\n",
       "               '2020-12-04', '2020-12-07', '2020-12-08', '2020-12-09',\n",
       "               '2020-12-10', '2020-12-11', '2020-12-14', '2020-12-15',\n",
       "               '2020-12-16', '2020-12-17', '2020-12-18', '2020-12-21',\n",
       "               '2020-12-22', '2020-12-23', '2020-12-24', '2020-12-28',\n",
       "               '2020-12-29', '2020-12-30', '2020-12-31', '2021-01-04',\n",
       "               '2021-01-05', '2021-01-06', '2021-01-07', '2021-01-08',\n",
       "               '2021-01-11', '2021-01-12'],\n",
       "              dtype='datetime64[ns]', name='Generated', freq='C')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ixt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Unnamed 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-28</th>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>2020-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-29</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>2020-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-30</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>2020-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-02</th>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>2020-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>2020-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>2020-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>2020-11-05</td>\n",
       "      <td>2020-11-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>2020-11-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>2020-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10</th>\n",
       "      <td>2020-11-10</td>\n",
       "      <td>2020-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-11</th>\n",
       "      <td>2020-11-11</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-12</th>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>2020-11-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-13</th>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>2020-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-16</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>2020-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-17</th>\n",
       "      <td>2020-11-17</td>\n",
       "      <td>2020-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-18</th>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>2020-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19</th>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>2020-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-20</th>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>2020-11-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-23</th>\n",
       "      <td>2020-11-23</td>\n",
       "      <td>2020-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-24</th>\n",
       "      <td>2020-11-24</td>\n",
       "      <td>2020-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-25</th>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>2020-11-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-27</th>\n",
       "      <td>2020-11-27</td>\n",
       "      <td>2020-11-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-30</th>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>2020-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>2020-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-02</th>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>2020-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-03</th>\n",
       "      <td>2020-12-03</td>\n",
       "      <td>2020-12-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-04</th>\n",
       "      <td>2020-12-04</td>\n",
       "      <td>2020-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-07</th>\n",
       "      <td>2020-12-07</td>\n",
       "      <td>2020-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-08</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>2020-12-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-09</th>\n",
       "      <td>2020-12-09</td>\n",
       "      <td>2020-12-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  Unnamed 0\n",
       "2020-10-28 2020-10-28 2020-10-28\n",
       "2020-10-29 2020-10-29 2020-10-29\n",
       "2020-10-30 2020-10-30 2020-10-30\n",
       "2020-11-02 2020-11-02 2020-11-02\n",
       "2020-11-03 2020-11-03 2020-11-03\n",
       "2020-11-04 2020-11-04 2020-11-04\n",
       "2020-11-05 2020-11-05 2020-11-05\n",
       "2020-11-06 2020-11-06 2020-11-06\n",
       "2020-11-09 2020-11-09 2020-11-09\n",
       "2020-11-10 2020-11-10 2020-11-10\n",
       "2020-11-11 2020-11-11        NaT\n",
       "2020-11-12 2020-11-12 2020-11-12\n",
       "2020-11-13 2020-11-13 2020-11-13\n",
       "2020-11-16 2020-11-16 2020-11-16\n",
       "2020-11-17 2020-11-17 2020-11-17\n",
       "2020-11-18 2020-11-18 2020-11-18\n",
       "2020-11-19 2020-11-19 2020-11-19\n",
       "2020-11-20 2020-11-20 2020-11-20\n",
       "2020-11-23 2020-11-23 2020-11-23\n",
       "2020-11-24 2020-11-24 2020-11-24\n",
       "2020-11-25 2020-11-25 2020-11-25\n",
       "2020-11-27 2020-11-27 2020-11-27\n",
       "2020-11-30 2020-11-30 2020-11-30\n",
       "2020-12-01 2020-12-01 2020-12-01\n",
       "2020-12-02 2020-12-02 2020-12-02\n",
       "2020-12-03 2020-12-03 2020-12-03\n",
       "2020-12-04 2020-12-04 2020-12-04\n",
       "2020-12-07 2020-12-07 2020-12-07\n",
       "2020-12-08 2020-12-08 2020-12-08\n",
       "2020-12-09 2020-12-09 2020-12-09"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdf.iloc[40:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesFrequency(d='B', i='None', w='None', o='09:30:00', c='16:00:00')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0   2020-09-01\n",
       "1.0   2020-09-02\n",
       "2.0   2020-09-03\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "89.0   2021-01-08\n",
       "90.0   2021-01-11\n",
       "91.0   2021-01-12\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2020-09-01    0.0\n",
       "2020-09-02    1.0\n",
       "2020-09-03    2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2021-01-08    89.0\n",
       "2021-01-11    90.0\n",
       "2021-01-12    91.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<bound method DateIlocTransform.to_datetime of <__main__.DateIlocTransform object at 0x7f5526550c70>>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<bound method DateIlocTransform.to_iloc of <__main__.DateIlocTransform object at 0x7f5526550c70>>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir(t)\n",
    "t._inferred_frequency\n",
    "t._to_date_series.head(3)\n",
    "t._to_date_series.tail(3)\n",
    "t._to_iloc_series.head(3)\n",
    "t._to_iloc_series.tail(3)\n",
    "t.to_datetime\n",
    "t.to_iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-09-17', '2020-09-18', '2020-09-21', '2020-09-22'], dtype='datetime64[ns]', name='Date', freq=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(d1s)= 13\n",
      "len(d2s)= 80\n",
      "12.0   2020-09-18 00:00:00   12.0\n",
      "len(d1s)= 13\n",
      "len(d2s)= 79\n",
      "d1,d2= 2020-09-18 00:00:00 2020-09-21 00:00:00\n",
      "12.1   2020-09-18 07:12:00   12.1\n",
      "len(d1s)= 13\n",
      "len(d2s)= 79\n",
      "d1,d2= 2020-09-18 00:00:00 2020-09-21 00:00:00\n",
      "12.2   2020-09-18 14:24:00   12.2\n",
      "len(d1s)= 13\n",
      "len(d2s)= 79\n",
      "d1,d2= 2020-09-18 00:00:00 2020-09-21 00:00:00\n",
      "12.3   2020-09-18 21:36:00   12.3\n",
      "len(d1s)= 13\n",
      "len(d2s)= 79\n",
      "d1,d2= 2020-09-18 00:00:00 2020-09-21 00:00:00\n",
      "12.4   2020-09-19 04:48:00   12.4\n",
      "len(d1s)= 13\n",
      "len(d2s)= 79\n",
      "d1,d2= 2020-09-18 00:00:00 2020-09-21 00:00:00\n",
      "12.5   2020-09-19 12:00:00   12.5\n",
      "len(d1s)= 13\n",
      "len(d2s)= 79\n",
      "d1,d2= 2020-09-18 00:00:00 2020-09-21 00:00:00\n",
      "12.6   2020-09-19 19:12:00   12.6\n",
      "len(d1s)= 13\n",
      "len(d2s)= 79\n",
      "d1,d2= 2020-09-18 00:00:00 2020-09-21 00:00:00\n",
      "12.7   2020-09-20 02:24:00   12.7\n",
      "len(d1s)= 13\n",
      "len(d2s)= 79\n",
      "d1,d2= 2020-09-18 00:00:00 2020-09-21 00:00:00\n",
      "12.8   2020-09-20 09:36:00   12.8\n",
      "len(d1s)= 13\n",
      "len(d2s)= 79\n",
      "d1,d2= 2020-09-18 00:00:00 2020-09-21 00:00:00\n",
      "12.9   2020-09-20 16:48:00   12.9\n",
      "len(d1s)= 13\n",
      "len(d2s)= 79\n",
      "d1,d2= 2020-09-18 00:00:00 2020-09-21 00:00:00\n",
      "13.0   2020-09-21 00:00:00   13.0\n",
      "len(d1s)= 14\n",
      "len(d2s)= 78\n",
      "d1,d2= 2020-09-21 00:00:00 2020-09-22 00:00:00\n",
      "13.1   2020-09-21 02:24:00   13.1\n",
      "len(d1s)= 14\n",
      "len(d2s)= 78\n",
      "d1,d2= 2020-09-21 00:00:00 2020-09-22 00:00:00\n",
      "13.2   2020-09-21 04:48:00   13.2\n",
      "len(d1s)= 14\n",
      "len(d2s)= 78\n",
      "d1,d2= 2020-09-21 00:00:00 2020-09-22 00:00:00\n",
      "13.3   2020-09-21 07:12:00   13.3\n",
      "len(d1s)= 14\n",
      "len(d2s)= 78\n",
      "d1,d2= 2020-09-21 00:00:00 2020-09-22 00:00:00\n",
      "13.4   2020-09-21 09:36:00   13.4\n",
      "len(d1s)= 14\n",
      "len(d2s)= 78\n",
      "d1,d2= 2020-09-21 00:00:00 2020-09-22 00:00:00\n",
      "13.5   2020-09-21 12:00:00   13.5\n",
      "len(d1s)= 14\n",
      "len(d2s)= 78\n",
      "d1,d2= 2020-09-21 00:00:00 2020-09-22 00:00:00\n",
      "13.6   2020-09-21 14:24:00   13.6\n",
      "len(d1s)= 14\n",
      "len(d2s)= 78\n",
      "d1,d2= 2020-09-21 00:00:00 2020-09-22 00:00:00\n",
      "13.7   2020-09-21 16:48:00   13.7\n",
      "len(d1s)= 14\n",
      "len(d2s)= 78\n",
      "d1,d2= 2020-09-21 00:00:00 2020-09-22 00:00:00\n",
      "13.8   2020-09-21 19:12:00   13.8\n",
      "len(d1s)= 14\n",
      "len(d2s)= 78\n",
      "d1,d2= 2020-09-21 00:00:00 2020-09-22 00:00:00\n",
      "13.9   2020-09-21 21:36:00   13.9\n"
     ]
    }
   ],
   "source": [
    "df.index[11:15]\n",
    "for ix in np.arange(12,14,0.1):\n",
    "    d = t.to_datetime(ix)\n",
    "    print(\"%3.1f   %s   %3.1f\" % (ix,d,t.to_iloc(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2021-01-07', '2021-01-08', '2021-01-11'], dtype='datetime64[ns]', name='Date', freq=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(d1s)= 91\n",
      "len(d2s)= 1\n",
      "d1,d2= 2021-01-11 00:00:00 2021-01-12 00:00:00\n",
      "90.5   2021-01-11 12:00:00\n",
      "90.5   2021-01-11 12:00:00   90.5\n",
      "len(d1s)= 91\n",
      "len(d2s)= 1\n",
      "d1,d2= 2021-01-11 00:00:00 2021-01-12 00:00:00\n",
      "90.6   2021-01-11 14:24:00\n",
      "90.6   2021-01-11 14:24:00   90.6\n",
      "len(d1s)= 91\n",
      "len(d2s)= 1\n",
      "d1,d2= 2021-01-11 00:00:00 2021-01-12 00:00:00\n",
      "90.7   2021-01-11 16:48:00\n",
      "90.7   2021-01-11 16:48:00   90.7\n",
      "len(d1s)= 91\n",
      "len(d2s)= 1\n",
      "d1,d2= 2021-01-11 00:00:00 2021-01-12 00:00:00\n",
      "90.8   2021-01-11 19:12:00\n",
      "90.8   2021-01-11 19:12:00   90.8\n",
      "len(d1s)= 91\n",
      "len(d2s)= 1\n",
      "d1,d2= 2021-01-11 00:00:00 2021-01-12 00:00:00\n",
      "90.9   2021-01-11 21:36:00\n",
      "90.9   2021-01-11 21:36:00   90.9\n",
      "len(d1s)= 91\n",
      "len(d2s)= 1\n",
      "d1,d2= 2021-01-11 00:00:00 2021-01-12 00:00:00\n",
      "91.0   2021-01-12 00:00:00\n",
      "91.0   2021-01-12 00:00:00   91.0\n",
      "len(d1s)= 92\n",
      "len(d2s)= 0\n",
      "d1,d2= 2021-01-12 00:00:00 nan\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: -9223372036854775808",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;48;5;17mself\u001b[39;49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17m_engine\u001b[49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17mget_loc\u001b[49m\u001b[48;5;17m(\u001b[49m\u001b[48;5;17mcasted_key\u001b[49m\u001b[48;5;17m)\u001b[49m\n\u001b[1;32m   2892\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: NaT",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[48;5;17mIndex\u001b[49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17mget_loc\u001b[49m\u001b[48;5;17m(\u001b[49m\u001b[38;5;28;48;5;17mself\u001b[39;49m\u001b[48;5;17m,\u001b[49m\u001b[48;5;17m \u001b[49m\u001b[48;5;17mkey\u001b[49m\u001b[48;5;17m,\u001b[49m\u001b[48;5;17m \u001b[49m\u001b[48;5;17mmethod\u001b[49m\u001b[48;5;17m,\u001b[49m\u001b[48;5;17m \u001b[49m\u001b[48;5;17mtolerance\u001b[49m\u001b[48;5;17m)\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2892\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 2893\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   2895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tolerance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: NaT",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-4f85a8571649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m df\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ix \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m90.5\u001b[39m,\u001b[38;5;241m93\u001b[39m,\u001b[38;5;241m0.1\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[48;5;17mt\u001b[49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17mto_datetime\u001b[49m\u001b[48;5;17m(\u001b[49m\u001b[48;5;17mix\u001b[49m\u001b[48;5;17m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%3.1f\u001b[39;00m\u001b[38;5;124m   \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (ix,d))\n\u001b[1;32m      5\u001b[0m     ixchk \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mto_iloc(d)\n",
      "\u001b[0;32m<ipython-input-50-c1953ac06281>\u001b[0m in \u001b[0;36mDateIlocTransform.to_datetime\u001b[0;34m(self, iloc)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md1,d2=\u001b[39m\u001b[38;5;124m'\u001b[39m,d1,d2)\n\u001b[1;32m     73\u001b[0m loc1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_iloc_series\u001b[38;5;241m.\u001b[39mloc[d1],\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 74\u001b[0m loc2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28;48;5;17mself\u001b[39;49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17m_to_iloc_series\u001b[49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17mloc\u001b[49m\u001b[48;5;17m[\u001b[49m\u001b[48;5;17md2\u001b[49m\u001b[48;5;17m]\u001b[49m,\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m#print('\\nd1,d2=',d1.date().day,d2.date().day,\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m#      ' iloc,loc1,loc2=',iloc,loc1,loc2)\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m#print('\\nd1,d2,(d2-d1),type(d2-d1)=',d1,d2,d2-d1,type(d2-d1))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Timestamp('2019-11-08 23:59:59.999999999')\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# d = ((iloc-loc1)/(loc2-loc1))*(d2-d1) + d1\u001b[39;00m\n\u001b[1;32m     82\u001b[0m d \u001b[38;5;241m=\u001b[39m ((iloc\u001b[38;5;241m-\u001b[39mloc1)\u001b[38;5;241m*\u001b[39m(d2\u001b[38;5;241m-\u001b[39md1)) \u001b[38;5;241m+\u001b[39m d1\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    876\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    878\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 879\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;48;5;17mself\u001b[39;49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17m_getitem_axis\u001b[49m\u001b[48;5;17m(\u001b[49m\u001b[48;5;17mmaybe_callable\u001b[49m\u001b[48;5;17m,\u001b[49m\u001b[48;5;17m \u001b[49m\u001b[48;5;17maxis\u001b[49m\u001b[38;5;241;48;5;17m=\u001b[39;49m\u001b[48;5;17maxis\u001b[49m\u001b[48;5;17m)\u001b[49m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;48;5;17mself\u001b[39;49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17m_get_label\u001b[49m\u001b[48;5;17m(\u001b[49m\u001b[48;5;17mkey\u001b[49m\u001b[48;5;17m,\u001b[49m\u001b[48;5;17m \u001b[49m\u001b[48;5;17maxis\u001b[49m\u001b[38;5;241;48;5;17m=\u001b[39;49m\u001b[48;5;17maxis\u001b[49m\u001b[48;5;17m)\u001b[49m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;66;03m# GH#5667 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1059\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;48;5;17mself\u001b[39;49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17mobj\u001b[49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17mxs\u001b[49m\u001b[48;5;17m(\u001b[49m\u001b[48;5;17mlabel\u001b[49m\u001b[48;5;17m,\u001b[49m\u001b[48;5;17m \u001b[49m\u001b[48;5;17maxis\u001b[49m\u001b[38;5;241;48;5;17m=\u001b[39;49m\u001b[48;5;17maxis\u001b[49m\u001b[48;5;17m)\u001b[49m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3486\u001b[0m     loc, new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc_level(key, drop_level\u001b[38;5;241m=\u001b[39mdrop_level)\n\u001b[1;32m   3487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3488\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;48;5;17mself\u001b[39;49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17mindex\u001b[49m\u001b[38;5;241;48;5;17m.\u001b[39;49m\u001b[48;5;17mget_loc\u001b[49m\u001b[48;5;17m(\u001b[49m\u001b[48;5;17mkey\u001b[49m\u001b[48;5;17m)\u001b[49m\n\u001b[1;32m   3490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   3491\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Index\u001b[38;5;241m.\u001b[39mget_loc(\u001b[38;5;28mself\u001b[39m, key, method, tolerance)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(orig_key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: nan"
     ]
    }
   ],
   "source": [
    "df.index[-4:-1]\n",
    "for ix in np.arange(90.5,93,0.1):\n",
    "    d = t.to_datetime(ix)\n",
    "    print(\"%3.1f   %s\" % (ix,d))\n",
    "    ixchk = t.to_iloc(d)\n",
    "    print(\"%3.1f   %s   %3.1f\" % (ix,d,ixchk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filelist = glob.glob('../data/*.csv')\n",
    "for fn in filelist:\n",
    "    df = pd.read_csv(fn,index_col=0,parse_dates=True)\n",
    "    f = infer_frequency(df)\n",
    "    print(f,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn ='../data/yahoofinance-INTC-19950101-20040412.csv'\n",
    "fn='../data/gbpusd_yf20210401-0407.csv'\n",
    "#fn='../data/SP500_20191106_IDayBollinger.csv'\n",
    "#fn = '../data/jpyusd_barchartdotcom.csv'\n",
    "df = pd.read_csv(fn,index_col=0,parse_dates=True)\n",
    "infer_frequency(df[::-1],trace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdict = {'Open'  :'first',\n",
    "           'High'  :'max',\n",
    "           'Low'   :'min',\n",
    "           'Close' :'last',\n",
    "           'Volume':'sum'\n",
    "          }\n",
    "fn ='../data/yahoofinance-INTC-19950101-20040412.csv'\n",
    "df = pd.read_csv(fn,index_col=0,parse_dates=True)\n",
    "\n",
    "\n",
    "for rs in ['1D','2D','3D','4D','5D','6D','7D','8D','9D','1W','2W','1M','2M','3M','4M','1Q','1Y']:\n",
    "    f = infer_frequency(df.resample(rs).agg(aggdict))\n",
    "    print('rs=',rs,'  f=',f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_index(start=None,end=None,freq=TimeSeriesFrequency()):\n",
    "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "    if not isinstance(freq,TimeSeriesFrequency):\n",
    "        raise TypeError('`freq` must be of type TimeSeriesFrequency')\n",
    "    if start is None: start = pd.Timestamp.today()\n",
    "    if end   is None: end   = start + pd.Timedelta(days=1)\n",
    "\n",
    "    bday_freq  = freq._dfreq\n",
    "    iday_freq  = freq._ifreq\n",
    "    weekmask   = freq._wmask\n",
    "    open_time  = freq._topen\n",
    "    close_time = freq._tclose\n",
    "\n",
    "    print('start=',start,' end=',end)\n",
    "    print('bday_freq=',bday_freq,' iday_freq=',iday_freq,' weekmask=',weekmask)\n",
    "    print('open_time=',open_time,' close_time=',close_time)\n",
    "\n",
    "    topen  = pd.Timestamp(open_time)\n",
    "    tclose = pd.Timestamp(close_time)\n",
    "    \n",
    "    #if bday_freq == 'B':\n",
    "    #    bday_freq = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "    daily = []\n",
    "    dates =  pd.bdate_range(start=start,end=end,freq=bday_freq,weekmask=weekmask)\n",
    "    if iday_freq is None:\n",
    "        return dates\n",
    "\n",
    "    for d in dates:\n",
    "        if d.date() == start.date(): topen = start\n",
    "        d1     = d.replace(hour=topen.hour,minute=topen.minute)\n",
    "        if d.date() == end.date(): tclose = end\n",
    "        d2     = d.replace(hour=tclose.hour,minute=tclose.minute)\n",
    "        daily.append(pd.date_range(d1,d2,freq=iday_freq))\n",
    "   \n",
    "    index = daily[0].union_many(daily[1:])\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filelist = glob.glob('../data/*.csv')\n",
    "count = 0\n",
    "import sys\n",
    "for fn in filelist:\n",
    "    df = pd.read_csv(fn,index_col=0,parse_dates=True)\n",
    "    f  = infer_frequency(df)\n",
    "    ix = time_series_index(start=df.index[0],end=df.index[-1],freq=f)\n",
    "    print(ix[[0,1,2,-3,-2,1]])\n",
    "    \n",
    "    so = df.index.to_series(name='Original')\n",
    "    sg = ix.to_series(name='Generated')\n",
    "    comp = pd.merge(so,sg,left_index=True,right_index=True,how='outer')\n",
    "    comp.to_csv('comp.csv')\n",
    "    #print('comp[comp.isnull()]=')\n",
    "    #isn = comp[comp.isnull()]\n",
    "    print(comp.head(18))\n",
    "    print(comp.tail(18))\n",
    "    try:\n",
    "        sd = ix == df.index\n",
    "        sd = pd.Series(sd)\n",
    "        print(sd.value_counts())\n",
    "    except:\n",
    "        e = sys.exc_info()[1]\n",
    "        print(type(e),'('+str(e)+')')\n",
    "        print('generated=',len(ix),' original=',len(df.index))\n",
    "        print('original df.index range:',df.index[0],df.index[-1])        \n",
    "    print(f,fn,'\\n')\n",
    "    count += 1\n",
    "    if count > 0:\n",
    "        print('break')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkdf = pd.DataFrame(dict(date=ix,dayofweek=[d.dayofweek for d in ix]))\n",
    "wkdf.head(4)\n",
    "\n",
    "weekdays = wkdf.groupby('dayofweek').count()\n",
    "weekdays\n",
    "weekdays.iloc[:,0].mean()\n",
    "weekdays.iloc[:,0].max()\n",
    "\n",
    "len(weekdays)\n",
    "\n",
    "cut = weekdays.max()[0] - 10\n",
    "len(weekdays[ weekdays['date'] > cut])\n",
    "\n",
    "cut = weekdays.max()[0] / 2\n",
    "len(weekdays[ weekdays['date'] > cut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '5/1/2021'\n",
    "end = '5/31/2021'\n",
    "#pd.bdate_range(start=start,end=end,freq=bday_freq,weekmask=weekmask)\n",
    "mask=[0,1,2,3,4]\n",
    "\n",
    "weekmask = [day in mask for day in range(7)]\n",
    "weekmask\n",
    "ix1 = pd.bdate_range(start=start,end=end,freq='C',weekmask=weekmask)\n",
    "\n",
    "weekmask='Mon Tue Wed Thu Fri'\n",
    "ix2 = pd.bdate_range(start=start,end=end,freq='C',weekmask=weekmask)\n",
    "\n",
    "all(ix1 == ix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def _lsq_linear(self,dtseries):\n",
    "#         '''\n",
    "#         Calculate `y = mx + b` linear relationship between `date` and\n",
    "#         `iloc` in `dtseries`.  Return slope (m) and y_intercept (b).\n",
    "#         This closed-form linear least squares algorithm was taken from\n",
    "#         https://mmas.github.io/least-squares-fitting-numpy-scipy\n",
    "#         '''\n",
    "#         si = dtseries\n",
    "#         s  = si.dropna() \n",
    "#         if len(s) < 2:\n",
    "#             err = 'NOT enough data for Least Squares'\n",
    "#             if (len(si) > 2):\n",
    "#                 err += ', due to presence of NaNs'\n",
    "#             raise ValueError(err)\n",
    "#         xs = mdates.date2num(s.index.to_pydatetime())\n",
    "#         ys = [y for y in range(len(xs))]\n",
    "#         a  = np.vstack([xs, np.ones(len(xs))]).T\n",
    "#         m, b  = np.dot(np.linalg.inv(np.dot(a.T,a)), np.dot(a.T,ys))\n",
    "#         #x1, x2 = xs[0], xs[-1]\n",
    "#         #y1 = m*x1 + b\n",
    "#         #y2 = m*x2 + b\n",
    "#         #x1, x2 = mdates.num2date(x1), mdates.num2date(x2)\n",
    "#         #return ((x1,y1),(x2,y2))\n",
    "#         return m, b\n",
    "    \n",
    "#     def _ep_linear(self,dtseries):\n",
    "#         d1 = _date_to_mdate(dtseries.index[0])\n",
    "#         d2 = _date_to_mdate(dtseries.index[-1])\n",
    "\n",
    "#         i1 = 0.0\n",
    "#         i2 = len(dtseries) - 1.0\n",
    "\n",
    "#         slope   = (i2 - i1) / (d2 - d1)\n",
    "#         yitrcpt1 = i1 - (slope*d1)\n",
    "#         yitrcpt2 = i2 - (slope*d2)\n",
    "#         if yitrcpt1 != yitrcpt2:\n",
    "#             print('WARNING: yintercepts NOT equal!!!(',yitrcpt1,yitrcpt2,')')\n",
    "#             yitrcpt = (yitrcpt1 + yitrcpt2) / 2.0\n",
    "#         else:\n",
    "#             yitrcpt = yitrcpt1 \n",
    "#         return slope, yitrcpt            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit wkday(ix)\n",
    "%timeit dofwk(ix)\n",
    "%timeit wkday(ix)\n",
    "%timeit dofwk(ix)\n",
    "\n",
    "\n",
    "%timeit dofwk(ix)\n",
    "%timeit wkday(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)\n",
    "len(ix)\n",
    "all(df.index == ix)\n",
    "sd = pd.Series(df.index == ix)\n",
    "sd.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[388:393]\n",
    "ix[388:393]\n",
    "df.iloc[779:784]\n",
    "ix[779:784]\n",
    "df.iloc[-4:]\n",
    "ix[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Some experiments with Pandas inferred frequency:\n",
    "#### As soon as a Holiday date is missing, Pandas inferred frequency fails<br> (only allows regular non-business days, but not holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/yahoofinance-SPY-20200901-20210113.csv',index_col=0,parse_dates=True)\n",
    "df = pd.read_csv('../data/SP500_NOV2019_Hist.csv',index_col=0,parse_dates=True)\n",
    "df.index\n",
    "len(df)\n",
    "df.index[6:18].inferred_freq\n",
    "df.index[6:18]\n",
    "df.index[0:20].inferred_freq\n",
    "df.index[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "bday_us = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "\n",
    "dtixBH = pd.bdate_range('11/1/2019','11/30/2019',freq=bday_us)\n",
    "#dtixBH\n",
    "\n",
    "dtixB  = pd.bdate_range('11/1/2019','11/30/2019',freq='B')\n",
    "#dtixB\n",
    "\n",
    "dtixD  = pd.bdate_range('11/1/2019','11/30/2019',freq='D')\n",
    "#dtixD\n",
    "\n",
    "#is1 = dtixB.intersection(dtixBH)\n",
    "#is2 = dtixBH.intersection(dtixB)\n",
    "#is1\n",
    "#is1 == is2\n",
    "len(dtixBH)\n",
    "len(dtixB)\n",
    "len(dtixD)\n",
    "\n",
    "\n",
    "#dtixBH.to_series()[is1] == dtixBH.to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sBH = dtixBH.to_series(name='BH')\n",
    "sB  = dtixB.to_series(name='B')\n",
    "sD  = dtixD.to_series(name='D')\n",
    "\n",
    "df  = pd.merge(sB,sBH,left_index=True,right_index=True,how='outer')\n",
    "df  = pd.merge(df,sD,left_index=True,right_index=True,how='outer')\n",
    "\n",
    "df\n",
    "len(sB)\n",
    "len(sBH)\n",
    "len(sD)\n",
    "len(df)\n",
    "for col in df.columns:\n",
    "    print('===',col,'===')\n",
    "    pd.value_counts([ isinstance(d,pd.Timestamp) for d in df[col] ])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts([ isinstance(d,pd.Timestamp) for d in df['BH'] ])\n",
    "pd.value_counts([ isinstance(d,pd.Timestamp) for d in df['B'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtix  = pd.bdate_range('11/1/2019','11/3/2019',freq='T')\n",
    "dtix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "data = [25. + random.random()*25. for j in range(len(dtix))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(data,index=dtix)\n",
    "s\n",
    "#s.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = s.resample('15T').ohlc()\n",
    "sr\n",
    "#sr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [d.weekday() for d in pd.Series([d.date() for d in sr.index]).unique()]\n",
    "# [d.weekday() for d in pd.Series([d.date() for d in sBH.index]).unique()]\n",
    "\n",
    "[d.strftime('%a') for d in pd.Series([d.date() for d in sr.index]).unique()]\n",
    "days = [d.strftime('%a') for d in pd.Series([d.date() for d in sBH.index]).unique()]\n",
    "#days\n",
    "import calendar\n",
    "print(list(calendar.day_abbr))\n",
    "for day in calendar.day_abbr:\n",
    "    print(day,day in days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[d.strftime('%a') for d in pd.Series([d.date() for d in sr.index]).unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(sr.index.values)\n",
    "ix = pd.Index(a)\n",
    "print('ix.inferred_freq=',str(ix.inferred_freq))\n",
    "del a[100]\n",
    "ix = pd.Index(a)\n",
    "print('ix.inferred_freq=',str(ix.inferred_freq))\n",
    "\n",
    "print('ix[0:99].inferred_freq=',str(ix[0:99].inferred_freq))\n",
    "\n",
    "print('ix[99:].inferred_freq=',str(ix[99:].inferred_freq))\n",
    "\n",
    "print('ix[100:].inferred_freq=',str(ix[100:].inferred_freq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix.inferred_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "list(calendar.day_name)\n",
    "list(calendar.day_abbr)\n",
    "print(calendar.calendar(2021))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('===  infer_frequency(df.head(4))  ===')\n",
    "infer_frequency(df.head(4))\n",
    "print('===  infer_frequency(df.head(6).tail(2))  ===')\n",
    "infer_frequency(df.head(6).tail(2))\n",
    "print('===  infer_frequency(df.head(3))  ===')\n",
    "infer_frequency(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design:\n",
    "\n",
    "- It now seems to me, that if we can identify one of the common patterns (listed below) then we can generate datetimes with that pattern to provide a ***more accurate extrapolation*** outside of the range of datetime data provided.\n",
    "  - if we cannot identify a pattern ***then*** we should fall back on linear extrapolation\n",
    "- The common patterns that we will attempt to find are:\n",
    "  - intraday, **one date**, with a regular frequency (hour, minutes, etc.)\n",
    "  - intraday, **multiple dates**, with a regular frequency (hour, minutes, etc.), ***and*** possibly skipping over weekends.\n",
    "    - For both of the above **intraday** case (especially the multiple date case) trading only between Open and Close times.\n",
    "  - daily, 5-day trading week, Mon-Fri\n",
    "  - daily, 5-day trading week, Sun-Thu\n",
    "  - daily, 6-day trading week ??\n",
    "  - weekly  (every Monday, or every Friday)\n",
    "  - Monthly (1st of month or last of month)\n",
    "  - Quaterly (1st of quarter or last of quarter)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Experiments\n",
    "\n",
    "- extrapolation: least squares versus end-to-end linear\n",
    "  - intraday 1m, 15m, 1h, 3h\n",
    "  - daily M-F\n",
    "  - weekly\n",
    "  \n",
    "- extrapolation: known frequency formula\n",
    "  - intraday 1m, 15m, 1h, 3h\n",
    "  - daily M-F\n",
    "  - weekly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls -l ../data/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = ['../data/SP500_NOV2019_Hist.csv',\n",
    "         '../data/SP500_NOV2019_IDayRVol.csv',\n",
    "         '../data/SPY_20110701_20120630_Bollinger.csv',\n",
    "         '../data/yahoofinance-GOOG-20040819-20180120.csv',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with diff value counts in search of a good frequency-inference algorithm\n",
    "\n",
    "- Given a series S, then the following give identical results:\n",
    "  - `diff = (S.shift(-1) - S).shift(1)`\n",
    "  - `diff = S.diff(1)`\n",
    "- The following also give identical results, with each other:\n",
    "  - `diff = S.diff(-1)`\n",
    "  - `diff = (S.shift(1) - S).shift(-1)`\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for file in INPUT:\n",
    "    data = pd.read_csv(file,index_col=0,parse_dates=True)\n",
    "    data.iloc[[0,1,-1],:].style.set_caption(str(data.shape)+' '+file)\n",
    "    dts  = data.index.to_series()\n",
    "    diff = dts.diff(1)\n",
    "    diff.value_counts()\n",
    "    diff.value_counts().idxmax()\n",
    "    diff.value_counts().index[0]\n",
    "    diff.value_counts().idxmax() == diff.value_counts().index[0]\n",
    "    type(diff.value_counts())\n",
    "    diff.value_counts().index\n",
    "    min(diff.value_counts().index)\n",
    "    min(diff.value_counts().index) == diff.value_counts().idxmax()\n",
    "    type(diff.value_counts().index[0])\n",
    "    td = diff.value_counts().keys()[0]\n",
    "    td.days,td.seconds,td.microseconds,td.nanoseconds\n",
    "    type(td.days),type(td.seconds),type(td.microseconds),type(td.nanoseconds)\n",
    "    #for jj in range(9,0,-1):\n",
    "    #    q = round(0.1*jj,1)\n",
    "    #    print('diff.quantile('+str(q)+')=',diff.quantile(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doff = pd.offsets.DateOffset(minutes=1)\n",
    "doff\n",
    "doff.freqstr\n",
    "#dir(doff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.dates as mdates\n",
    "from mplfinance._utils import _date_to_mdate\n",
    "    \n",
    "class DateIlocTransform:\n",
    "    '''Create a transform object that can transform from a date to a DatetimeIndex location, and vis versa.\n",
    "    Requires a Pandas DatetimeIndex upon creation\n",
    "    If `date` does not exactly match a date in the series then interpolate between two dates.\n",
    "    If `date` is outside the range of dates in the series, then extrapolate.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,dtindex):\n",
    "        if not isinstance(dtindex,pd.DatetimeIndex):\n",
    "            raise TypeError('Need `pandas.DatetimeIndex`, but got \"'+str(type(dtindex))+'\"')\n",
    "        if not len(dtindex) > 1:\n",
    "            raise ValueError('`dtindex` must have length of at least 2.')\n",
    "        ixlist = np.linspace(0,len(dtindex),len(dtindex)+1)[0:-1]\n",
    "        self._to_iloc_series = pd.Series(ixlist,index=dtindex)\n",
    "        self._to_date_series = pd.Series(dtindex.values,index=ixlist)\n",
    "        dtseries = dtindex.to_series()\n",
    "        self._lsslope, self._lsyicpt = self._lsq_linear(dtseries)\n",
    "        self._epslope, self._epyicpt = self._ep_linear(dtseries)\n",
    "        \n",
    "\n",
    "    def _lsq_linear(self,dtseries):\n",
    "        '''\n",
    "        Calculate `y = mx + b` linear relationship between `date` and\n",
    "        `iloc` in `dtseries`.  Return slope (m) and y_intercept (b).\n",
    "        This closed-form linear least squares algorithm was taken from\n",
    "        https://mmas.github.io/least-squares-fitting-numpy-scipy\n",
    "        '''\n",
    "        si = dtseries\n",
    "        s  = si.dropna() \n",
    "        if len(s) < 2:\n",
    "            err = 'NOT enough data for Least Squares'\n",
    "            if (len(si) > 2):\n",
    "                err += ', due to presence of NaNs'\n",
    "            raise ValueError(err)\n",
    "        xs = mdates.date2num(s.index.to_pydatetime())\n",
    "        ys = [y for y in range(len(xs))]\n",
    "        a  = np.vstack([xs, np.ones(len(xs))]).T\n",
    "        m, b  = np.dot(np.linalg.inv(np.dot(a.T,a)), np.dot(a.T,ys))\n",
    "        #x1, x2 = xs[0], xs[-1]\n",
    "        #y1 = m*x1 + b\n",
    "        #y2 = m*x2 + b\n",
    "        #x1, x2 = mdates.num2date(x1), mdates.num2date(x2)\n",
    "        #return ((x1,y1),(x2,y2))\n",
    "        return m, b\n",
    "    \n",
    "    def _ep_linear(self,dtseries):\n",
    "        d1 = _date_to_mdate(dtseries.index[0])\n",
    "        d2 = _date_to_mdate(dtseries.index[-1])\n",
    "\n",
    "        i1 = 0.0\n",
    "        i2 = len(dtseries) - 1.0\n",
    "\n",
    "        slope   = (i2 - i1) / (d2 - d1)\n",
    "        yitrcpt1 = i1 - (slope*d1)\n",
    "        yitrcpt2 = i2 - (slope*d2)\n",
    "        if yitrcpt1 != yitrcpt2:\n",
    "            print('WARNING: yintercepts NOT equal!!!(',yitrcpt1,yitrcpt2,')')\n",
    "            yitrcpt = (yitrcpt1 + yitrcpt2) / 2.0\n",
    "        else:\n",
    "            yitrcpt = yitrcpt1 \n",
    "        return slope, yitrcpt\n",
    "    \n",
    "    def to_iloc(self,date,method='ls'):\n",
    "        if method == 'ls':   # Least Squares linear\n",
    "            return self._lsslope*mdates.date2num(date) + self._lsyicpt\n",
    "        elif method == 'ep': # End Point linear\n",
    "            return self._epslope*mdates.date2num(date) + self._epyicpt\n",
    "        elif method == 'in': # INterpolate\n",
    "            #self._to_iloc_series = pd.Series(range(len(dtindex)),index=dtindex)\n",
    "            i1s = self._to_iloc_series.loc[:date]\n",
    "            i1  = i1s[-1] if len(i1s) > 0 else float('nan') # else need to extrapolate\n",
    "            i2s = self._to_iloc_series.loc[date:]\n",
    "            i2  = i2s[ 0] if len(i2s) > 0 else float('nan') # else need to extrapolate\n",
    "            #print('\\ndate,i1,i2=',date,i1,i2)\n",
    "            loc1 = i1\n",
    "            loc2 = i2\n",
    "            d1 = self._to_date_series.iloc[int(round(i1,0))]\n",
    "            d2 = self._to_date_series.iloc[int(round(i2,0))]\n",
    "            #print('date,i1,i2,d1,d2=',date,i1,i2,d1,d2)\n",
    "            loc = ((date-d1)/(d2-d1))*(loc2-loc1) + loc1 if d1 != d2 else loc1\n",
    "            #print('loc1,loc2,loc=',loc1,loc2,loc)\n",
    "            return loc\n",
    "        else:\n",
    "            raise ValueError('Bad value for `method`: ('+str(method)+') ')\n",
    "        return loc2\n",
    "    \n",
    "    def to_datetime(self,iloc,method='ls'):\n",
    "        '''\n",
    "        y = mx + b    \n",
    "        x = (y-b)/m\n",
    "        '''\n",
    "        if method == 'ls':    # Least Squares linear\n",
    "            d = (iloc - self._lsyicpt)/self._lsslope\n",
    "            return mdates.num2date(d).replace(tzinfo=None)\n",
    "        elif method == 'ep':  # End Point linear\n",
    "            d = (iloc - self._epyicpt)/self._epslope\n",
    "            return mdates.num2date(d).replace(tzinfo=None)\n",
    "        elif method == 'in': # INterpolate\n",
    "            #self._to_date_series = pd.Series(dtindex.values,index=range(len(dtindex))) \n",
    "            d1s = self._to_date_series.loc[:iloc]\n",
    "            d1  = d1s.iloc[-1] if len(d1s) > 0 else float('nan') # else should extrapolate\n",
    "            d2s = self._to_date_series.loc[iloc:]\n",
    "            d2  = d2s.iloc[ 0] if len(d2s) > 0 else float('nan') # else should extrapolate\n",
    "            if d1 == d2:\n",
    "                return d1\n",
    "            loc1 = int(round(self._to_iloc_series.loc[d1],0))\n",
    "            loc2 = int(round(self._to_iloc_series.loc[d2],0))\n",
    "            #print('\\nd1,d2=',d1.date().day,d2.date().day,\n",
    "            #      ' iloc,loc1,loc2=',iloc,loc1,loc2)\n",
    "            #print('\\nd1,d2,(d2-d1),type(d2-d1)=',d1,d2,d2-d1,type(d2-d1))\n",
    "            # d1,d2= 8 11  iloc,loc1,loc2= 5.333333333333333 5 6\n",
    "            # d1,d2,(d2-d1)= 2019-11-08 00:00:00 2019-11-11 00:00:00 3 days 00:00:00\n",
    "            # Timestamp('2019-11-08 23:59:59.999999999')\n",
    "            # d = ((iloc-loc1)/(loc2-loc1))*(d2-d1) + d1\n",
    "            d = ((iloc-loc1)*(d2-d1)) + d1\n",
    "            return d.round('s')\n",
    "        else:\n",
    "            raise ValueError('Bad value for `method`: ('+str(method)+') ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in INPUT:\n",
    "    data = pd.read_csv(file,index_col=0,parse_dates=True)\n",
    "    data.iloc[[0,1,-1],:].style.set_caption(str(data.shape)+' '+file)\n",
    "    print(infer_frequency(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdict = {'Open'  :'first',\n",
    "           'High'  :'max',\n",
    "           'Low'   :'min',\n",
    "           'Close' :'last',\n",
    "           'Volume':'sum'\n",
    "          }\n",
    "f = infer_frequency(data.resample('1W').agg(aggdict))\n",
    "f\n",
    "pd.Timedelta(days=7)\n",
    "f == pd.Timedelta(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.resample('1M').agg(aggdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_frequency(data.resample('1M').agg(aggdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Timedelta('1Month')\n",
    "d1 = data.loc['2004-10',:]\n",
    "d2 = data.resample('1M').agg(aggdict)\n",
    "d3 = data.asfreq('1M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.iloc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are going to develop a transform similar to date_to_iloc() with the following features:\n",
    "- Able to transform both directions\n",
    "- saves the relavant input data to avoid *some* recalculation\n",
    "- implementation as a class will enable saving the input data in the transform object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/SP500_NOV2019_IDayRVol.csv',index_col=0,parse_dates=True)\n",
    "dtindex = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtseries = dtindex.to_series()\n",
    "dtseries['2019-11-08 15:50:01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtseries.describe(datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = dtseries.shift(-1) - dtseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.quantile(0.9981)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Here we experiment with finding gaps in the data, specifically for the example of *intraday* data with specific trading hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../tmp.py\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Construct dummy dataframe\n",
    "dates = pd.to_datetime([\n",
    "    '2016-08-03',\n",
    "    '2016-08-04',\n",
    "    '2016-08-05',\n",
    "    '2016-08-17',\n",
    "    '2016-09-05',\n",
    "    '2016-09-06',\n",
    "    '2016-09-07',\n",
    "    '2016-09-19'])\n",
    "df = pd.DataFrame(dates, columns=['date'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the diff of the first column (drop 1st row since it's undefined)\n",
    "deltas = df['date'].diff()[1:]\n",
    "deltas\n",
    "# Filter diffs (here days > 1, but could be seconds, hours, etc)\n",
    "gaps = deltas[deltas > timedelta(days=1)]\n",
    "gaps\n",
    "# Print results\n",
    "#print(f'{len(gaps)} gaps with average gap duration: {gaps.mean()}')\n",
    "#for i, g in gaps.iteritems():\n",
    "#    gap_start = df['date'][i - 1]\n",
    "#    print(f'Start: {datetime.strftime(gap_start, \"%Y-%m-%d\")} | '\n",
    "#          f'Duration: {str(g.to_pytimedelta())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = pd.read_csv('../data/SP500_NOV2019_IDayRVol.csv',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.iloc[[0,1,2,-2,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = idf.index.to_series().diff()[1:]\n",
    "deltas\n",
    "# Filter diffs (here days > 1, but could be seconds, hours, etc)\n",
    "deltas.value_counts()\n",
    "freq = deltas.value_counts().idxmax()\n",
    "freq\n",
    "gaps = deltas[deltas != freq]\n",
    "gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.head(3)\n",
    "idf.loc['2019-11-06'].index[-1]\n",
    "idf.loc['2019-11-07'].index[ 0]\n",
    "idf.loc['2019-11-07'].index[ 0] - idf.loc['2019-11-06'].index[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datetime index associate with the gap (i.e. with the gap duration)<br> appears to be the ***end time*** of the gap (or rather the start time of the next *non-gap*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/SP500_NOV2019_Hist.csv',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dit = DateIlocTransform(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtindex = df.index\n",
    "ixlist = np.linspace(0,len(dtindex),len(dtindex)+1)[0:-1]\n",
    "to_iloc_series = pd.Series(ixlist,index=dtindex)\n",
    "to_date_series = pd.Series(dtindex.values,index=ixlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in ['ep','ls']:\n",
    "    print('\\n=== method: \"'+method+'\"  =====')\n",
    "    for d in df.index.to_pydatetime():\n",
    "        il = dit.to_iloc(d,method=method)\n",
    "        dt = dit.to_datetime(il,method=method)\n",
    "        err = 'ERR' if d.date().day != dt.date().day else ''\n",
    "        print(\"%6.2f  %2d  %2d  %3s\" % (il,d.date().day,dt.date().day,err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(daterange)= 134\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-33e959914b36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlen(daterange)=\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mlen\u001b[39m(daterange))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m daterange:\n\u001b[0;32m----> 5\u001b[0m     il \u001b[38;5;241m=\u001b[39m dit\u001b[38;5;241m.\u001b[39mto_iloc(d,method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#print('il=',il,type(il))\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     dt \u001b[38;5;241m=\u001b[39m dit\u001b[38;5;241m.\u001b[39mto_datetime(il,method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dit' is not defined"
     ]
    }
   ],
   "source": [
    "daterange = pd.date_range(start=df.index[0],end=df.index[-1],freq='D')\n",
    "#for d in df.index.to_pydatetime():\n",
    "print('len(daterange)=',len(daterange))\n",
    "for d in daterange:\n",
    "    il = dit.to_iloc(d,method='in')\n",
    "    #print('il=',il,type(il))\n",
    "    dt = dit.to_datetime(il,method='in')\n",
    "    err = 'ERR' if d.date().day != dt.date().day else ''\n",
    "    print(\"%6.2f  %s  %2d  %2d  %3s\" % (il,d.date(),d.date().day,dt.date().day,err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = 0.333333333333333*pd.Timedelta(days=3)\n",
    "td\n",
    "td.round('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[0]\n",
    "df.index[-1] - df.index[0]\n",
    "(df.index[-1] - df.index[0]).days\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df))/(df.index[-1] - df.index[0]).days\n",
    "(len(df)-1)/(df.index[-1] - df.index[0]).days\n",
    "5/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[19]\n",
    "df.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n==== INTC ====')\n",
    "# df = pd.read_csv('../data/yahoofinance-INTC-19950101-20040412.csv',index_col=0,parse_dates=True)\n",
    "# df.iloc[[0,1,-2,-1]]\n",
    "# len(df)\n",
    "# print('\\n==== GOOG ====')\n",
    "df = pd.read_csv('../data/yahoofinance-GOOG-20040819-20180120.csv',index_col=0,parse_dates=True)\n",
    "df.iloc[[0,1,-2,-1]]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.index[-1] - df.index[0]).days\n",
    "(len(df))/(df.index[-1] - df.index[0]).days\n",
    "(len(df)-1)/(df.index[-1] - df.index[0]).days\n",
    "5/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.index[-1] - df.index[0]).days\n",
    "yrs = ((df.index[-1] - df.index[0]).days - 1) / 365.25\n",
    "hldys = yrs*3\n",
    "((5/7)*365.25 - hldys)/365.25\n",
    "print()\n",
    "4/7\n",
    "6/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df)-1)/(df.index[-1]-df.index[0]).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = df.index.to_series().diff(1)\n",
    "dvc = diff.value_counts()\n",
    "dvc[0]/dvc[1]\n",
    "dvc\n",
    "dvc.keys()\n",
    "dne1 = diff[ diff > pd.Timedelta(days=1) ]\n",
    "len(diff)\n",
    "len(dne1)\n",
    "vc = dne1.value_counts()\n",
    "vc\n",
    "vc[0]/vc[1]\n",
    "vc[0]/vc[1] > 2\n",
    "vc.idxmax().days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = pd.date_range(start='1/1/2001',periods=30,freq='D')\n",
    "dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(dr)-1)/(dr[-1] - dr[0]).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = pd.date_range(start='1/1/2001',periods=30,freq='B')\n",
    "dr\n",
    "\n",
    "bday_Israel = pd.offsets.CustomBusinessDay(weekmask='Sun Mon Tue Wed Thu')\n",
    "drI = pd.date_range(start='1/1/2001',periods=30,freq=bday_Israel)\n",
    "drI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2f = pd.offsets.CustomBusinessDay(weekmask='Mon Tue Wed Thu Fri')\n",
    "drm2f = pd.date_range(start='1/1/2001',periods=30,freq=m2f)\n",
    "drm2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(dr == drm2f)\n",
    "all(dr == drI)\n",
    "dr == drI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drt = pd.date_range(dr[0],dr[-1],freq='B')\n",
    "drt\n",
    "dr == drt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = pd.date_range('1/1/2021',periods=12,freq='BM')\n",
    "dr\n",
    "dr = pd.date_range('1/1/2021',periods=12,freq='W-FRI')\n",
    "dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dr)\n",
    "dr[-1] - dr[0]\n",
    "(len(dr)-1) == (dr[-1]-dr[0]).days/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idr = pd.date_range('1/2/2021 09:30',periods=12,freq='15T')\n",
    "idr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T15  = pd.offsets.Minute(15)\n",
    "BD   = pd.offsets.BDay()\n",
    "TH   = pd.offsets.BusinessHour(start='09:30',end='16:00')\n",
    "do15 = pd.offsets.DateOffset(minutes=15)\n",
    "do15 == T15\n",
    "T15\n",
    "BD\n",
    "TH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.bdate_range('1/1/2021','1/13/2021',freq='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.bdate_range('1/1/2021','1/13/2021',freq='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "bday_us = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "pd.bdate_range('1/1/2021','1/13/2021',freq=bday_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bday_me = pd.offsets.CustomBusinessDay(weekmask='Sun Mon Tue Wed Thu')\n",
    "pd.bdate_range('1/1/2021','1/13/2021',freq=bday_me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhours = pd.offsets.BusinessHour(start='09:30',end='16:00')\n",
    "pd.bdate_range('1/1/2021','1/13/2021',freq=bhours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bday_us = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "dtindex = pd.bdate_range('1/1/2021','1/13/2021',freq=bday_us)\n",
    "ixlist  = []\n",
    "for dt in dtindex:\n",
    "    d1 = dt.replace(hour=9,minute=30)\n",
    "    d2 = dt.replace(hour=16,minute=1) # make sure to include 16:00\n",
    "    # Here we must use `date_range()` instead of `bdate_range()`\n",
    "    ixlist.append(pd.date_range(d1,d2,freq='30min'))\n",
    "trading_index = ixlist[0].union_many(ixlist[1:])\n",
    "print(trading_index[range(16)])\n",
    "print('...')\n",
    "print(trading_index[range(63,77)])\n",
    "print('...')\n",
    "print(trading_index[range(-16,0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bday_us = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "dtindex = pd.bdate_range('1/1/2021','1/13/2021',freq=bday_us)\n",
    "octimes = [] # open and close times\n",
    "for dt in dtindex:\n",
    "    octimes.append(dt.replace(hour=9,minute=30))\n",
    "    octimes.append(dt.replace(hour=16,minute=0))\n",
    "\n",
    "for ts in octimes:\n",
    "    print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idr = pd.date_range('1/2/2021 09:30',periods=500,freq='15T')\n",
    "#idr\n",
    "t_hours = idr[idr.indexer_between_time(start_time='09:30',end_time='16:00')]\n",
    "t_hours[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(range(len(idr)),index=idr)\n",
    "ts.index[ts.index.indexer_between_time(start_time='09:30',end_time='16:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = pd.bdate_range('01/01/2021 09:30','01/13/2021 16:00',freq='D')\n",
    "dr\n",
    "dr = pd.bdate_range('01/01/2021 09:30','01/13/2021 16:00',freq='B')\n",
    "dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dr = pd.date_range('01/01/2021 09:30','01/13/2021 16:00',freq=BD)\n",
    "dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr[0]\n",
    "dr[0].replace(hour=16,minute=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for d in dr:\n",
    "    d2 = d.replace(hour=16,minute=1)\n",
    "    indexes.append(pd.date_range(d,d2,freq='15T'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = indexes[0]\n",
    "ix = ix.union_many(indexes[1:])\n",
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for d in ix[0:200]:\n",
    "# for d in ix[20:32]:\n",
    "#    print(d)\n",
    "ix[20:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_time = '16:00'\n",
    "close = pd.Timestamp(close_time)\n",
    "close\n",
    "close.hour\n",
    "close.minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Alias|Description|\n",
    "|---|---|\n",
    "|B    |business day frequency|\n",
    "|C    |custom business day frequency|\n",
    "|D    |calendar day frequency|\n",
    "|W    |weekly frequency|\n",
    "|M    |month end frequency|\n",
    "|SM   |semi-month end frequency (15th and end of month)|\n",
    "|BM   |business month end frequency|\n",
    "|CBM  |custom business month end frequency|\n",
    "|MS   |month start frequency|\n",
    "|SMS  |semi-month start frequency (1st and 15th)|\n",
    "|BMS  |business month start frequency|\n",
    "|CBMS  |custom business month start frequency|\n",
    "|Q     |quarter end frequency|\n",
    "|BQ    |business quarter end frequency|\n",
    "|QS    |quarter start frequency|\n",
    "|BQS   |business quarter start frequency|\n",
    "|A,Y   |year end frequency|\n",
    "|BA,BY |business year end frequency|\n",
    "|AS,YS |year start frequency|\n",
    "|BAS,BYS | business year start frequency|\n",
    "|BH    |business hour frequency|\n",
    "|H     |hourly frequency|\n",
    "|T,min |minutely frequency|\n",
    "|S     |secondly frequency|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='M',weekmask=None)\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='BM',weekmask=None)\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='MS',weekmask=None)\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='BMS',weekmask=None)\n",
    "\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='Q',weekmask=None)\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='BQ',weekmask=None)\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='QS',weekmask=None)\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='BQS',weekmask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfreq = TimeSeriesFrequency(dfreq=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.calendar.holidays\n",
    "d.calendar.weekmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trading_day_range(bday_start=None,bday_end=None,bday_freq='B',\n",
    "                      open_time='09:30',close_time='16:00',iday_freq='15T',weekmask=None):\n",
    "\n",
    "    if bday_start is None: bday_start = pd.Timestamp.today()\n",
    "    if bday_end   is None: bday_end = bday_start + pd.Timedelta(days=1)\n",
    "\n",
    "    daily = []\n",
    "    for d in pd.bdate_range(start=bday_start,end=bday_end,freq=bday_freq,weekmask=weekmask):\n",
    "        topen  = pd.Timestamp(open_time)\n",
    "        d1     = d.replace(hour=topen.hour,minute=topen.minute)\n",
    "        tclose = pd.Timestamp(close_time)\n",
    "        d2     = d.replace(hour=tclose.hour,minute=tclose.minute+1)\n",
    "        daily.append(pd.date_range(d1,d2,freq=iday_freq))\n",
    "   \n",
    "    index = daily[0].union_many(daily[1:])\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = trading_day_range()\n",
    "print('len(ix)=',len(ix))\n",
    "print(ix[20:40])\n",
    "print(ix[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trading_day_range(bday_start=None,bday_end=None,day_freq='B',\n",
    "#                       open_time='09:30',close_time='16:00',trade_freq='15T',weekmask=None):\n",
    "\n",
    "#ix1 = trading_day_range('01/01/2021 09:30','01/13/2021 16:00',day_freq='B',trade_freq='30T')#,weekmask='Wed Thu')\n",
    "ix1 = trading_day_range('01/01/2021 09:30','01/13/2021 16:00',bday_freq='C',iday_freq='30T',weekmask='Wed Thu Fri')\n",
    "print('len(ix1)=',len(ix1))\n",
    "print(ix1[20:40])\n",
    "print(ix1[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix2 = pd.bdate_range('01/01/2021 09:30','01/13/2021 16:00',freq='30T')\n",
    "#ix2 = pd.bdate_range('01/01/2021 09:30','01/13/2021 16:00',freq='C',weekmask=\"Mon Tue Wed Thu Fri\")\n",
    "ix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix2 = ix2[ix2.indexer_between_time(start_time='09:30',end_time='16:00')]\n",
    "ix2[20:40]\n",
    "ix2[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(ix1)\n",
    "len(ix2)\n",
    "bdays = pd.bdate_range('01/01/2021 09:30','01/13/2021 16:00',freq='B')\n",
    "\n",
    "\n",
    "ix2list = [d for d in ix2 if pd.Timestamp(d.date()) in bdays]\n",
    "#ix2list\n",
    "ix2n = pd.DatetimeIndex(ix2list)\n",
    "len(ix2n)\n",
    "ix2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(range(10),index=['A','B','C','D','E','F','G','H','I','J'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[['A','C','F']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.DataFrame(range(10),index=pd.date_range('1/1/2021',periods=10))\n",
    "s = pd.DataFrame(range(10),index=pd.date_range('1/1/2021 09:30',periods=10,freq='12H'))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index\n",
    "type(s.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s.loc[['2021-01-01','2021-01-04'],:]\n",
    "s.loc['2021-01-01']\n",
    "#s[['2021-01-01','2021-01-04']]\n",
    "#s['2021-01-01'] + s['2021-01-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['Date'] = [d.date() for d in s.index]\n",
    "s\n",
    "\n",
    "s['Date'][0]\n",
    "type(s['Date'][0])\n",
    "\n",
    "s['Date']\n",
    "s['Date'].isin([datetime.date(2021,1,1),datetime.date(2021,1,4)])\n",
    "\n",
    "s[ s['Date'].isin([datetime.date(2021,1,1),datetime.date(2021,1,4)]) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtix = pd.DatetimeIndex([datetime.date(2021,1,1),datetime.date(2021,1,4)])\n",
    "dtix\n",
    "dtix[0]\n",
    "dtix.to_pydatetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['Date']\n",
    "s['Date'].isin([datetime.date(2021,1,1),datetime.date(2021,1,4)])\n",
    "s['Date'].isin([d.date() for d in dtix.to_pydatetime()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drbd = pd.date_range('01/01/2021 09:30','01/13/2021 16:00',freq=BD)\n",
    "# [d.date() for d in  drbd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dr = pd.date_range('01/01/2021 09:30','01/13/2021 16:00',freq='15T')\n",
    "# sd = pd.Series(range(len(dr)),index=dr)\n",
    "# sd\n",
    "# dlist = [d.date() for d in  drbd] \n",
    "# dlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm, lb = dit._lsq_linear(dtseries)\n",
    "lm, lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em, eb = dit._ep_linear(dtseries)\n",
    "em, eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jj in range(len(dtseries)):\n",
    "    date = dtseries.iloc[jj]\n",
    "    \n",
    "    ly  = lm*mdates.date2num(date) + lb\n",
    "    ily = int(np.round(ly))\n",
    "    \n",
    "    ey  = em*mdates.date2num(date) + eb\n",
    "    iey = int(np.round(ey))\n",
    "    \n",
    "    print(\"%2d  %5.2f  %2d  %5.2f %20s\" % (ily,ly,iey,ey,date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldts = [dtseries[0] + pd.DateOffset(offset) for offset in range(30)]\n",
    "new_dtseries = pd.Series(alldts,index=pd.DatetimeIndex(alldts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eerr = []\n",
    "lerr = []\n",
    "print(\"jj ily  iey   ly     ey     dt  dt(il) dt(ie)\")\n",
    "for jj in range(len(new_dtseries)-1):\n",
    "    date = new_dtseries.iloc[jj]\n",
    "    \n",
    "    ly  = lm*mdates.date2num(date) + lb\n",
    "    ily = int(np.round(ly))\n",
    "    \n",
    "    ey  = em*mdates.date2num(date) + eb\n",
    "    iey = int(np.round(ey))\n",
    "    \n",
    "    ily = 0 if (ily < 0 or ily > 19) else ily\n",
    "    iey = 0 if (iey < 0 or iey > 19) else iey\n",
    "    \n",
    "    err_l = dtseries.iloc[ily].date().day - date.date().day\n",
    "    err_e = dtseries.iloc[iey].date().day - date.date().day\n",
    "    lerr.append(abs(err_l))\n",
    "    eerr.append(abs(err_e))\n",
    "\n",
    "    print(\"%2d  %2d  %2d  %5.2f  %5.2f  %4s  %4s  %4s  %4s  %4s\" % \n",
    "          (jj,ily,iey,ly,ey,date.date().day,dtseries.iloc[ily].date().day,\n",
    "           dtseries.iloc[iey].date().day, err_l, err_e)\n",
    "         )\n",
    "\n",
    "print('\\nsum(lerr)=',sum(lerr),' sum(eerr)=',sum(eerr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lerr = []\n",
    "eerr = []\n",
    "for jj in range(len(dtseries)):\n",
    "    date = dtseries.iloc[jj]\n",
    "    \n",
    "    ly  = lm*mdates.date2num(date) + lb\n",
    "    ily = int(np.round(ly))\n",
    "    \n",
    "    ey  = em*mdates.date2num(date) + eb\n",
    "    iey = int(np.round(ey))\n",
    "    \n",
    "    err_l = dtseries.iloc[ily].date().day - date.date().day\n",
    "    err_e = dtseries.iloc[iey].date().day - date.date().day\n",
    "    \n",
    "    lerr.append(abs(err_l))\n",
    "    eerr.append(abs(err_e))\n",
    "\n",
    "    \n",
    "    print(\"%2d  %5.2f  %2d  %5.2f %6s %6s %6s %6s %6s\" % (ily,ly,iey,ey,date.date().day,\n",
    "                                                  dtseries.iloc[ily].date().day,\n",
    "                                                  dtseries.iloc[iey].date().day,\n",
    "                                                  err_l, err_e))\n",
    "    \n",
    "print('\\nsum(lerr)=',sum(lerr),' sum(eerr)=',sum(eerr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
