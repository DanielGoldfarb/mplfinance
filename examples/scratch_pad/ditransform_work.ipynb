{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#  mplfinance Date iLoc Transform\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows multiple outputs from a single jupyter notebook cell:\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.9b0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mplfinance as mpf\n",
    "mpf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/SP500_NOV2019_Hist.csv',index_col=0,parse_dates=True)\n",
    "df = pd.read_csv('../data/yahoofinance-SPY-20200901-20210113.csv',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uses for DateIlocTransform\n",
    "\n",
    "#### aka \"DateIxPos\" or \"DateIPos\" Transform\n",
    "\n",
    "#### All uses are for `show_nontrading=False` only:\n",
    "\n",
    "- `.to_date()` &nbsp; location *to* date: &nbsp; for tick label formatting.\n",
    "- `.to_iloc()` &nbsp; date *to* location: &nbsp; for `xticks` placement.\n",
    "- `.to_iloc()` &nbsp; date *to* location: &nbsp; for `xlim` placement.\n",
    "- `.to_iloc()` &nbsp; date *to* location: &nbsp; for `lines` placement.\n",
    "\n",
    "---\n",
    "\n",
    "- It seems to me that  \n",
    "  - **interpolation** may be better using the actual datetime series (rather than the linear formula), whereas \n",
    "  - **extrapolation** *will require* the linear formula.\n",
    "    - Or for \"known\" cases may be able to use **date calculations**, for example:\n",
    "      - quartile(0.65) == quartile(0.50) == quartile(0.35) == \"known\" frequency.\n",
    "      - intraday with consistent trading hours in data\n",
    "      - daily with weekends missing (maybe someday allow users to supply holidays)\n",
    "      - weekly, monthly, yearly, etc. are simple?\n",
    "  - need to run some tests to see which, if either, is better.\n",
    "- Keep in mind, while testing, that `xlim` values will affect `xticks` placement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-01</th>\n",
       "      <td>350.209991</td>\n",
       "      <td>352.709991</td>\n",
       "      <td>349.239990</td>\n",
       "      <td>352.600006</td>\n",
       "      <td>349.703522</td>\n",
       "      <td>54999300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-02</th>\n",
       "      <td>354.670013</td>\n",
       "      <td>358.750000</td>\n",
       "      <td>353.429993</td>\n",
       "      <td>357.700012</td>\n",
       "      <td>354.761627</td>\n",
       "      <td>69540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-03</th>\n",
       "      <td>355.869995</td>\n",
       "      <td>356.380005</td>\n",
       "      <td>342.589996</td>\n",
       "      <td>345.390015</td>\n",
       "      <td>342.552765</td>\n",
       "      <td>148011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-04</th>\n",
       "      <td>346.130005</td>\n",
       "      <td>347.829987</td>\n",
       "      <td>334.869995</td>\n",
       "      <td>342.570007</td>\n",
       "      <td>339.755890</td>\n",
       "      <td>139156300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-08</th>\n",
       "      <td>336.709991</td>\n",
       "      <td>342.640015</td>\n",
       "      <td>332.880005</td>\n",
       "      <td>333.209991</td>\n",
       "      <td>330.472778</td>\n",
       "      <td>114465300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2020-09-01  350.209991  352.709991  349.239990  352.600006  349.703522   \n",
       "2020-09-02  354.670013  358.750000  353.429993  357.700012  354.761627   \n",
       "2020-09-03  355.869995  356.380005  342.589996  345.390015  342.552765   \n",
       "2020-09-04  346.130005  347.829987  334.869995  342.570007  339.755890   \n",
       "2020-09-08  336.709991  342.640015  332.880005  333.209991  330.472778   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2020-09-01   54999300  \n",
       "2020-09-02   69540000  \n",
       "2020-09-03  148011100  \n",
       "2020-09-04  139156300  \n",
       "2020-09-08  114465300  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>369.709991</td>\n",
       "      <td>376.980011</td>\n",
       "      <td>369.119995</td>\n",
       "      <td>373.549988</td>\n",
       "      <td>373.549988</td>\n",
       "      <td>107997700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>376.100006</td>\n",
       "      <td>379.899994</td>\n",
       "      <td>375.910004</td>\n",
       "      <td>379.100006</td>\n",
       "      <td>379.100006</td>\n",
       "      <td>68766800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>380.589996</td>\n",
       "      <td>381.489990</td>\n",
       "      <td>377.100006</td>\n",
       "      <td>381.260010</td>\n",
       "      <td>381.260010</td>\n",
       "      <td>71677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-11</th>\n",
       "      <td>377.850006</td>\n",
       "      <td>380.579987</td>\n",
       "      <td>377.720001</td>\n",
       "      <td>378.690002</td>\n",
       "      <td>378.690002</td>\n",
       "      <td>51176700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-12</th>\n",
       "      <td>378.890015</td>\n",
       "      <td>379.859985</td>\n",
       "      <td>376.359985</td>\n",
       "      <td>378.769989</td>\n",
       "      <td>378.769989</td>\n",
       "      <td>52445000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2021-01-06  369.709991  376.980011  369.119995  373.549988  373.549988   \n",
       "2021-01-07  376.100006  379.899994  375.910004  379.100006  379.100006   \n",
       "2021-01-08  380.589996  381.489990  377.100006  381.260010  381.260010   \n",
       "2021-01-11  377.850006  380.579987  377.720001  378.690002  378.690002   \n",
       "2021-01-12  378.890015  379.859985  376.359985  378.769989  378.769989   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2021-01-06  107997700  \n",
       "2021-01-07   68766800  \n",
       "2021-01-08   71677200  \n",
       "2021-01-11   51176700  \n",
       "2021-01-12   52445000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.datetimes.DatetimeIndex"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.datetime64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-01 00:00:00\n",
      "2020-09-01T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "s = df.head().index.to_series()\n",
    "type(s.index)\n",
    "type(s.index[0])\n",
    "type(s.values)\n",
    "type(s.values[0])\n",
    "s.index[0] == s.values[0]\n",
    "print(s.index[0])\n",
    "print(s.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Cases\n",
    "- For each use case (data entered) we interpolate a few points, and extrapolate a few points, both datetime -> iloc and iloc -> datetime\n",
    "\n",
    "1. Intraday, part of a day (1 to 4 hours).  Data frequencies: min, 3min, 15min, 30min, hour, 90 min\n",
    "2. Intraday, one full day.  (Data freq: min, 3min, 15min, 30min, hour, 90 min)\n",
    "3. Intraday, 1.5 days. ...\n",
    "4. Intraday, 10 days (skip weekends; weekend=FS and weekend=SS)\n",
    "5. Intraday, 10 days (including weekends; weekend=FS and weekend=SS)\n",
    "6. Daily, 3 days\n",
    "7. Daily, 45 days (skip weekends, 1-day weekends, no weekends, holidays)\n",
    "8. Daily, 125 days (skip weekends, 1-day weekends, no weekends, holidays)\n",
    "9. Weekly ...\n",
    "10. Monthly ...\n",
    "11. Quarterly ...\n",
    "12. Yearly ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ditransform as ditf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basefreq= 1 days 00:00:00\n",
      "basefreq.days= 1\n",
      "weekmask= [True, True, True, True, True, False, False]\n",
      "\n",
      "vc(value counts)=\n",
      "1 days    71\n",
      "3 days    16\n",
      "4 days     3\n",
      "2 days     1\n",
      "Name: Date, dtype: int64\n",
      "ifreq = None \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "_extrapolation_limits\n",
      "_inferred_frequency\n",
      "_to_date_series\n",
      "_to_iloc_series\n",
      "infer_frequency\n",
      "infer_open_close\n",
      "infer_weekmask\n",
      "time_series_index\n",
      "timedelta_to_freqabbr\n",
      "to_datetime\n",
      "to_iloc\n"
     ]
    }
   ],
   "source": [
    "tf = ditf.DateIlocTransform(df.index)\n",
    "\n",
    "dl = dir(tf)\n",
    "for item in dl:\n",
    "    if item[0:2] != '__':\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../data/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/alphavantage_demodata.csv',\n",
       " '../data/yahoofinance-GOOG-20040819-20180120.csv',\n",
       " '../data/SPY_20110701_20120630_Bollinger.csv',\n",
       " '../data/SP500_NOV2019_IDay.csv',\n",
       " '../data/yahoofinance-INTC-19950101-20040412.csv',\n",
       " '../data/SP500_NOV2019_Hist.csv',\n",
       " '../data/yahoofinance-SPY-20200901-20210113.csv',\n",
       " '../data/SP500_20191106_IDayBollinger.csv',\n",
       " '../data/yahoofinance-AAPL-20040819-20180120.csv',\n",
       " '../data/SP500_20191106_IDayBollTweak.csv',\n",
       " '../data/yahoofinance-SPY-20080101-20180101.csv',\n",
       " '../data/SP500_NOV2019_IDayRVol.csv',\n",
       " '../data/jpyusd_barchartdotcom.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basefreq= 0 days 00:05:00\n",
      "basefreq.days= 0\n",
      "weekmask= [True, True, True, True, True, False, False]\n",
      "Date\n",
      "2022-04-18 04:35:00   2022-04-18 04:35:00\n",
      "2022-04-18 07:05:00   2022-04-18 07:05:00\n",
      "2022-04-18 07:10:00   2022-04-18 07:10:00\n",
      "2022-05-13 17:10:00   2022-05-13 17:10:00\n",
      "2022-05-13 17:25:00   2022-05-13 17:25:00\n",
      "2022-05-13 18:10:00   2022-05-13 18:10:00\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "\n",
      "vc(value counts)=\n",
      "0 days 00:05:00    1928\n",
      "0 days 00:10:00     117\n",
      "0 days 00:15:00      58\n",
      "0 days 00:20:00      37\n",
      "0 days 00:25:00      24\n",
      "0 days 00:30:00      14\n",
      "0 days 00:35:00      11\n",
      "0 days 00:40:00       8\n",
      "0 days 00:55:00       6\n",
      "0 days 00:45:00       6\n",
      "Name: Date, dtype: int64\n",
      "ifreq = 5T \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/alphavantage_demodata.csv ===\n",
      "TimeSeriesFrequency(d='B', i='5T', w='[True, True, True, True, True, False, False]', o='04:05:00', c='20:00:00')\n",
      "\n",
      "basefreq= 1 days 00:00:00\n",
      "basefreq.days= 1\n",
      "weekmask= [True, True, True, True, True, False, False]\n",
      "\n",
      "vc(value counts)=\n",
      "1 days    2649\n",
      "3 days     608\n",
      "4 days      90\n",
      "2 days      29\n",
      "5 days       2\n",
      "Name: Date, dtype: int64\n",
      "ifreq = None \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/yahoofinance-GOOG-20040819-20180120.csv ===\n",
      "TimeSeriesFrequency(d='B', i='None', w='[True, True, True, True, True, False, False]', o='09:30:00', c='16:00:00')\n",
      "\n",
      "basefreq= 1 days 00:00:00\n",
      "basefreq.days= 1\n",
      "weekmask= [True, True, True, True, True, False, False]\n",
      "\n",
      "vc(value counts)=\n",
      "1 days    198\n",
      "3 days     44\n",
      "4 days      8\n",
      "2 days      1\n",
      "Name: Date, dtype: int64\n",
      "ifreq = None \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/SPY_20110701_20120630_Bollinger.csv ===\n",
      "TimeSeriesFrequency(d='B', i='None', w='[True, True, True, True, True, False, False]', o='09:30:00', c='16:00:00')\n",
      "\n",
      "basefreq= 0 days 00:01:00\n",
      "basefreq.days= 0\n",
      "weekmask= [False, True, True, True, True, False, False]\n",
      "Date\n",
      "2019-11-05 09:30:00   2019-11-05 09:30:00\n",
      "2019-11-05 09:31:00   2019-11-05 09:31:00\n",
      "2019-11-05 09:32:00   2019-11-05 09:32:00\n",
      "2019-11-08 15:57:00   2019-11-08 15:57:00\n",
      "2019-11-08 15:58:00   2019-11-08 15:58:00\n",
      "2019-11-08 15:59:00   2019-11-08 15:59:00\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "\n",
      "vc(value counts)=\n",
      "0 days 00:01:00    1559\n",
      "0 days 17:30:00       3\n",
      "Name: Date, dtype: int64\n",
      "ifreq = 1T \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/SP500_NOV2019_IDay.csv ===\n",
      "TimeSeriesFrequency(d='B', i='1T', w='[False, True, True, True, True, False, False]', o='09:30:00', c='16:00:00')\n",
      "\n",
      "basefreq= 1 days 00:00:00\n",
      "basefreq.days= 1\n",
      "weekmask= [True, True, True, True, True, False, False]\n",
      "\n",
      "vc(value counts)=\n",
      "1 days    1827\n",
      "3 days     427\n",
      "4 days      55\n",
      "2 days      24\n",
      "7 days       1\n",
      "Name: Date, dtype: int64\n",
      "ifreq = None \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/yahoofinance-INTC-19950101-20040412.csv ===\n",
      "TimeSeriesFrequency(d='B', i='None', w='[True, True, True, True, True, False, False]', o='09:30:00', c='16:00:00')\n",
      "\n",
      "basefreq= 1 days 00:00:00\n",
      "basefreq.days= 1\n",
      "weekmask= [True, True, True, True, True, False, False]\n",
      "\n",
      "vc(value counts)=\n",
      "1 days    14\n",
      "3 days     4\n",
      "2 days     1\n",
      "Name: Date, dtype: int64\n",
      "ifreq = None \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/SP500_NOV2019_Hist.csv ===\n",
      "TimeSeriesFrequency(d='B', i='None', w='[True, True, True, True, True, False, False]', o='09:30:00', c='16:00:00')\n",
      "\n",
      "basefreq= 1 days 00:00:00\n",
      "basefreq.days= 1\n",
      "weekmask= [True, True, True, True, True, False, False]\n",
      "\n",
      "vc(value counts)=\n",
      "1 days    71\n",
      "3 days    16\n",
      "4 days     3\n",
      "2 days     1\n",
      "Name: Date, dtype: int64\n",
      "ifreq = None \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/yahoofinance-SPY-20200901-20210113.csv ===\n",
      "TimeSeriesFrequency(d='B', i='None', w='[True, True, True, True, True, False, False]', o='09:30:00', c='16:00:00')\n",
      "\n",
      "basefreq= 0 days 00:01:00\n",
      "basefreq.days= 0\n",
      "weekmask= [False, False, True, False, False, False, False]\n",
      "Date\n",
      "2019-11-06 09:30:00   2019-11-06 09:30:00\n",
      "2019-11-06 09:31:00   2019-11-06 09:31:00\n",
      "2019-11-06 09:32:00   2019-11-06 09:32:00\n",
      "2019-11-06 15:58:00   2019-11-06 15:58:00\n",
      "2019-11-06 15:59:00   2019-11-06 15:59:00\n",
      "2019-11-06 16:00:00   2019-11-06 16:00:00\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "\n",
      "vc(value counts)=\n",
      "0 days 00:01:00    390\n",
      "Name: Date, dtype: int64\n",
      "ifreq = 1T \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/SP500_20191106_IDayBollinger.csv ===\n",
      "TimeSeriesFrequency(d='B', i='1T', w='[False, False, True, False, False, False, False]', o='09:30:00', c='16:00:00')\n",
      "\n",
      "basefreq= 1 days 00:00:00\n",
      "basefreq.days= 1\n",
      "weekmask= [True, True, True, True, True, False, False]\n",
      "\n",
      "vc(value counts)=\n",
      "1 days    2649\n",
      "3 days     608\n",
      "4 days      90\n",
      "2 days      29\n",
      "5 days       2\n",
      "Name: Date, dtype: int64\n",
      "ifreq = None \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/yahoofinance-AAPL-20040819-20180120.csv ===\n",
      "TimeSeriesFrequency(d='B', i='None', w='[True, True, True, True, True, False, False]', o='09:30:00', c='16:00:00')\n",
      "\n",
      "basefreq= 0 days 00:01:00\n",
      "basefreq.days= 0\n",
      "weekmask= [False, False, True, False, False, False, False]\n",
      "Date\n",
      "2019-11-06 09:45:00   2019-11-06 09:45:00\n",
      "2019-11-06 09:46:00   2019-11-06 09:46:00\n",
      "2019-11-06 09:47:00   2019-11-06 09:47:00\n",
      "2019-11-06 15:58:00   2019-11-06 15:58:00\n",
      "2019-11-06 15:59:00   2019-11-06 15:59:00\n",
      "2019-11-06 16:00:00   2019-11-06 16:00:00\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "\n",
      "vc(value counts)=\n",
      "0 days 00:01:00    375\n",
      "Name: Date, dtype: int64\n",
      "ifreq = 1T \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/SP500_20191106_IDayBollTweak.csv ===\n",
      "TimeSeriesFrequency(d='B', i='1T', w='[False, False, True, False, False, False, False]', o='09:45:00', c='16:00:00')\n",
      "\n",
      "basefreq= 1 days 00:00:00\n",
      "basefreq.days= 1\n",
      "weekmask= [True, True, True, True, True, False, False]\n",
      "\n",
      "vc(value counts)=\n",
      "1 days    1975\n",
      "3 days     453\n",
      "4 days      67\n",
      "2 days      22\n",
      "5 days       1\n",
      "Name: Date, dtype: int64\n",
      "ifreq = None \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/yahoofinance-SPY-20080101-20180101.csv ===\n",
      "TimeSeriesFrequency(d='B', i='None', w='[True, True, True, True, True, False, False]', o='09:30:00', c='16:00:00')\n",
      "\n",
      "basefreq= 0 days 00:01:00\n",
      "basefreq.days= 0\n",
      "weekmask= [False, True, True, True, True, False, False]\n",
      "Date\n",
      "2019-11-05 09:30:00   2019-11-05 09:30:00\n",
      "2019-11-05 09:31:00   2019-11-05 09:31:00\n",
      "2019-11-05 09:32:00   2019-11-05 09:32:00\n",
      "2019-11-08 15:57:00   2019-11-08 15:57:00\n",
      "2019-11-08 15:58:00   2019-11-08 15:58:00\n",
      "2019-11-08 15:59:00   2019-11-08 15:59:00\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "\n",
      "vc(value counts)=\n",
      "0 days 00:01:00    1559\n",
      "0 days 17:30:00       3\n",
      "Name: Date, dtype: int64\n",
      "ifreq = 1T \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/SP500_NOV2019_IDayRVol.csv ===\n",
      "TimeSeriesFrequency(d='B', i='1T', w='[False, True, True, True, True, False, False]', o='09:30:00', c='16:00:00')\n",
      "\n",
      "basefreq= 1 days 00:00:00\n",
      "basefreq.days= 1\n",
      "weekmask= [True, True, True, True, True, False, False]\n",
      "\n",
      "vc(value counts)=\n",
      "1 days    410\n",
      "3 days    104\n",
      "2 days      4\n",
      "Name: Time, dtype: int64\n",
      "ifreq = None \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/jpyusd_barchartdotcom.csv ===\n",
      "TimeSeriesFrequency(d='B', i='None', w='[True, True, True, True, True, False, False]', o='09:30:00', c='16:00:00')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fn in files:\n",
    "    df = pd.read_csv(fn,index_col=0,parse_dates=True)\n",
    "    tf = ditf.DateIlocTransform(df.index)\n",
    "    \n",
    "    print('===',fn,'===')\n",
    "    print(tf._inferred_frequency)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ../data/alphavantage_demodata.csv ===\n",
      "weekmask= [True, True, True, True, True, False, False] True= 5\n",
      "\n",
      "=== ../data/yahoofinance-GOOG-20040819-20180120.csv ===\n",
      "weekmask= [True, True, True, True, True, False, False] True= 5\n",
      "\n",
      "=== ../data/SPY_20110701_20120630_Bollinger.csv ===\n",
      "weekmask= [True, True, True, True, True, False, False] True= 5\n",
      "\n",
      "=== ../data/SP500_NOV2019_IDay.csv ===\n",
      "weekmask= [False, True, True, True, True, False, False] True= 4\n",
      "\n",
      "=== ../data/yahoofinance-INTC-19950101-20040412.csv ===\n",
      "weekmask= [True, True, True, True, True, False, False] True= 5\n",
      "\n",
      "=== ../data/SP500_NOV2019_Hist.csv ===\n",
      "weekmask= [True, True, True, True, True, False, False] True= 5\n",
      "\n",
      "=== ../data/yahoofinance-SPY-20200901-20210113.csv ===\n",
      "weekmask= [True, True, True, True, True, False, False] True= 5\n",
      "\n",
      "=== ../data/SP500_20191106_IDayBollinger.csv ===\n",
      "weekmask= [False, False, True, False, False, False, False] True= 1\n",
      "\n",
      "=== ../data/yahoofinance-AAPL-20040819-20180120.csv ===\n",
      "weekmask= [True, True, True, True, True, False, False] True= 5\n",
      "\n",
      "=== ../data/SP500_20191106_IDayBollTweak.csv ===\n",
      "weekmask= [False, False, True, False, False, False, False] True= 1\n",
      "\n",
      "=== ../data/yahoofinance-SPY-20080101-20180101.csv ===\n",
      "weekmask= [True, True, True, True, True, False, False] True= 5\n",
      "\n",
      "=== ../data/SP500_NOV2019_IDayRVol.csv ===\n",
      "weekmask= [False, True, True, True, True, False, False] True= 4\n",
      "\n",
      "=== ../data/jpyusd_barchartdotcom.csv ===\n",
      "weekmask= [True, True, True, True, True, False, False] True= 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fn in files:\n",
    "    df = pd.read_csv(fn,index_col=0,parse_dates=True)\n",
    "    #tf = ditf.DateIlocTransform(df.index)\n",
    "    wm = ditf.DateIlocTransform.infer_weekmask(df.index)    \n",
    "    print('===',fn,'===')\n",
    "    print('weekmask=',wm, 'True=',wm.count(True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-a6774c8535dd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-a6774c8535dd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    STOP HERE\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_transform(fn):\n",
    "    df = pd.read_csv(fn,index_col=0,parse_dates=True)\n",
    "    tf = ditf.DateIlocTransform(df.index)\n",
    "    \n",
    "    print('===',fn,'===')\n",
    "    print('Inspect_transform: Inferred Frequency=')\n",
    "    print(tf._inferred_frequency)\n",
    "    print()\n",
    "    \n",
    "    new_dtix = tf.time_series_index(start=df.index[0],\n",
    "                                    end=df.index[-1],\n",
    "                                    freq=tf._inferred_frequency\n",
    "                                   )\n",
    "    orig_dtix = df.index\n",
    "    ldiff = len(orig_dtix) - len(new_dtix)\n",
    "    if ldiff != 0:\n",
    "        print('ldiff=',ldiff,\n",
    "              'len(orig_dtix)=',len(orig_dtix),\n",
    "              'len(new_dtix)=',len(new_dtix)\n",
    "             )\n",
    "        minix = min(len(orig_dtix),len(new_dtix))\n",
    "        orig_dtix = orig_dtix[0:minix]\n",
    "        new_dtix  = new_dtix[0:minix]\n",
    "    if not all(orig_dtix == new_dtix):\n",
    "        #print('orig_dtix=',orig_dtix)\n",
    "        #print(' new_dtix=',new_dtix)\n",
    "        print('In Orig but not in New :')\n",
    "        orig_not_new = list(set(orig_dtix)-set(new_dtix))\n",
    "        orig_not_new.sort()\n",
    "        pp.pprint(orig_not_new)\n",
    "        print('In New  but not in Orig:')\n",
    "        new_not_orig = list(set(new_dtix)-set(orig_dtix))\n",
    "        new_not_orig.sort()\n",
    "        pp.pprint(new_not_orig)\n",
    "    return orig_dtix,new_dtix,orig_not_new,new_not_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'../data/yahoofinance-GOOG-20040819-20180120.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)\n",
    "files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basefreq= 0 days 00:05:00\n",
      "basefreq.days= 0\n",
      "weekmask= [True, True, True, True, True, False, False]\n",
      "Date\n",
      "2022-04-18 04:35:00   2022-04-18 04:35:00\n",
      "2022-04-18 07:05:00   2022-04-18 07:05:00\n",
      "2022-04-18 07:10:00   2022-04-18 07:10:00\n",
      "2022-05-13 17:10:00   2022-05-13 17:10:00\n",
      "2022-05-13 17:25:00   2022-05-13 17:25:00\n",
      "2022-05-13 18:10:00   2022-05-13 18:10:00\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "\n",
      "vc(value counts)=\n",
      "0 days 00:05:00    1928\n",
      "0 days 00:10:00     117\n",
      "0 days 00:15:00      58\n",
      "0 days 00:20:00      37\n",
      "0 days 00:25:00      24\n",
      "0 days 00:30:00      14\n",
      "0 days 00:35:00      11\n",
      "0 days 00:40:00       8\n",
      "0 days 00:55:00       6\n",
      "0 days 00:45:00       6\n",
      "Name: Date, dtype: int64\n",
      "ifreq = 5T \n",
      "\n",
      "dfreq = B \n",
      "\n",
      "=== ../data/alphavantage_demodata.csv ===\n",
      "Inspect_transform: Inferred Frequency=\n",
      "TimeSeriesFrequency(d='B', i='5T', w='[True, True, True, True, True, False, False]', o='04:05:00', c='20:00:00')\n",
      "\n",
      "start= 2022-04-18 04:35:00  end= 2022-05-13 18:10:00\n",
      "bday_freq= B  iday_freq= 5T  weekmask= None\n",
      "open_time= 04:05:00  close_time= 20:00:00\n",
      "ldiff= -1554 len(orig_dtix)= 2258 len(new_dtix)= 3812\n",
      "In Orig but not in New :\n",
      "[   Timestamp('2022-05-03 17:05:00'),\n",
      "    Timestamp('2022-05-03 17:25:00'),\n",
      "    Timestamp('2022-05-03 17:45:00'),\n",
      "    Timestamp('2022-05-03 18:15:00'),\n",
      "    Timestamp('2022-05-03 19:30:00'),\n",
      "    Timestamp('2022-05-04 07:05:00'),\n",
      "    Timestamp('2022-05-04 07:10:00'),\n",
      "    Timestamp('2022-05-04 07:20:00'),\n",
      "    Timestamp('2022-05-04 07:50:00'),\n",
      "    Timestamp('2022-05-04 08:05:00'),\n",
      "    Timestamp('2022-05-04 08:30:00'),\n",
      "    Timestamp('2022-05-04 08:45:00'),\n",
      "    Timestamp('2022-05-04 08:55:00'),\n",
      "    Timestamp('2022-05-04 09:20:00'),\n",
      "    Timestamp('2022-05-04 09:35:00'),\n",
      "    Timestamp('2022-05-04 09:40:00'),\n",
      "    Timestamp('2022-05-04 09:45:00'),\n",
      "    Timestamp('2022-05-04 09:50:00'),\n",
      "    Timestamp('2022-05-04 09:55:00'),\n",
      "    Timestamp('2022-05-04 10:00:00'),\n",
      "    Timestamp('2022-05-04 10:05:00'),\n",
      "    Timestamp('2022-05-04 10:10:00'),\n",
      "    Timestamp('2022-05-04 10:15:00'),\n",
      "    Timestamp('2022-05-04 10:20:00'),\n",
      "    Timestamp('2022-05-04 10:25:00'),\n",
      "    Timestamp('2022-05-04 10:30:00'),\n",
      "    Timestamp('2022-05-04 10:35:00'),\n",
      "    Timestamp('2022-05-04 10:40:00'),\n",
      "    Timestamp('2022-05-04 10:45:00'),\n",
      "    Timestamp('2022-05-04 10:50:00'),\n",
      "    Timestamp('2022-05-04 10:55:00'),\n",
      "    Timestamp('2022-05-04 11:00:00'),\n",
      "    Timestamp('2022-05-04 11:05:00'),\n",
      "    Timestamp('2022-05-04 11:10:00'),\n",
      "    Timestamp('2022-05-04 11:15:00'),\n",
      "    Timestamp('2022-05-04 11:20:00'),\n",
      "    Timestamp('2022-05-04 11:25:00'),\n",
      "    Timestamp('2022-05-04 11:30:00'),\n",
      "    Timestamp('2022-05-04 11:35:00'),\n",
      "    Timestamp('2022-05-04 11:40:00'),\n",
      "    Timestamp('2022-05-04 11:45:00'),\n",
      "    Timestamp('2022-05-04 11:50:00'),\n",
      "    Timestamp('2022-05-04 11:55:00'),\n",
      "    Timestamp('2022-05-04 12:00:00'),\n",
      "    Timestamp('2022-05-04 12:05:00'),\n",
      "    Timestamp('2022-05-04 12:10:00'),\n",
      "    Timestamp('2022-05-04 12:15:00'),\n",
      "    Timestamp('2022-05-04 12:20:00'),\n",
      "    Timestamp('2022-05-04 12:25:00'),\n",
      "    Timestamp('2022-05-04 12:30:00'),\n",
      "    Timestamp('2022-05-04 12:35:00'),\n",
      "    Timestamp('2022-05-04 12:40:00'),\n",
      "    Timestamp('2022-05-04 12:45:00'),\n",
      "    Timestamp('2022-05-04 12:50:00'),\n",
      "    Timestamp('2022-05-04 12:55:00'),\n",
      "    Timestamp('2022-05-04 13:00:00'),\n",
      "    Timestamp('2022-05-04 13:05:00'),\n",
      "    Timestamp('2022-05-04 13:10:00'),\n",
      "    Timestamp('2022-05-04 13:15:00'),\n",
      "    Timestamp('2022-05-04 13:20:00'),\n",
      "    Timestamp('2022-05-04 13:25:00'),\n",
      "    Timestamp('2022-05-04 13:30:00'),\n",
      "    Timestamp('2022-05-04 13:35:00'),\n",
      "    Timestamp('2022-05-04 13:40:00'),\n",
      "    Timestamp('2022-05-04 13:45:00'),\n",
      "    Timestamp('2022-05-04 13:50:00'),\n",
      "    Timestamp('2022-05-04 13:55:00'),\n",
      "    Timestamp('2022-05-04 14:00:00'),\n",
      "    Timestamp('2022-05-04 14:05:00'),\n",
      "    Timestamp('2022-05-04 14:10:00'),\n",
      "    Timestamp('2022-05-04 14:15:00'),\n",
      "    Timestamp('2022-05-04 14:20:00'),\n",
      "    Timestamp('2022-05-04 14:25:00'),\n",
      "    Timestamp('2022-05-04 14:30:00'),\n",
      "    Timestamp('2022-05-04 14:35:00'),\n",
      "    Timestamp('2022-05-04 14:40:00'),\n",
      "    Timestamp('2022-05-04 14:45:00'),\n",
      "    Timestamp('2022-05-04 14:50:00'),\n",
      "    Timestamp('2022-05-04 14:55:00'),\n",
      "    Timestamp('2022-05-04 15:00:00'),\n",
      "    Timestamp('2022-05-04 15:05:00'),\n",
      "    Timestamp('2022-05-04 15:10:00'),\n",
      "    Timestamp('2022-05-04 15:15:00'),\n",
      "    Timestamp('2022-05-04 15:20:00'),\n",
      "    Timestamp('2022-05-04 15:25:00'),\n",
      "    Timestamp('2022-05-04 15:30:00'),\n",
      "    Timestamp('2022-05-04 15:35:00'),\n",
      "    Timestamp('2022-05-04 15:40:00'),\n",
      "    Timestamp('2022-05-04 15:45:00'),\n",
      "    Timestamp('2022-05-04 15:50:00'),\n",
      "    Timestamp('2022-05-04 15:55:00'),\n",
      "    Timestamp('2022-05-04 16:00:00'),\n",
      "    Timestamp('2022-05-04 16:05:00'),\n",
      "    Timestamp('2022-05-04 16:10:00'),\n",
      "    Timestamp('2022-05-04 16:15:00'),\n",
      "    Timestamp('2022-05-04 16:25:00'),\n",
      "    Timestamp('2022-05-04 16:30:00'),\n",
      "    Timestamp('2022-05-04 17:05:00'),\n",
      "    Timestamp('2022-05-04 17:10:00'),\n",
      "    Timestamp('2022-05-04 17:25:00'),\n",
      "    Timestamp('2022-05-04 17:45:00'),\n",
      "    Timestamp('2022-05-04 18:10:00'),\n",
      "    Timestamp('2022-05-04 18:40:00'),\n",
      "    Timestamp('2022-05-04 18:45:00'),\n",
      "    Timestamp('2022-05-04 18:50:00'),\n",
      "    Timestamp('2022-05-04 19:05:00'),\n",
      "    Timestamp('2022-05-04 19:10:00'),\n",
      "    Timestamp('2022-05-04 20:00:00'),\n",
      "    Timestamp('2022-05-05 07:05:00'),\n",
      "    Timestamp('2022-05-05 07:30:00'),\n",
      "    Timestamp('2022-05-05 08:00:00'),\n",
      "    Timestamp('2022-05-05 08:05:00'),\n",
      "    Timestamp('2022-05-05 08:20:00'),\n",
      "    Timestamp('2022-05-05 08:25:00'),\n",
      "    Timestamp('2022-05-05 08:45:00'),\n",
      "    Timestamp('2022-05-05 09:00:00'),\n",
      "    Timestamp('2022-05-05 09:10:00'),\n",
      "    Timestamp('2022-05-05 09:20:00'),\n",
      "    Timestamp('2022-05-05 09:30:00'),\n",
      "    Timestamp('2022-05-05 09:35:00'),\n",
      "    Timestamp('2022-05-05 09:40:00'),\n",
      "    Timestamp('2022-05-05 09:45:00'),\n",
      "    Timestamp('2022-05-05 09:50:00'),\n",
      "    Timestamp('2022-05-05 09:55:00'),\n",
      "    Timestamp('2022-05-05 10:00:00'),\n",
      "    Timestamp('2022-05-05 10:05:00'),\n",
      "    Timestamp('2022-05-05 10:10:00'),\n",
      "    Timestamp('2022-05-05 10:15:00'),\n",
      "    Timestamp('2022-05-05 10:20:00'),\n",
      "    Timestamp('2022-05-05 10:25:00'),\n",
      "    Timestamp('2022-05-05 10:30:00'),\n",
      "    Timestamp('2022-05-05 10:35:00'),\n",
      "    Timestamp('2022-05-05 10:40:00'),\n",
      "    Timestamp('2022-05-05 10:45:00'),\n",
      "    Timestamp('2022-05-05 10:50:00'),\n",
      "    Timestamp('2022-05-05 10:55:00'),\n",
      "    Timestamp('2022-05-05 11:00:00'),\n",
      "    Timestamp('2022-05-05 11:05:00'),\n",
      "    Timestamp('2022-05-05 11:10:00'),\n",
      "    Timestamp('2022-05-05 11:15:00'),\n",
      "    Timestamp('2022-05-05 11:20:00'),\n",
      "    Timestamp('2022-05-05 11:25:00'),\n",
      "    Timestamp('2022-05-05 11:30:00'),\n",
      "    Timestamp('2022-05-05 11:35:00'),\n",
      "    Timestamp('2022-05-05 11:40:00'),\n",
      "    Timestamp('2022-05-05 11:45:00'),\n",
      "    Timestamp('2022-05-05 11:50:00'),\n",
      "    Timestamp('2022-05-05 11:55:00'),\n",
      "    Timestamp('2022-05-05 12:00:00'),\n",
      "    Timestamp('2022-05-05 12:05:00'),\n",
      "    Timestamp('2022-05-05 12:10:00'),\n",
      "    Timestamp('2022-05-05 12:15:00'),\n",
      "    Timestamp('2022-05-05 12:20:00'),\n",
      "    Timestamp('2022-05-05 12:25:00'),\n",
      "    Timestamp('2022-05-05 12:30:00'),\n",
      "    Timestamp('2022-05-05 12:35:00'),\n",
      "    Timestamp('2022-05-05 12:40:00'),\n",
      "    Timestamp('2022-05-05 12:45:00'),\n",
      "    Timestamp('2022-05-05 12:50:00'),\n",
      "    Timestamp('2022-05-05 12:55:00'),\n",
      "    Timestamp('2022-05-05 13:00:00'),\n",
      "    Timestamp('2022-05-05 13:05:00'),\n",
      "    Timestamp('2022-05-05 13:10:00'),\n",
      "    Timestamp('2022-05-05 13:15:00'),\n",
      "    Timestamp('2022-05-05 13:20:00'),\n",
      "    Timestamp('2022-05-05 13:25:00'),\n",
      "    Timestamp('2022-05-05 13:30:00'),\n",
      "    Timestamp('2022-05-05 13:35:00'),\n",
      "    Timestamp('2022-05-05 13:40:00'),\n",
      "    Timestamp('2022-05-05 13:45:00'),\n",
      "    Timestamp('2022-05-05 13:50:00'),\n",
      "    Timestamp('2022-05-05 13:55:00'),\n",
      "    Timestamp('2022-05-05 14:00:00'),\n",
      "    Timestamp('2022-05-05 14:05:00'),\n",
      "    Timestamp('2022-05-05 14:10:00'),\n",
      "    Timestamp('2022-05-05 14:15:00'),\n",
      "    Timestamp('2022-05-05 14:20:00'),\n",
      "    Timestamp('2022-05-05 14:25:00'),\n",
      "    Timestamp('2022-05-05 14:30:00'),\n",
      "    Timestamp('2022-05-05 14:35:00'),\n",
      "    Timestamp('2022-05-05 14:40:00'),\n",
      "    Timestamp('2022-05-05 14:45:00'),\n",
      "    Timestamp('2022-05-05 14:50:00'),\n",
      "    Timestamp('2022-05-05 14:55:00'),\n",
      "    Timestamp('2022-05-05 15:00:00'),\n",
      "    Timestamp('2022-05-05 15:05:00'),\n",
      "    Timestamp('2022-05-05 15:10:00'),\n",
      "    Timestamp('2022-05-05 15:15:00'),\n",
      "    Timestamp('2022-05-05 15:20:00'),\n",
      "    Timestamp('2022-05-05 15:25:00'),\n",
      "    Timestamp('2022-05-05 15:30:00'),\n",
      "    Timestamp('2022-05-05 15:35:00'),\n",
      "    Timestamp('2022-05-05 15:40:00'),\n",
      "    Timestamp('2022-05-05 15:45:00'),\n",
      "    Timestamp('2022-05-05 15:50:00'),\n",
      "    Timestamp('2022-05-05 15:55:00'),\n",
      "    Timestamp('2022-05-05 16:00:00'),\n",
      "    Timestamp('2022-05-05 16:05:00'),\n",
      "    Timestamp('2022-05-05 16:10:00'),\n",
      "    Timestamp('2022-05-05 16:15:00'),\n",
      "    Timestamp('2022-05-05 16:20:00'),\n",
      "    Timestamp('2022-05-05 16:35:00'),\n",
      "    Timestamp('2022-05-05 16:40:00'),\n",
      "    Timestamp('2022-05-05 16:45:00'),\n",
      "    Timestamp('2022-05-05 16:50:00'),\n",
      "    Timestamp('2022-05-05 16:55:00'),\n",
      "    Timestamp('2022-05-05 18:05:00'),\n",
      "    Timestamp('2022-05-05 18:10:00'),\n",
      "    Timestamp('2022-05-05 18:25:00'),\n",
      "    Timestamp('2022-05-05 18:50:00'),\n",
      "    Timestamp('2022-05-05 19:05:00'),\n",
      "    Timestamp('2022-05-05 19:15:00'),\n",
      "    Timestamp('2022-05-06 04:10:00'),\n",
      "    Timestamp('2022-05-06 07:35:00'),\n",
      "    Timestamp('2022-05-06 08:05:00'),\n",
      "    Timestamp('2022-05-06 08:35:00'),\n",
      "    Timestamp('2022-05-06 09:35:00'),\n",
      "    Timestamp('2022-05-06 09:40:00'),\n",
      "    Timestamp('2022-05-06 09:45:00'),\n",
      "    Timestamp('2022-05-06 09:50:00'),\n",
      "    Timestamp('2022-05-06 09:55:00'),\n",
      "    Timestamp('2022-05-06 10:00:00'),\n",
      "    Timestamp('2022-05-06 10:05:00'),\n",
      "    Timestamp('2022-05-06 10:10:00'),\n",
      "    Timestamp('2022-05-06 10:15:00'),\n",
      "    Timestamp('2022-05-06 10:20:00'),\n",
      "    Timestamp('2022-05-06 10:25:00'),\n",
      "    Timestamp('2022-05-06 10:30:00'),\n",
      "    Timestamp('2022-05-06 10:35:00'),\n",
      "    Timestamp('2022-05-06 10:40:00'),\n",
      "    Timestamp('2022-05-06 10:45:00'),\n",
      "    Timestamp('2022-05-06 10:50:00'),\n",
      "    Timestamp('2022-05-06 10:55:00'),\n",
      "    Timestamp('2022-05-06 11:00:00'),\n",
      "    Timestamp('2022-05-06 11:05:00'),\n",
      "    Timestamp('2022-05-06 11:10:00'),\n",
      "    Timestamp('2022-05-06 11:15:00'),\n",
      "    Timestamp('2022-05-06 11:20:00'),\n",
      "    Timestamp('2022-05-06 11:25:00'),\n",
      "    Timestamp('2022-05-06 11:30:00'),\n",
      "    Timestamp('2022-05-06 11:35:00'),\n",
      "    Timestamp('2022-05-06 11:40:00'),\n",
      "    Timestamp('2022-05-06 11:45:00'),\n",
      "    Timestamp('2022-05-06 11:50:00'),\n",
      "    Timestamp('2022-05-06 11:55:00'),\n",
      "    Timestamp('2022-05-06 12:00:00'),\n",
      "    Timestamp('2022-05-06 12:05:00'),\n",
      "    Timestamp('2022-05-06 12:10:00'),\n",
      "    Timestamp('2022-05-06 12:15:00'),\n",
      "    Timestamp('2022-05-06 12:20:00'),\n",
      "    Timestamp('2022-05-06 12:25:00'),\n",
      "    Timestamp('2022-05-06 12:30:00'),\n",
      "    Timestamp('2022-05-06 12:35:00'),\n",
      "    Timestamp('2022-05-06 12:40:00'),\n",
      "    Timestamp('2022-05-06 12:45:00'),\n",
      "    Timestamp('2022-05-06 12:50:00'),\n",
      "    Timestamp('2022-05-06 12:55:00'),\n",
      "    Timestamp('2022-05-06 13:00:00'),\n",
      "    Timestamp('2022-05-06 13:05:00'),\n",
      "    Timestamp('2022-05-06 13:10:00'),\n",
      "    Timestamp('2022-05-06 13:15:00'),\n",
      "    Timestamp('2022-05-06 13:20:00'),\n",
      "    Timestamp('2022-05-06 13:25:00'),\n",
      "    Timestamp('2022-05-06 13:30:00'),\n",
      "    Timestamp('2022-05-06 13:35:00'),\n",
      "    Timestamp('2022-05-06 13:40:00'),\n",
      "    Timestamp('2022-05-06 13:45:00'),\n",
      "    Timestamp('2022-05-06 13:50:00'),\n",
      "    Timestamp('2022-05-06 13:55:00'),\n",
      "    Timestamp('2022-05-06 14:00:00'),\n",
      "    Timestamp('2022-05-06 14:05:00'),\n",
      "    Timestamp('2022-05-06 14:10:00'),\n",
      "    Timestamp('2022-05-06 14:15:00'),\n",
      "    Timestamp('2022-05-06 14:20:00'),\n",
      "    Timestamp('2022-05-06 14:25:00'),\n",
      "    Timestamp('2022-05-06 14:30:00'),\n",
      "    Timestamp('2022-05-06 14:35:00'),\n",
      "    Timestamp('2022-05-06 14:40:00'),\n",
      "    Timestamp('2022-05-06 14:45:00'),\n",
      "    Timestamp('2022-05-06 14:50:00'),\n",
      "    Timestamp('2022-05-06 14:55:00'),\n",
      "    Timestamp('2022-05-06 15:00:00'),\n",
      "    Timestamp('2022-05-06 15:05:00'),\n",
      "    Timestamp('2022-05-06 15:10:00'),\n",
      "    Timestamp('2022-05-06 15:15:00'),\n",
      "    Timestamp('2022-05-06 15:20:00'),\n",
      "    Timestamp('2022-05-06 15:25:00'),\n",
      "    Timestamp('2022-05-06 15:30:00'),\n",
      "    Timestamp('2022-05-06 15:35:00'),\n",
      "    Timestamp('2022-05-06 15:40:00'),\n",
      "    Timestamp('2022-05-06 15:45:00'),\n",
      "    Timestamp('2022-05-06 15:50:00'),\n",
      "    Timestamp('2022-05-06 15:55:00'),\n",
      "    Timestamp('2022-05-06 16:00:00'),\n",
      "    Timestamp('2022-05-06 16:05:00'),\n",
      "    Timestamp('2022-05-06 16:10:00'),\n",
      "    Timestamp('2022-05-06 16:15:00'),\n",
      "    Timestamp('2022-05-06 16:20:00'),\n",
      "    Timestamp('2022-05-06 16:25:00'),\n",
      "    Timestamp('2022-05-06 16:50:00'),\n",
      "    Timestamp('2022-05-06 17:25:00'),\n",
      "    Timestamp('2022-05-06 17:30:00'),\n",
      "    Timestamp('2022-05-06 17:35:00'),\n",
      "    Timestamp('2022-05-06 18:30:00'),\n",
      "    Timestamp('2022-05-06 18:40:00'),\n",
      "    Timestamp('2022-05-06 18:45:00'),\n",
      "    Timestamp('2022-05-06 18:55:00'),\n",
      "    Timestamp('2022-05-06 19:55:00'),\n",
      "    Timestamp('2022-05-06 20:00:00'),\n",
      "    Timestamp('2022-05-09 04:05:00'),\n",
      "    Timestamp('2022-05-09 04:35:00'),\n",
      "    Timestamp('2022-05-09 05:00:00'),\n",
      "    Timestamp('2022-05-09 06:05:00'),\n",
      "    Timestamp('2022-05-09 06:45:00'),\n",
      "    Timestamp('2022-05-09 06:50:00'),\n",
      "    Timestamp('2022-05-09 07:00:00'),\n",
      "    Timestamp('2022-05-09 07:05:00'),\n",
      "    Timestamp('2022-05-09 07:10:00'),\n",
      "    Timestamp('2022-05-09 07:15:00'),\n",
      "    Timestamp('2022-05-09 07:25:00'),\n",
      "    Timestamp('2022-05-09 07:30:00'),\n",
      "    Timestamp('2022-05-09 07:40:00'),\n",
      "    Timestamp('2022-05-09 07:45:00'),\n",
      "    Timestamp('2022-05-09 07:50:00'),\n",
      "    Timestamp('2022-05-09 08:00:00'),\n",
      "    Timestamp('2022-05-09 08:05:00'),\n",
      "    Timestamp('2022-05-09 08:10:00'),\n",
      "    Timestamp('2022-05-09 08:15:00'),\n",
      "    Timestamp('2022-05-09 08:30:00'),\n",
      "    Timestamp('2022-05-09 08:35:00'),\n",
      "    Timestamp('2022-05-09 08:40:00'),\n",
      "    Timestamp('2022-05-09 08:45:00'),\n",
      "    Timestamp('2022-05-09 08:50:00'),\n",
      "    Timestamp('2022-05-09 08:55:00'),\n",
      "    Timestamp('2022-05-09 09:00:00'),\n",
      "    Timestamp('2022-05-09 09:05:00'),\n",
      "    Timestamp('2022-05-09 09:10:00'),\n",
      "    Timestamp('2022-05-09 09:15:00'),\n",
      "    Timestamp('2022-05-09 09:20:00'),\n",
      "    Timestamp('2022-05-09 09:30:00'),\n",
      "    Timestamp('2022-05-09 09:35:00'),\n",
      "    Timestamp('2022-05-09 09:40:00'),\n",
      "    Timestamp('2022-05-09 09:45:00'),\n",
      "    Timestamp('2022-05-09 09:50:00'),\n",
      "    Timestamp('2022-05-09 09:55:00'),\n",
      "    Timestamp('2022-05-09 10:00:00'),\n",
      "    Timestamp('2022-05-09 10:05:00'),\n",
      "    Timestamp('2022-05-09 10:10:00'),\n",
      "    Timestamp('2022-05-09 10:15:00'),\n",
      "    Timestamp('2022-05-09 10:20:00'),\n",
      "    Timestamp('2022-05-09 10:25:00'),\n",
      "    Timestamp('2022-05-09 10:30:00'),\n",
      "    Timestamp('2022-05-09 10:35:00'),\n",
      "    Timestamp('2022-05-09 10:40:00'),\n",
      "    Timestamp('2022-05-09 10:45:00'),\n",
      "    Timestamp('2022-05-09 10:50:00'),\n",
      "    Timestamp('2022-05-09 10:55:00'),\n",
      "    Timestamp('2022-05-09 11:00:00'),\n",
      "    Timestamp('2022-05-09 11:05:00'),\n",
      "    Timestamp('2022-05-09 11:10:00'),\n",
      "    Timestamp('2022-05-09 11:15:00'),\n",
      "    Timestamp('2022-05-09 11:20:00'),\n",
      "    Timestamp('2022-05-09 11:25:00'),\n",
      "    Timestamp('2022-05-09 11:30:00'),\n",
      "    Timestamp('2022-05-09 11:35:00'),\n",
      "    Timestamp('2022-05-09 11:40:00'),\n",
      "    Timestamp('2022-05-09 11:45:00'),\n",
      "    Timestamp('2022-05-09 11:50:00'),\n",
      "    Timestamp('2022-05-09 11:55:00'),\n",
      "    Timestamp('2022-05-09 12:00:00'),\n",
      "    Timestamp('2022-05-09 12:05:00'),\n",
      "    Timestamp('2022-05-09 12:10:00'),\n",
      "    Timestamp('2022-05-09 12:15:00'),\n",
      "    Timestamp('2022-05-09 12:20:00'),\n",
      "    Timestamp('2022-05-09 12:25:00'),\n",
      "    Timestamp('2022-05-09 12:30:00'),\n",
      "    Timestamp('2022-05-09 12:35:00'),\n",
      "    Timestamp('2022-05-09 12:40:00'),\n",
      "    Timestamp('2022-05-09 12:45:00'),\n",
      "    Timestamp('2022-05-09 12:50:00'),\n",
      "    Timestamp('2022-05-09 12:55:00'),\n",
      "    Timestamp('2022-05-09 13:00:00'),\n",
      "    Timestamp('2022-05-09 13:05:00'),\n",
      "    Timestamp('2022-05-09 13:10:00'),\n",
      "    Timestamp('2022-05-09 13:15:00'),\n",
      "    Timestamp('2022-05-09 13:20:00'),\n",
      "    Timestamp('2022-05-09 13:25:00'),\n",
      "    Timestamp('2022-05-09 13:30:00'),\n",
      "    Timestamp('2022-05-09 13:35:00'),\n",
      "    Timestamp('2022-05-09 13:40:00'),\n",
      "    Timestamp('2022-05-09 13:45:00'),\n",
      "    Timestamp('2022-05-09 13:50:00'),\n",
      "    Timestamp('2022-05-09 13:55:00'),\n",
      "    Timestamp('2022-05-09 14:00:00'),\n",
      "    Timestamp('2022-05-09 14:05:00'),\n",
      "    Timestamp('2022-05-09 14:10:00'),\n",
      "    Timestamp('2022-05-09 14:15:00'),\n",
      "    Timestamp('2022-05-09 14:20:00'),\n",
      "    Timestamp('2022-05-09 14:25:00'),\n",
      "    Timestamp('2022-05-09 14:30:00'),\n",
      "    Timestamp('2022-05-09 14:35:00'),\n",
      "    Timestamp('2022-05-09 14:40:00'),\n",
      "    Timestamp('2022-05-09 14:45:00'),\n",
      "    Timestamp('2022-05-09 14:50:00'),\n",
      "    Timestamp('2022-05-09 14:55:00'),\n",
      "    Timestamp('2022-05-09 15:00:00'),\n",
      "    Timestamp('2022-05-09 15:05:00'),\n",
      "    Timestamp('2022-05-09 15:10:00'),\n",
      "    Timestamp('2022-05-09 15:15:00'),\n",
      "    Timestamp('2022-05-09 15:20:00'),\n",
      "    Timestamp('2022-05-09 15:25:00'),\n",
      "    Timestamp('2022-05-09 15:30:00'),\n",
      "    Timestamp('2022-05-09 15:35:00'),\n",
      "    Timestamp('2022-05-09 15:40:00'),\n",
      "    Timestamp('2022-05-09 15:45:00'),\n",
      "    Timestamp('2022-05-09 15:50:00'),\n",
      "    Timestamp('2022-05-09 15:55:00'),\n",
      "    Timestamp('2022-05-09 16:00:00'),\n",
      "    Timestamp('2022-05-09 16:05:00'),\n",
      "    Timestamp('2022-05-09 16:15:00'),\n",
      "    Timestamp('2022-05-09 16:25:00'),\n",
      "    Timestamp('2022-05-09 16:30:00'),\n",
      "    Timestamp('2022-05-09 16:35:00'),\n",
      "    Timestamp('2022-05-09 16:45:00'),\n",
      "    Timestamp('2022-05-09 16:55:00'),\n",
      "    Timestamp('2022-05-09 17:10:00'),\n",
      "    Timestamp('2022-05-09 18:25:00'),\n",
      "    Timestamp('2022-05-09 18:50:00'),\n",
      "    Timestamp('2022-05-09 19:45:00'),\n",
      "    Timestamp('2022-05-09 19:55:00'),\n",
      "    Timestamp('2022-05-10 08:05:00'),\n",
      "    Timestamp('2022-05-10 08:15:00'),\n",
      "    Timestamp('2022-05-10 08:20:00'),\n",
      "    Timestamp('2022-05-10 08:35:00'),\n",
      "    Timestamp('2022-05-10 08:50:00'),\n",
      "    Timestamp('2022-05-10 08:55:00'),\n",
      "    Timestamp('2022-05-10 09:00:00'),\n",
      "    Timestamp('2022-05-10 09:10:00'),\n",
      "    Timestamp('2022-05-10 09:20:00'),\n",
      "    Timestamp('2022-05-10 09:25:00'),\n",
      "    Timestamp('2022-05-10 09:30:00'),\n",
      "    Timestamp('2022-05-10 09:35:00'),\n",
      "    Timestamp('2022-05-10 09:40:00'),\n",
      "    Timestamp('2022-05-10 09:45:00'),\n",
      "    Timestamp('2022-05-10 09:50:00'),\n",
      "    Timestamp('2022-05-10 09:55:00'),\n",
      "    Timestamp('2022-05-10 10:00:00'),\n",
      "    Timestamp('2022-05-10 10:05:00'),\n",
      "    Timestamp('2022-05-10 10:10:00'),\n",
      "    Timestamp('2022-05-10 10:15:00'),\n",
      "    Timestamp('2022-05-10 10:20:00'),\n",
      "    Timestamp('2022-05-10 10:25:00'),\n",
      "    Timestamp('2022-05-10 10:30:00'),\n",
      "    Timestamp('2022-05-10 10:35:00'),\n",
      "    Timestamp('2022-05-10 10:40:00'),\n",
      "    Timestamp('2022-05-10 10:45:00'),\n",
      "    Timestamp('2022-05-10 10:50:00'),\n",
      "    Timestamp('2022-05-10 10:55:00'),\n",
      "    Timestamp('2022-05-10 11:00:00'),\n",
      "    Timestamp('2022-05-10 11:05:00'),\n",
      "    Timestamp('2022-05-10 11:10:00'),\n",
      "    Timestamp('2022-05-10 11:15:00'),\n",
      "    Timestamp('2022-05-10 11:20:00'),\n",
      "    Timestamp('2022-05-10 11:25:00'),\n",
      "    Timestamp('2022-05-10 11:30:00'),\n",
      "    Timestamp('2022-05-10 11:35:00'),\n",
      "    Timestamp('2022-05-10 11:40:00'),\n",
      "    Timestamp('2022-05-10 11:45:00'),\n",
      "    Timestamp('2022-05-10 11:50:00'),\n",
      "    Timestamp('2022-05-10 11:55:00'),\n",
      "    Timestamp('2022-05-10 12:00:00'),\n",
      "    Timestamp('2022-05-10 12:05:00'),\n",
      "    Timestamp('2022-05-10 12:10:00'),\n",
      "    Timestamp('2022-05-10 12:15:00'),\n",
      "    Timestamp('2022-05-10 12:20:00'),\n",
      "    Timestamp('2022-05-10 12:25:00'),\n",
      "    Timestamp('2022-05-10 12:30:00'),\n",
      "    Timestamp('2022-05-10 12:35:00'),\n",
      "    Timestamp('2022-05-10 12:40:00'),\n",
      "    Timestamp('2022-05-10 12:45:00'),\n",
      "    Timestamp('2022-05-10 12:50:00'),\n",
      "    Timestamp('2022-05-10 12:55:00'),\n",
      "    Timestamp('2022-05-10 13:00:00'),\n",
      "    Timestamp('2022-05-10 13:05:00'),\n",
      "    Timestamp('2022-05-10 13:10:00'),\n",
      "    Timestamp('2022-05-10 13:15:00'),\n",
      "    Timestamp('2022-05-10 13:20:00'),\n",
      "    Timestamp('2022-05-10 13:25:00'),\n",
      "    Timestamp('2022-05-10 13:30:00'),\n",
      "    Timestamp('2022-05-10 13:35:00'),\n",
      "    Timestamp('2022-05-10 13:40:00'),\n",
      "    Timestamp('2022-05-10 13:45:00'),\n",
      "    Timestamp('2022-05-10 13:50:00'),\n",
      "    Timestamp('2022-05-10 13:55:00'),\n",
      "    Timestamp('2022-05-10 14:00:00'),\n",
      "    Timestamp('2022-05-10 14:05:00'),\n",
      "    Timestamp('2022-05-10 14:10:00'),\n",
      "    Timestamp('2022-05-10 14:15:00'),\n",
      "    Timestamp('2022-05-10 14:20:00'),\n",
      "    Timestamp('2022-05-10 14:25:00'),\n",
      "    Timestamp('2022-05-10 14:30:00'),\n",
      "    Timestamp('2022-05-10 14:35:00'),\n",
      "    Timestamp('2022-05-10 14:40:00'),\n",
      "    Timestamp('2022-05-10 14:45:00'),\n",
      "    Timestamp('2022-05-10 14:50:00'),\n",
      "    Timestamp('2022-05-10 14:55:00'),\n",
      "    Timestamp('2022-05-10 15:00:00'),\n",
      "    Timestamp('2022-05-10 15:05:00'),\n",
      "    Timestamp('2022-05-10 15:10:00'),\n",
      "    Timestamp('2022-05-10 15:15:00'),\n",
      "    Timestamp('2022-05-10 15:20:00'),\n",
      "    Timestamp('2022-05-10 15:25:00'),\n",
      "    Timestamp('2022-05-10 15:30:00'),\n",
      "    Timestamp('2022-05-10 15:35:00'),\n",
      "    Timestamp('2022-05-10 15:40:00'),\n",
      "    Timestamp('2022-05-10 15:45:00'),\n",
      "    Timestamp('2022-05-10 15:50:00'),\n",
      "    Timestamp('2022-05-10 15:55:00'),\n",
      "    Timestamp('2022-05-10 16:00:00'),\n",
      "    Timestamp('2022-05-10 16:05:00'),\n",
      "    Timestamp('2022-05-10 16:10:00'),\n",
      "    Timestamp('2022-05-10 16:15:00'),\n",
      "    Timestamp('2022-05-10 16:20:00'),\n",
      "    Timestamp('2022-05-10 16:30:00'),\n",
      "    Timestamp('2022-05-10 16:35:00'),\n",
      "    Timestamp('2022-05-10 16:50:00'),\n",
      "    Timestamp('2022-05-10 16:55:00'),\n",
      "    Timestamp('2022-05-10 17:05:00'),\n",
      "    Timestamp('2022-05-10 17:15:00'),\n",
      "    Timestamp('2022-05-10 17:20:00'),\n",
      "    Timestamp('2022-05-10 17:25:00'),\n",
      "    Timestamp('2022-05-10 17:30:00'),\n",
      "    Timestamp('2022-05-10 17:35:00'),\n",
      "    Timestamp('2022-05-10 18:15:00'),\n",
      "    Timestamp('2022-05-10 18:20:00'),\n",
      "    Timestamp('2022-05-10 18:25:00'),\n",
      "    Timestamp('2022-05-10 18:30:00'),\n",
      "    Timestamp('2022-05-10 18:35:00'),\n",
      "    Timestamp('2022-05-10 19:05:00'),\n",
      "    Timestamp('2022-05-10 19:20:00'),\n",
      "    Timestamp('2022-05-10 19:55:00'),\n",
      "    Timestamp('2022-05-10 20:00:00'),\n",
      "    Timestamp('2022-05-11 06:25:00'),\n",
      "    Timestamp('2022-05-11 06:35:00'),\n",
      "    Timestamp('2022-05-11 06:40:00'),\n",
      "    Timestamp('2022-05-11 07:05:00'),\n",
      "    Timestamp('2022-05-11 07:25:00'),\n",
      "    Timestamp('2022-05-11 07:50:00'),\n",
      "    Timestamp('2022-05-11 08:00:00'),\n",
      "    Timestamp('2022-05-11 08:05:00'),\n",
      "    Timestamp('2022-05-11 08:15:00'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Timestamp('2022-05-11 08:20:00'),\n",
      "    Timestamp('2022-05-11 08:25:00'),\n",
      "    Timestamp('2022-05-11 08:35:00'),\n",
      "    Timestamp('2022-05-11 08:40:00'),\n",
      "    Timestamp('2022-05-11 08:45:00'),\n",
      "    Timestamp('2022-05-11 08:55:00'),\n",
      "    Timestamp('2022-05-11 09:00:00'),\n",
      "    Timestamp('2022-05-11 09:05:00'),\n",
      "    Timestamp('2022-05-11 09:10:00'),\n",
      "    Timestamp('2022-05-11 09:20:00'),\n",
      "    Timestamp('2022-05-11 09:25:00'),\n",
      "    Timestamp('2022-05-11 09:30:00'),\n",
      "    Timestamp('2022-05-11 09:35:00'),\n",
      "    Timestamp('2022-05-11 09:40:00'),\n",
      "    Timestamp('2022-05-11 09:45:00'),\n",
      "    Timestamp('2022-05-11 09:50:00'),\n",
      "    Timestamp('2022-05-11 09:55:00'),\n",
      "    Timestamp('2022-05-11 10:00:00'),\n",
      "    Timestamp('2022-05-11 10:05:00'),\n",
      "    Timestamp('2022-05-11 10:10:00'),\n",
      "    Timestamp('2022-05-11 10:15:00'),\n",
      "    Timestamp('2022-05-11 10:20:00'),\n",
      "    Timestamp('2022-05-11 10:25:00'),\n",
      "    Timestamp('2022-05-11 10:30:00'),\n",
      "    Timestamp('2022-05-11 10:35:00'),\n",
      "    Timestamp('2022-05-11 10:40:00'),\n",
      "    Timestamp('2022-05-11 10:45:00'),\n",
      "    Timestamp('2022-05-11 10:50:00'),\n",
      "    Timestamp('2022-05-11 10:55:00'),\n",
      "    Timestamp('2022-05-11 11:00:00'),\n",
      "    Timestamp('2022-05-11 11:05:00'),\n",
      "    Timestamp('2022-05-11 11:10:00'),\n",
      "    Timestamp('2022-05-11 11:15:00'),\n",
      "    Timestamp('2022-05-11 11:20:00'),\n",
      "    Timestamp('2022-05-11 11:25:00'),\n",
      "    Timestamp('2022-05-11 11:30:00'),\n",
      "    Timestamp('2022-05-11 11:35:00'),\n",
      "    Timestamp('2022-05-11 11:40:00'),\n",
      "    Timestamp('2022-05-11 11:45:00'),\n",
      "    Timestamp('2022-05-11 11:50:00'),\n",
      "    Timestamp('2022-05-11 11:55:00'),\n",
      "    Timestamp('2022-05-11 12:00:00'),\n",
      "    Timestamp('2022-05-11 12:05:00'),\n",
      "    Timestamp('2022-05-11 12:10:00'),\n",
      "    Timestamp('2022-05-11 12:15:00'),\n",
      "    Timestamp('2022-05-11 12:20:00'),\n",
      "    Timestamp('2022-05-11 12:25:00'),\n",
      "    Timestamp('2022-05-11 12:30:00'),\n",
      "    Timestamp('2022-05-11 12:35:00'),\n",
      "    Timestamp('2022-05-11 12:40:00'),\n",
      "    Timestamp('2022-05-11 12:45:00'),\n",
      "    Timestamp('2022-05-11 12:50:00'),\n",
      "    Timestamp('2022-05-11 12:55:00'),\n",
      "    Timestamp('2022-05-11 13:00:00'),\n",
      "    Timestamp('2022-05-11 13:05:00'),\n",
      "    Timestamp('2022-05-11 13:10:00'),\n",
      "    Timestamp('2022-05-11 13:15:00'),\n",
      "    Timestamp('2022-05-11 13:20:00'),\n",
      "    Timestamp('2022-05-11 13:25:00'),\n",
      "    Timestamp('2022-05-11 13:30:00'),\n",
      "    Timestamp('2022-05-11 13:35:00'),\n",
      "    Timestamp('2022-05-11 13:40:00'),\n",
      "    Timestamp('2022-05-11 13:45:00'),\n",
      "    Timestamp('2022-05-11 13:50:00'),\n",
      "    Timestamp('2022-05-11 13:55:00'),\n",
      "    Timestamp('2022-05-11 14:00:00'),\n",
      "    Timestamp('2022-05-11 14:05:00'),\n",
      "    Timestamp('2022-05-11 14:10:00'),\n",
      "    Timestamp('2022-05-11 14:15:00'),\n",
      "    Timestamp('2022-05-11 14:20:00'),\n",
      "    Timestamp('2022-05-11 14:25:00'),\n",
      "    Timestamp('2022-05-11 14:30:00'),\n",
      "    Timestamp('2022-05-11 14:35:00'),\n",
      "    Timestamp('2022-05-11 14:40:00'),\n",
      "    Timestamp('2022-05-11 14:45:00'),\n",
      "    Timestamp('2022-05-11 14:50:00'),\n",
      "    Timestamp('2022-05-11 14:55:00'),\n",
      "    Timestamp('2022-05-11 15:00:00'),\n",
      "    Timestamp('2022-05-11 15:05:00'),\n",
      "    Timestamp('2022-05-11 15:10:00'),\n",
      "    Timestamp('2022-05-11 15:15:00'),\n",
      "    Timestamp('2022-05-11 15:20:00'),\n",
      "    Timestamp('2022-05-11 15:25:00'),\n",
      "    Timestamp('2022-05-11 15:30:00'),\n",
      "    Timestamp('2022-05-11 15:35:00'),\n",
      "    Timestamp('2022-05-11 15:40:00'),\n",
      "    Timestamp('2022-05-11 15:45:00'),\n",
      "    Timestamp('2022-05-11 15:50:00'),\n",
      "    Timestamp('2022-05-11 15:55:00'),\n",
      "    Timestamp('2022-05-11 16:00:00'),\n",
      "    Timestamp('2022-05-11 16:05:00'),\n",
      "    Timestamp('2022-05-11 16:10:00'),\n",
      "    Timestamp('2022-05-11 16:15:00'),\n",
      "    Timestamp('2022-05-11 16:20:00'),\n",
      "    Timestamp('2022-05-11 16:25:00'),\n",
      "    Timestamp('2022-05-11 16:45:00'),\n",
      "    Timestamp('2022-05-11 16:55:00'),\n",
      "    Timestamp('2022-05-11 18:00:00'),\n",
      "    Timestamp('2022-05-11 18:15:00'),\n",
      "    Timestamp('2022-05-11 18:20:00'),\n",
      "    Timestamp('2022-05-11 18:25:00'),\n",
      "    Timestamp('2022-05-11 20:00:00'),\n",
      "    Timestamp('2022-05-12 04:05:00'),\n",
      "    Timestamp('2022-05-12 05:35:00'),\n",
      "    Timestamp('2022-05-12 05:55:00'),\n",
      "    Timestamp('2022-05-12 06:20:00'),\n",
      "    Timestamp('2022-05-12 06:30:00'),\n",
      "    Timestamp('2022-05-12 06:50:00'),\n",
      "    Timestamp('2022-05-12 06:55:00'),\n",
      "    Timestamp('2022-05-12 07:00:00'),\n",
      "    Timestamp('2022-05-12 07:05:00'),\n",
      "    Timestamp('2022-05-12 07:50:00'),\n",
      "    Timestamp('2022-05-12 07:55:00'),\n",
      "    Timestamp('2022-05-12 08:00:00'),\n",
      "    Timestamp('2022-05-12 08:05:00'),\n",
      "    Timestamp('2022-05-12 08:10:00'),\n",
      "    Timestamp('2022-05-12 08:15:00'),\n",
      "    Timestamp('2022-05-12 08:20:00'),\n",
      "    Timestamp('2022-05-12 08:30:00'),\n",
      "    Timestamp('2022-05-12 08:40:00'),\n",
      "    Timestamp('2022-05-12 08:45:00'),\n",
      "    Timestamp('2022-05-12 08:50:00'),\n",
      "    Timestamp('2022-05-12 09:00:00'),\n",
      "    Timestamp('2022-05-12 09:05:00'),\n",
      "    Timestamp('2022-05-12 09:10:00'),\n",
      "    Timestamp('2022-05-12 09:15:00'),\n",
      "    Timestamp('2022-05-12 09:30:00'),\n",
      "    Timestamp('2022-05-12 09:35:00'),\n",
      "    Timestamp('2022-05-12 09:40:00'),\n",
      "    Timestamp('2022-05-12 09:45:00'),\n",
      "    Timestamp('2022-05-12 09:50:00'),\n",
      "    Timestamp('2022-05-12 09:55:00'),\n",
      "    Timestamp('2022-05-12 10:00:00'),\n",
      "    Timestamp('2022-05-12 10:05:00'),\n",
      "    Timestamp('2022-05-12 10:10:00'),\n",
      "    Timestamp('2022-05-12 10:15:00'),\n",
      "    Timestamp('2022-05-12 10:20:00'),\n",
      "    Timestamp('2022-05-12 10:25:00'),\n",
      "    Timestamp('2022-05-12 10:30:00'),\n",
      "    Timestamp('2022-05-12 10:35:00'),\n",
      "    Timestamp('2022-05-12 10:40:00'),\n",
      "    Timestamp('2022-05-12 10:45:00'),\n",
      "    Timestamp('2022-05-12 10:50:00'),\n",
      "    Timestamp('2022-05-12 10:55:00'),\n",
      "    Timestamp('2022-05-12 11:00:00'),\n",
      "    Timestamp('2022-05-12 11:05:00'),\n",
      "    Timestamp('2022-05-12 11:10:00'),\n",
      "    Timestamp('2022-05-12 11:15:00'),\n",
      "    Timestamp('2022-05-12 11:20:00'),\n",
      "    Timestamp('2022-05-12 11:25:00'),\n",
      "    Timestamp('2022-05-12 11:30:00'),\n",
      "    Timestamp('2022-05-12 11:35:00'),\n",
      "    Timestamp('2022-05-12 11:40:00'),\n",
      "    Timestamp('2022-05-12 11:45:00'),\n",
      "    Timestamp('2022-05-12 11:50:00'),\n",
      "    Timestamp('2022-05-12 11:55:00'),\n",
      "    Timestamp('2022-05-12 12:00:00'),\n",
      "    Timestamp('2022-05-12 12:05:00'),\n",
      "    Timestamp('2022-05-12 12:10:00'),\n",
      "    Timestamp('2022-05-12 12:15:00'),\n",
      "    Timestamp('2022-05-12 12:20:00'),\n",
      "    Timestamp('2022-05-12 12:25:00'),\n",
      "    Timestamp('2022-05-12 12:30:00'),\n",
      "    Timestamp('2022-05-12 12:35:00'),\n",
      "    Timestamp('2022-05-12 12:40:00'),\n",
      "    Timestamp('2022-05-12 12:45:00'),\n",
      "    Timestamp('2022-05-12 12:50:00'),\n",
      "    Timestamp('2022-05-12 12:55:00'),\n",
      "    Timestamp('2022-05-12 13:00:00'),\n",
      "    Timestamp('2022-05-12 13:05:00'),\n",
      "    Timestamp('2022-05-12 13:10:00'),\n",
      "    Timestamp('2022-05-12 13:15:00'),\n",
      "    Timestamp('2022-05-12 13:20:00'),\n",
      "    Timestamp('2022-05-12 13:25:00'),\n",
      "    Timestamp('2022-05-12 13:30:00'),\n",
      "    Timestamp('2022-05-12 13:35:00'),\n",
      "    Timestamp('2022-05-12 13:40:00'),\n",
      "    Timestamp('2022-05-12 13:45:00'),\n",
      "    Timestamp('2022-05-12 13:50:00'),\n",
      "    Timestamp('2022-05-12 13:55:00'),\n",
      "    Timestamp('2022-05-12 14:00:00'),\n",
      "    Timestamp('2022-05-12 14:05:00'),\n",
      "    Timestamp('2022-05-12 14:10:00'),\n",
      "    Timestamp('2022-05-12 14:15:00'),\n",
      "    Timestamp('2022-05-12 14:20:00'),\n",
      "    Timestamp('2022-05-12 14:25:00'),\n",
      "    Timestamp('2022-05-12 14:30:00'),\n",
      "    Timestamp('2022-05-12 14:35:00'),\n",
      "    Timestamp('2022-05-12 14:40:00'),\n",
      "    Timestamp('2022-05-12 14:45:00'),\n",
      "    Timestamp('2022-05-12 14:50:00'),\n",
      "    Timestamp('2022-05-12 14:55:00'),\n",
      "    Timestamp('2022-05-12 15:00:00'),\n",
      "    Timestamp('2022-05-12 15:05:00'),\n",
      "    Timestamp('2022-05-12 15:10:00'),\n",
      "    Timestamp('2022-05-12 15:15:00'),\n",
      "    Timestamp('2022-05-12 15:20:00'),\n",
      "    Timestamp('2022-05-12 15:25:00'),\n",
      "    Timestamp('2022-05-12 15:30:00'),\n",
      "    Timestamp('2022-05-12 15:35:00'),\n",
      "    Timestamp('2022-05-12 15:40:00'),\n",
      "    Timestamp('2022-05-12 15:45:00'),\n",
      "    Timestamp('2022-05-12 15:50:00'),\n",
      "    Timestamp('2022-05-12 15:55:00'),\n",
      "    Timestamp('2022-05-12 16:00:00'),\n",
      "    Timestamp('2022-05-12 16:05:00'),\n",
      "    Timestamp('2022-05-12 16:10:00'),\n",
      "    Timestamp('2022-05-12 16:15:00'),\n",
      "    Timestamp('2022-05-12 16:20:00'),\n",
      "    Timestamp('2022-05-12 16:25:00'),\n",
      "    Timestamp('2022-05-12 16:30:00'),\n",
      "    Timestamp('2022-05-12 16:45:00'),\n",
      "    Timestamp('2022-05-12 16:55:00'),\n",
      "    Timestamp('2022-05-12 17:05:00'),\n",
      "    Timestamp('2022-05-12 17:25:00'),\n",
      "    Timestamp('2022-05-12 17:30:00'),\n",
      "    Timestamp('2022-05-12 17:35:00'),\n",
      "    Timestamp('2022-05-12 17:45:00'),\n",
      "    Timestamp('2022-05-12 17:50:00'),\n",
      "    Timestamp('2022-05-12 17:55:00'),\n",
      "    Timestamp('2022-05-12 18:00:00'),\n",
      "    Timestamp('2022-05-12 18:05:00'),\n",
      "    Timestamp('2022-05-12 19:10:00'),\n",
      "    Timestamp('2022-05-12 19:35:00'),\n",
      "    Timestamp('2022-05-13 04:10:00'),\n",
      "    Timestamp('2022-05-13 04:15:00'),\n",
      "    Timestamp('2022-05-13 04:40:00'),\n",
      "    Timestamp('2022-05-13 05:15:00'),\n",
      "    Timestamp('2022-05-13 05:40:00'),\n",
      "    Timestamp('2022-05-13 06:00:00'),\n",
      "    Timestamp('2022-05-13 06:05:00'),\n",
      "    Timestamp('2022-05-13 07:10:00'),\n",
      "    Timestamp('2022-05-13 07:20:00'),\n",
      "    Timestamp('2022-05-13 07:25:00'),\n",
      "    Timestamp('2022-05-13 07:50:00'),\n",
      "    Timestamp('2022-05-13 08:05:00'),\n",
      "    Timestamp('2022-05-13 08:45:00'),\n",
      "    Timestamp('2022-05-13 08:55:00'),\n",
      "    Timestamp('2022-05-13 09:00:00'),\n",
      "    Timestamp('2022-05-13 09:05:00'),\n",
      "    Timestamp('2022-05-13 09:15:00'),\n",
      "    Timestamp('2022-05-13 09:30:00'),\n",
      "    Timestamp('2022-05-13 09:35:00'),\n",
      "    Timestamp('2022-05-13 09:40:00'),\n",
      "    Timestamp('2022-05-13 09:45:00'),\n",
      "    Timestamp('2022-05-13 09:50:00'),\n",
      "    Timestamp('2022-05-13 09:55:00'),\n",
      "    Timestamp('2022-05-13 10:00:00'),\n",
      "    Timestamp('2022-05-13 10:05:00'),\n",
      "    Timestamp('2022-05-13 10:10:00'),\n",
      "    Timestamp('2022-05-13 10:15:00'),\n",
      "    Timestamp('2022-05-13 10:20:00'),\n",
      "    Timestamp('2022-05-13 10:25:00'),\n",
      "    Timestamp('2022-05-13 10:30:00'),\n",
      "    Timestamp('2022-05-13 10:35:00'),\n",
      "    Timestamp('2022-05-13 10:40:00'),\n",
      "    Timestamp('2022-05-13 10:45:00'),\n",
      "    Timestamp('2022-05-13 10:50:00'),\n",
      "    Timestamp('2022-05-13 10:55:00'),\n",
      "    Timestamp('2022-05-13 11:00:00'),\n",
      "    Timestamp('2022-05-13 11:05:00'),\n",
      "    Timestamp('2022-05-13 11:10:00'),\n",
      "    Timestamp('2022-05-13 11:15:00'),\n",
      "    Timestamp('2022-05-13 11:20:00'),\n",
      "    Timestamp('2022-05-13 11:25:00'),\n",
      "    Timestamp('2022-05-13 11:30:00'),\n",
      "    Timestamp('2022-05-13 11:35:00'),\n",
      "    Timestamp('2022-05-13 11:40:00'),\n",
      "    Timestamp('2022-05-13 11:45:00'),\n",
      "    Timestamp('2022-05-13 11:50:00'),\n",
      "    Timestamp('2022-05-13 11:55:00'),\n",
      "    Timestamp('2022-05-13 12:00:00'),\n",
      "    Timestamp('2022-05-13 12:05:00'),\n",
      "    Timestamp('2022-05-13 12:10:00'),\n",
      "    Timestamp('2022-05-13 12:15:00'),\n",
      "    Timestamp('2022-05-13 12:20:00'),\n",
      "    Timestamp('2022-05-13 12:25:00'),\n",
      "    Timestamp('2022-05-13 12:30:00'),\n",
      "    Timestamp('2022-05-13 12:35:00'),\n",
      "    Timestamp('2022-05-13 12:40:00'),\n",
      "    Timestamp('2022-05-13 12:45:00'),\n",
      "    Timestamp('2022-05-13 12:50:00'),\n",
      "    Timestamp('2022-05-13 12:55:00'),\n",
      "    Timestamp('2022-05-13 13:00:00'),\n",
      "    Timestamp('2022-05-13 13:05:00'),\n",
      "    Timestamp('2022-05-13 13:10:00'),\n",
      "    Timestamp('2022-05-13 13:15:00'),\n",
      "    Timestamp('2022-05-13 13:20:00'),\n",
      "    Timestamp('2022-05-13 13:25:00'),\n",
      "    Timestamp('2022-05-13 13:30:00'),\n",
      "    Timestamp('2022-05-13 13:35:00'),\n",
      "    Timestamp('2022-05-13 13:40:00'),\n",
      "    Timestamp('2022-05-13 13:45:00'),\n",
      "    Timestamp('2022-05-13 13:50:00'),\n",
      "    Timestamp('2022-05-13 13:55:00'),\n",
      "    Timestamp('2022-05-13 14:00:00'),\n",
      "    Timestamp('2022-05-13 14:05:00'),\n",
      "    Timestamp('2022-05-13 14:10:00'),\n",
      "    Timestamp('2022-05-13 14:15:00'),\n",
      "    Timestamp('2022-05-13 14:20:00'),\n",
      "    Timestamp('2022-05-13 14:25:00'),\n",
      "    Timestamp('2022-05-13 14:30:00'),\n",
      "    Timestamp('2022-05-13 14:35:00'),\n",
      "    Timestamp('2022-05-13 14:40:00'),\n",
      "    Timestamp('2022-05-13 14:45:00'),\n",
      "    Timestamp('2022-05-13 14:50:00'),\n",
      "    Timestamp('2022-05-13 14:55:00'),\n",
      "    Timestamp('2022-05-13 15:00:00'),\n",
      "    Timestamp('2022-05-13 15:05:00'),\n",
      "    Timestamp('2022-05-13 15:10:00'),\n",
      "    Timestamp('2022-05-13 15:15:00'),\n",
      "    Timestamp('2022-05-13 15:20:00'),\n",
      "    Timestamp('2022-05-13 15:25:00'),\n",
      "    Timestamp('2022-05-13 15:30:00'),\n",
      "    Timestamp('2022-05-13 15:35:00'),\n",
      "    Timestamp('2022-05-13 15:40:00'),\n",
      "    Timestamp('2022-05-13 15:45:00'),\n",
      "    Timestamp('2022-05-13 15:50:00'),\n",
      "    Timestamp('2022-05-13 15:55:00'),\n",
      "    Timestamp('2022-05-13 16:00:00'),\n",
      "    Timestamp('2022-05-13 16:05:00'),\n",
      "    Timestamp('2022-05-13 16:10:00'),\n",
      "    Timestamp('2022-05-13 16:15:00'),\n",
      "    Timestamp('2022-05-13 16:20:00'),\n",
      "    Timestamp('2022-05-13 16:30:00'),\n",
      "    Timestamp('2022-05-13 16:40:00'),\n",
      "    Timestamp('2022-05-13 17:00:00'),\n",
      "    Timestamp('2022-05-13 17:05:00'),\n",
      "    Timestamp('2022-05-13 17:10:00'),\n",
      "    Timestamp('2022-05-13 17:25:00'),\n",
      "    Timestamp('2022-05-13 18:10:00')]\n",
      "In New  but not in Orig:\n",
      "[   Timestamp('2022-04-18 04:40:00'),\n",
      "    Timestamp('2022-04-18 04:45:00'),\n",
      "    Timestamp('2022-04-18 04:50:00'),\n",
      "    Timestamp('2022-04-18 04:55:00'),\n",
      "    Timestamp('2022-04-18 05:00:00'),\n",
      "    Timestamp('2022-04-18 05:05:00'),\n",
      "    Timestamp('2022-04-18 05:10:00'),\n",
      "    Timestamp('2022-04-18 05:15:00'),\n",
      "    Timestamp('2022-04-18 05:20:00'),\n",
      "    Timestamp('2022-04-18 05:25:00'),\n",
      "    Timestamp('2022-04-18 05:30:00'),\n",
      "    Timestamp('2022-04-18 05:35:00'),\n",
      "    Timestamp('2022-04-18 05:40:00'),\n",
      "    Timestamp('2022-04-18 05:45:00'),\n",
      "    Timestamp('2022-04-18 05:50:00'),\n",
      "    Timestamp('2022-04-18 05:55:00'),\n",
      "    Timestamp('2022-04-18 06:00:00'),\n",
      "    Timestamp('2022-04-18 06:05:00'),\n",
      "    Timestamp('2022-04-18 06:10:00'),\n",
      "    Timestamp('2022-04-18 06:15:00'),\n",
      "    Timestamp('2022-04-18 06:20:00'),\n",
      "    Timestamp('2022-04-18 06:25:00'),\n",
      "    Timestamp('2022-04-18 06:30:00'),\n",
      "    Timestamp('2022-04-18 06:35:00'),\n",
      "    Timestamp('2022-04-18 06:40:00'),\n",
      "    Timestamp('2022-04-18 06:45:00'),\n",
      "    Timestamp('2022-04-18 06:50:00'),\n",
      "    Timestamp('2022-04-18 06:55:00'),\n",
      "    Timestamp('2022-04-18 07:00:00'),\n",
      "    Timestamp('2022-04-18 07:15:00'),\n",
      "    Timestamp('2022-04-18 07:20:00'),\n",
      "    Timestamp('2022-04-18 07:25:00'),\n",
      "    Timestamp('2022-04-18 07:30:00'),\n",
      "    Timestamp('2022-04-18 07:35:00'),\n",
      "    Timestamp('2022-04-18 07:40:00'),\n",
      "    Timestamp('2022-04-18 07:45:00'),\n",
      "    Timestamp('2022-04-18 07:50:00'),\n",
      "    Timestamp('2022-04-18 07:55:00'),\n",
      "    Timestamp('2022-04-18 08:00:00'),\n",
      "    Timestamp('2022-04-18 08:10:00'),\n",
      "    Timestamp('2022-04-18 08:15:00'),\n",
      "    Timestamp('2022-04-18 08:20:00'),\n",
      "    Timestamp('2022-04-18 08:25:00'),\n",
      "    Timestamp('2022-04-18 08:30:00'),\n",
      "    Timestamp('2022-04-18 08:35:00'),\n",
      "    Timestamp('2022-04-18 08:50:00'),\n",
      "    Timestamp('2022-04-18 08:55:00'),\n",
      "    Timestamp('2022-04-18 09:00:00'),\n",
      "    Timestamp('2022-04-18 09:10:00'),\n",
      "    Timestamp('2022-04-18 09:15:00'),\n",
      "    Timestamp('2022-04-18 09:20:00'),\n",
      "    Timestamp('2022-04-18 16:20:00'),\n",
      "    Timestamp('2022-04-18 16:30:00'),\n",
      "    Timestamp('2022-04-18 16:35:00'),\n",
      "    Timestamp('2022-04-18 16:45:00'),\n",
      "    Timestamp('2022-04-18 16:50:00'),\n",
      "    Timestamp('2022-04-18 16:55:00'),\n",
      "    Timestamp('2022-04-18 17:00:00'),\n",
      "    Timestamp('2022-04-18 17:05:00'),\n",
      "    Timestamp('2022-04-18 17:10:00'),\n",
      "    Timestamp('2022-04-18 17:15:00'),\n",
      "    Timestamp('2022-04-18 17:20:00'),\n",
      "    Timestamp('2022-04-18 17:25:00'),\n",
      "    Timestamp('2022-04-18 17:30:00'),\n",
      "    Timestamp('2022-04-18 18:10:00'),\n",
      "    Timestamp('2022-04-18 18:15:00'),\n",
      "    Timestamp('2022-04-18 18:20:00'),\n",
      "    Timestamp('2022-04-18 18:35:00'),\n",
      "    Timestamp('2022-04-18 18:40:00'),\n",
      "    Timestamp('2022-04-18 18:45:00'),\n",
      "    Timestamp('2022-04-18 18:50:00'),\n",
      "    Timestamp('2022-04-18 19:00:00'),\n",
      "    Timestamp('2022-04-18 19:05:00'),\n",
      "    Timestamp('2022-04-18 19:10:00'),\n",
      "    Timestamp('2022-04-18 19:25:00'),\n",
      "    Timestamp('2022-04-18 19:30:00'),\n",
      "    Timestamp('2022-04-18 19:35:00'),\n",
      "    Timestamp('2022-04-18 19:40:00'),\n",
      "    Timestamp('2022-04-18 19:45:00'),\n",
      "    Timestamp('2022-04-19 04:05:00'),\n",
      "    Timestamp('2022-04-19 04:10:00'),\n",
      "    Timestamp('2022-04-19 04:15:00'),\n",
      "    Timestamp('2022-04-19 04:20:00'),\n",
      "    Timestamp('2022-04-19 04:25:00'),\n",
      "    Timestamp('2022-04-19 04:30:00'),\n",
      "    Timestamp('2022-04-19 04:40:00'),\n",
      "    Timestamp('2022-04-19 04:45:00'),\n",
      "    Timestamp('2022-04-19 05:00:00'),\n",
      "    Timestamp('2022-04-19 05:05:00'),\n",
      "    Timestamp('2022-04-19 05:10:00'),\n",
      "    Timestamp('2022-04-19 05:15:00'),\n",
      "    Timestamp('2022-04-19 05:20:00'),\n",
      "    Timestamp('2022-04-19 05:25:00'),\n",
      "    Timestamp('2022-04-19 05:30:00'),\n",
      "    Timestamp('2022-04-19 05:35:00'),\n",
      "    Timestamp('2022-04-19 05:40:00'),\n",
      "    Timestamp('2022-04-19 05:45:00'),\n",
      "    Timestamp('2022-04-19 05:50:00'),\n",
      "    Timestamp('2022-04-19 05:55:00'),\n",
      "    Timestamp('2022-04-19 06:00:00'),\n",
      "    Timestamp('2022-04-19 06:05:00'),\n",
      "    Timestamp('2022-04-19 06:10:00'),\n",
      "    Timestamp('2022-04-19 06:15:00'),\n",
      "    Timestamp('2022-04-19 06:20:00'),\n",
      "    Timestamp('2022-04-19 06:25:00'),\n",
      "    Timestamp('2022-04-19 06:30:00'),\n",
      "    Timestamp('2022-04-19 06:40:00'),\n",
      "    Timestamp('2022-04-19 06:45:00'),\n",
      "    Timestamp('2022-04-19 06:50:00'),\n",
      "    Timestamp('2022-04-19 06:55:00'),\n",
      "    Timestamp('2022-04-19 07:00:00'),\n",
      "    Timestamp('2022-04-19 07:10:00'),\n",
      "    Timestamp('2022-04-19 07:15:00'),\n",
      "    Timestamp('2022-04-19 07:20:00'),\n",
      "    Timestamp('2022-04-19 07:30:00'),\n",
      "    Timestamp('2022-04-19 07:35:00'),\n",
      "    Timestamp('2022-04-19 07:40:00'),\n",
      "    Timestamp('2022-04-19 07:45:00'),\n",
      "    Timestamp('2022-04-19 07:50:00'),\n",
      "    Timestamp('2022-04-19 07:55:00'),\n",
      "    Timestamp('2022-04-19 08:10:00'),\n",
      "    Timestamp('2022-04-19 08:15:00'),\n",
      "    Timestamp('2022-04-19 08:35:00'),\n",
      "    Timestamp('2022-04-19 08:50:00'),\n",
      "    Timestamp('2022-04-19 09:05:00'),\n",
      "    Timestamp('2022-04-19 09:15:00'),\n",
      "    Timestamp('2022-04-19 09:25:00'),\n",
      "    Timestamp('2022-04-19 18:45:00'),\n",
      "    Timestamp('2022-04-20 04:10:00'),\n",
      "    Timestamp('2022-04-20 04:20:00'),\n",
      "    Timestamp('2022-04-20 04:25:00'),\n",
      "    Timestamp('2022-04-20 04:30:00'),\n",
      "    Timestamp('2022-04-20 04:35:00'),\n",
      "    Timestamp('2022-04-20 04:40:00'),\n",
      "    Timestamp('2022-04-20 04:45:00'),\n",
      "    Timestamp('2022-04-20 04:50:00'),\n",
      "    Timestamp('2022-04-20 05:00:00'),\n",
      "    Timestamp('2022-04-20 05:15:00'),\n",
      "    Timestamp('2022-04-20 05:20:00'),\n",
      "    Timestamp('2022-04-20 05:25:00'),\n",
      "    Timestamp('2022-04-20 05:40:00'),\n",
      "    Timestamp('2022-04-20 05:45:00'),\n",
      "    Timestamp('2022-04-20 05:55:00'),\n",
      "    Timestamp('2022-04-20 06:00:00'),\n",
      "    Timestamp('2022-04-20 06:05:00'),\n",
      "    Timestamp('2022-04-20 06:10:00'),\n",
      "    Timestamp('2022-04-20 06:15:00'),\n",
      "    Timestamp('2022-04-20 06:20:00'),\n",
      "    Timestamp('2022-04-20 06:25:00'),\n",
      "    Timestamp('2022-04-20 06:30:00'),\n",
      "    Timestamp('2022-04-20 06:35:00'),\n",
      "    Timestamp('2022-04-20 06:40:00'),\n",
      "    Timestamp('2022-04-20 06:50:00'),\n",
      "    Timestamp('2022-04-20 07:00:00'),\n",
      "    Timestamp('2022-04-20 08:35:00'),\n",
      "    Timestamp('2022-04-20 17:05:00'),\n",
      "    Timestamp('2022-04-20 17:10:00'),\n",
      "    Timestamp('2022-04-20 17:30:00'),\n",
      "    Timestamp('2022-04-20 17:45:00'),\n",
      "    Timestamp('2022-04-20 17:55:00'),\n",
      "    Timestamp('2022-04-20 18:05:00'),\n",
      "    Timestamp('2022-04-20 18:10:00'),\n",
      "    Timestamp('2022-04-20 18:15:00'),\n",
      "    Timestamp('2022-04-20 18:20:00'),\n",
      "    Timestamp('2022-04-20 18:55:00'),\n",
      "    Timestamp('2022-04-20 19:00:00'),\n",
      "    Timestamp('2022-04-20 19:05:00'),\n",
      "    Timestamp('2022-04-20 19:15:00'),\n",
      "    Timestamp('2022-04-21 04:05:00'),\n",
      "    Timestamp('2022-04-21 04:10:00'),\n",
      "    Timestamp('2022-04-21 04:15:00'),\n",
      "    Timestamp('2022-04-21 04:25:00'),\n",
      "    Timestamp('2022-04-21 04:30:00'),\n",
      "    Timestamp('2022-04-21 04:35:00'),\n",
      "    Timestamp('2022-04-21 04:40:00'),\n",
      "    Timestamp('2022-04-21 04:45:00'),\n",
      "    Timestamp('2022-04-21 04:50:00'),\n",
      "    Timestamp('2022-04-21 04:55:00'),\n",
      "    Timestamp('2022-04-21 05:00:00'),\n",
      "    Timestamp('2022-04-21 05:05:00'),\n",
      "    Timestamp('2022-04-21 05:10:00'),\n",
      "    Timestamp('2022-04-21 05:15:00'),\n",
      "    Timestamp('2022-04-21 05:20:00'),\n",
      "    Timestamp('2022-04-21 05:25:00'),\n",
      "    Timestamp('2022-04-21 05:30:00'),\n",
      "    Timestamp('2022-04-21 05:35:00'),\n",
      "    Timestamp('2022-04-21 05:40:00'),\n",
      "    Timestamp('2022-04-21 05:45:00'),\n",
      "    Timestamp('2022-04-21 05:50:00'),\n",
      "    Timestamp('2022-04-21 05:55:00'),\n",
      "    Timestamp('2022-04-21 06:00:00'),\n",
      "    Timestamp('2022-04-21 06:05:00'),\n",
      "    Timestamp('2022-04-21 06:10:00'),\n",
      "    Timestamp('2022-04-21 06:15:00'),\n",
      "    Timestamp('2022-04-21 06:20:00'),\n",
      "    Timestamp('2022-04-21 06:25:00'),\n",
      "    Timestamp('2022-04-21 06:30:00'),\n",
      "    Timestamp('2022-04-21 06:35:00'),\n",
      "    Timestamp('2022-04-21 06:40:00'),\n",
      "    Timestamp('2022-04-21 06:45:00'),\n",
      "    Timestamp('2022-04-21 07:00:00'),\n",
      "    Timestamp('2022-04-21 07:10:00'),\n",
      "    Timestamp('2022-04-21 07:40:00'),\n",
      "    Timestamp('2022-04-21 07:45:00'),\n",
      "    Timestamp('2022-04-21 08:15:00'),\n",
      "    Timestamp('2022-04-21 09:00:00'),\n",
      "    Timestamp('2022-04-21 16:30:00'),\n",
      "    Timestamp('2022-04-21 16:40:00'),\n",
      "    Timestamp('2022-04-21 16:50:00'),\n",
      "    Timestamp('2022-04-21 17:00:00'),\n",
      "    Timestamp('2022-04-21 17:05:00'),\n",
      "    Timestamp('2022-04-21 17:10:00'),\n",
      "    Timestamp('2022-04-21 17:15:00'),\n",
      "    Timestamp('2022-04-21 17:20:00'),\n",
      "    Timestamp('2022-04-21 17:30:00'),\n",
      "    Timestamp('2022-04-21 17:35:00'),\n",
      "    Timestamp('2022-04-21 17:45:00'),\n",
      "    Timestamp('2022-04-21 17:50:00'),\n",
      "    Timestamp('2022-04-21 17:55:00'),\n",
      "    Timestamp('2022-04-21 18:00:00'),\n",
      "    Timestamp('2022-04-21 18:05:00'),\n",
      "    Timestamp('2022-04-21 18:10:00'),\n",
      "    Timestamp('2022-04-21 18:15:00'),\n",
      "    Timestamp('2022-04-21 18:30:00'),\n",
      "    Timestamp('2022-04-21 18:45:00'),\n",
      "    Timestamp('2022-04-21 18:50:00'),\n",
      "    Timestamp('2022-04-21 18:55:00'),\n",
      "    Timestamp('2022-04-21 19:00:00'),\n",
      "    Timestamp('2022-04-21 19:05:00'),\n",
      "    Timestamp('2022-04-21 19:10:00'),\n",
      "    Timestamp('2022-04-21 19:15:00'),\n",
      "    Timestamp('2022-04-21 19:20:00'),\n",
      "    Timestamp('2022-04-21 19:25:00'),\n",
      "    Timestamp('2022-04-21 19:40:00'),\n",
      "    Timestamp('2022-04-21 19:50:00'),\n",
      "    Timestamp('2022-04-22 04:05:00'),\n",
      "    Timestamp('2022-04-22 04:10:00'),\n",
      "    Timestamp('2022-04-22 04:15:00'),\n",
      "    Timestamp('2022-04-22 04:20:00'),\n",
      "    Timestamp('2022-04-22 04:25:00'),\n",
      "    Timestamp('2022-04-22 04:30:00'),\n",
      "    Timestamp('2022-04-22 04:40:00'),\n",
      "    Timestamp('2022-04-22 04:50:00'),\n",
      "    Timestamp('2022-04-22 04:55:00'),\n",
      "    Timestamp('2022-04-22 05:00:00'),\n",
      "    Timestamp('2022-04-22 05:05:00'),\n",
      "    Timestamp('2022-04-22 05:10:00'),\n",
      "    Timestamp('2022-04-22 05:15:00'),\n",
      "    Timestamp('2022-04-22 05:20:00'),\n",
      "    Timestamp('2022-04-22 05:25:00'),\n",
      "    Timestamp('2022-04-22 05:30:00'),\n",
      "    Timestamp('2022-04-22 05:35:00'),\n",
      "    Timestamp('2022-04-22 05:40:00'),\n",
      "    Timestamp('2022-04-22 05:45:00'),\n",
      "    Timestamp('2022-04-22 05:50:00'),\n",
      "    Timestamp('2022-04-22 06:00:00'),\n",
      "    Timestamp('2022-04-22 06:10:00'),\n",
      "    Timestamp('2022-04-22 06:15:00'),\n",
      "    Timestamp('2022-04-22 06:20:00'),\n",
      "    Timestamp('2022-04-22 06:25:00'),\n",
      "    Timestamp('2022-04-22 06:30:00'),\n",
      "    Timestamp('2022-04-22 06:35:00'),\n",
      "    Timestamp('2022-04-22 06:40:00'),\n",
      "    Timestamp('2022-04-22 06:45:00'),\n",
      "    Timestamp('2022-04-22 06:50:00'),\n",
      "    Timestamp('2022-04-22 07:00:00'),\n",
      "    Timestamp('2022-04-22 07:10:00'),\n",
      "    Timestamp('2022-04-22 07:15:00'),\n",
      "    Timestamp('2022-04-22 07:20:00'),\n",
      "    Timestamp('2022-04-22 07:25:00'),\n",
      "    Timestamp('2022-04-22 07:30:00'),\n",
      "    Timestamp('2022-04-22 07:35:00'),\n",
      "    Timestamp('2022-04-22 07:40:00'),\n",
      "    Timestamp('2022-04-22 07:45:00'),\n",
      "    Timestamp('2022-04-22 07:50:00'),\n",
      "    Timestamp('2022-04-22 07:55:00'),\n",
      "    Timestamp('2022-04-22 08:00:00'),\n",
      "    Timestamp('2022-04-22 08:10:00'),\n",
      "    Timestamp('2022-04-22 08:15:00'),\n",
      "    Timestamp('2022-04-22 08:25:00'),\n",
      "    Timestamp('2022-04-22 08:35:00'),\n",
      "    Timestamp('2022-04-22 08:40:00'),\n",
      "    Timestamp('2022-04-22 09:00:00'),\n",
      "    Timestamp('2022-04-22 09:10:00'),\n",
      "    Timestamp('2022-04-22 09:15:00'),\n",
      "    Timestamp('2022-04-22 09:25:00'),\n",
      "    Timestamp('2022-04-22 09:30:00'),\n",
      "    Timestamp('2022-04-22 16:15:00'),\n",
      "    Timestamp('2022-04-22 16:50:00'),\n",
      "    Timestamp('2022-04-22 16:55:00'),\n",
      "    Timestamp('2022-04-22 17:00:00'),\n",
      "    Timestamp('2022-04-22 17:15:00'),\n",
      "    Timestamp('2022-04-22 17:20:00'),\n",
      "    Timestamp('2022-04-22 17:25:00'),\n",
      "    Timestamp('2022-04-22 17:45:00'),\n",
      "    Timestamp('2022-04-22 17:50:00'),\n",
      "    Timestamp('2022-04-22 18:00:00'),\n",
      "    Timestamp('2022-04-22 18:05:00'),\n",
      "    Timestamp('2022-04-22 18:10:00'),\n",
      "    Timestamp('2022-04-22 18:15:00'),\n",
      "    Timestamp('2022-04-22 18:20:00'),\n",
      "    Timestamp('2022-04-22 18:30:00'),\n",
      "    Timestamp('2022-04-22 18:35:00'),\n",
      "    Timestamp('2022-04-22 18:40:00'),\n",
      "    Timestamp('2022-04-22 18:50:00'),\n",
      "    Timestamp('2022-04-22 18:55:00'),\n",
      "    Timestamp('2022-04-22 19:00:00'),\n",
      "    Timestamp('2022-04-22 19:15:00'),\n",
      "    Timestamp('2022-04-22 19:30:00'),\n",
      "    Timestamp('2022-04-22 19:40:00'),\n",
      "    Timestamp('2022-04-22 19:45:00'),\n",
      "    Timestamp('2022-04-22 19:50:00'),\n",
      "    Timestamp('2022-04-22 19:55:00'),\n",
      "    Timestamp('2022-04-22 20:00:00'),\n",
      "    Timestamp('2022-04-25 04:10:00'),\n",
      "    Timestamp('2022-04-25 04:15:00'),\n",
      "    Timestamp('2022-04-25 04:20:00'),\n",
      "    Timestamp('2022-04-25 04:25:00'),\n",
      "    Timestamp('2022-04-25 04:30:00'),\n",
      "    Timestamp('2022-04-25 04:35:00'),\n",
      "    Timestamp('2022-04-25 04:45:00'),\n",
      "    Timestamp('2022-04-25 04:50:00'),\n",
      "    Timestamp('2022-04-25 04:55:00'),\n",
      "    Timestamp('2022-04-25 05:00:00'),\n",
      "    Timestamp('2022-04-25 05:05:00'),\n",
      "    Timestamp('2022-04-25 05:10:00'),\n",
      "    Timestamp('2022-04-25 05:20:00'),\n",
      "    Timestamp('2022-04-25 05:25:00'),\n",
      "    Timestamp('2022-04-25 05:30:00'),\n",
      "    Timestamp('2022-04-25 05:40:00'),\n",
      "    Timestamp('2022-04-25 05:45:00'),\n",
      "    Timestamp('2022-04-25 05:50:00'),\n",
      "    Timestamp('2022-04-25 05:55:00'),\n",
      "    Timestamp('2022-04-25 06:00:00'),\n",
      "    Timestamp('2022-04-25 06:05:00'),\n",
      "    Timestamp('2022-04-25 06:10:00'),\n",
      "    Timestamp('2022-04-25 06:15:00'),\n",
      "    Timestamp('2022-04-25 06:25:00'),\n",
      "    Timestamp('2022-04-25 06:30:00'),\n",
      "    Timestamp('2022-04-25 06:35:00'),\n",
      "    Timestamp('2022-04-25 06:40:00'),\n",
      "    Timestamp('2022-04-25 06:45:00'),\n",
      "    Timestamp('2022-04-25 06:50:00'),\n",
      "    Timestamp('2022-04-25 06:55:00'),\n",
      "    Timestamp('2022-04-25 07:00:00'),\n",
      "    Timestamp('2022-04-25 07:10:00'),\n",
      "    Timestamp('2022-04-25 07:30:00'),\n",
      "    Timestamp('2022-04-25 07:35:00'),\n",
      "    Timestamp('2022-04-25 07:45:00'),\n",
      "    Timestamp('2022-04-25 07:55:00'),\n",
      "    Timestamp('2022-04-25 08:00:00'),\n",
      "    Timestamp('2022-04-25 08:20:00'),\n",
      "    Timestamp('2022-04-25 08:40:00'),\n",
      "    Timestamp('2022-04-25 08:55:00'),\n",
      "    Timestamp('2022-04-25 09:00:00'),\n",
      "    Timestamp('2022-04-25 09:15:00'),\n",
      "    Timestamp('2022-04-25 16:10:00'),\n",
      "    Timestamp('2022-04-25 16:35:00'),\n",
      "    Timestamp('2022-04-25 16:40:00'),\n",
      "    Timestamp('2022-04-25 16:50:00'),\n",
      "    Timestamp('2022-04-25 17:10:00'),\n",
      "    Timestamp('2022-04-25 17:15:00'),\n",
      "    Timestamp('2022-04-25 17:20:00'),\n",
      "    Timestamp('2022-04-25 17:30:00'),\n",
      "    Timestamp('2022-04-25 17:35:00'),\n",
      "    Timestamp('2022-04-25 17:50:00'),\n",
      "    Timestamp('2022-04-25 18:00:00'),\n",
      "    Timestamp('2022-04-25 18:35:00'),\n",
      "    Timestamp('2022-04-25 18:40:00'),\n",
      "    Timestamp('2022-04-25 18:45:00'),\n",
      "    Timestamp('2022-04-25 18:55:00'),\n",
      "    Timestamp('2022-04-25 19:05:00'),\n",
      "    Timestamp('2022-04-25 19:10:00'),\n",
      "    Timestamp('2022-04-25 19:15:00'),\n",
      "    Timestamp('2022-04-25 19:20:00'),\n",
      "    Timestamp('2022-04-25 19:30:00'),\n",
      "    Timestamp('2022-04-25 19:40:00'),\n",
      "    Timestamp('2022-04-25 19:45:00'),\n",
      "    Timestamp('2022-04-25 19:50:00'),\n",
      "    Timestamp('2022-04-25 19:55:00'),\n",
      "    Timestamp('2022-04-26 04:15:00'),\n",
      "    Timestamp('2022-04-26 04:20:00'),\n",
      "    Timestamp('2022-04-26 04:25:00'),\n",
      "    Timestamp('2022-04-26 04:30:00'),\n",
      "    Timestamp('2022-04-26 04:40:00'),\n",
      "    Timestamp('2022-04-26 04:45:00'),\n",
      "    Timestamp('2022-04-26 04:50:00'),\n",
      "    Timestamp('2022-04-26 04:55:00'),\n",
      "    Timestamp('2022-04-26 05:00:00'),\n",
      "    Timestamp('2022-04-26 05:05:00'),\n",
      "    Timestamp('2022-04-26 05:10:00'),\n",
      "    Timestamp('2022-04-26 05:15:00'),\n",
      "    Timestamp('2022-04-26 05:20:00'),\n",
      "    Timestamp('2022-04-26 05:25:00'),\n",
      "    Timestamp('2022-04-26 05:30:00'),\n",
      "    Timestamp('2022-04-26 05:35:00'),\n",
      "    Timestamp('2022-04-26 05:40:00'),\n",
      "    Timestamp('2022-04-26 05:45:00'),\n",
      "    Timestamp('2022-04-26 05:50:00'),\n",
      "    Timestamp('2022-04-26 06:00:00'),\n",
      "    Timestamp('2022-04-26 06:05:00'),\n",
      "    Timestamp('2022-04-26 06:10:00'),\n",
      "    Timestamp('2022-04-26 06:20:00'),\n",
      "    Timestamp('2022-04-26 06:25:00'),\n",
      "    Timestamp('2022-04-26 06:30:00'),\n",
      "    Timestamp('2022-04-26 06:35:00'),\n",
      "    Timestamp('2022-04-26 06:40:00'),\n",
      "    Timestamp('2022-04-26 06:45:00'),\n",
      "    Timestamp('2022-04-26 06:50:00'),\n",
      "    Timestamp('2022-04-26 06:55:00'),\n",
      "    Timestamp('2022-04-26 07:00:00'),\n",
      "    Timestamp('2022-04-26 07:10:00'),\n",
      "    Timestamp('2022-04-26 07:15:00'),\n",
      "    Timestamp('2022-04-26 07:20:00'),\n",
      "    Timestamp('2022-04-26 07:35:00'),\n",
      "    Timestamp('2022-04-26 07:40:00'),\n",
      "    Timestamp('2022-04-26 07:45:00'),\n",
      "    Timestamp('2022-04-26 07:50:00'),\n",
      "    Timestamp('2022-04-26 07:55:00'),\n",
      "    Timestamp('2022-04-26 08:00:00'),\n",
      "    Timestamp('2022-04-26 08:15:00'),\n",
      "    Timestamp('2022-04-26 08:20:00'),\n",
      "    Timestamp('2022-04-26 08:25:00'),\n",
      "    Timestamp('2022-04-26 08:30:00'),\n",
      "    Timestamp('2022-04-26 08:35:00'),\n",
      "    Timestamp('2022-04-26 08:40:00'),\n",
      "    Timestamp('2022-04-26 08:45:00'),\n",
      "    Timestamp('2022-04-26 08:50:00'),\n",
      "    Timestamp('2022-04-26 08:55:00'),\n",
      "    Timestamp('2022-04-26 09:05:00'),\n",
      "    Timestamp('2022-04-26 09:10:00'),\n",
      "    Timestamp('2022-04-26 09:25:00'),\n",
      "    Timestamp('2022-04-26 09:30:00'),\n",
      "    Timestamp('2022-04-26 16:15:00'),\n",
      "    Timestamp('2022-04-26 16:30:00'),\n",
      "    Timestamp('2022-04-26 16:40:00'),\n",
      "    Timestamp('2022-04-26 17:00:00'),\n",
      "    Timestamp('2022-04-26 17:10:00'),\n",
      "    Timestamp('2022-04-26 17:20:00'),\n",
      "    Timestamp('2022-04-26 17:25:00'),\n",
      "    Timestamp('2022-04-26 17:30:00'),\n",
      "    Timestamp('2022-04-26 17:40:00'),\n",
      "    Timestamp('2022-04-26 17:45:00'),\n",
      "    Timestamp('2022-04-26 17:50:00'),\n",
      "    Timestamp('2022-04-26 18:00:00'),\n",
      "    Timestamp('2022-04-26 18:05:00'),\n",
      "    Timestamp('2022-04-26 18:10:00'),\n",
      "    Timestamp('2022-04-26 18:20:00'),\n",
      "    Timestamp('2022-04-26 18:35:00'),\n",
      "    Timestamp('2022-04-26 18:40:00'),\n",
      "    Timestamp('2022-04-26 18:45:00'),\n",
      "    Timestamp('2022-04-26 19:00:00'),\n",
      "    Timestamp('2022-04-26 19:15:00'),\n",
      "    Timestamp('2022-04-26 19:20:00'),\n",
      "    Timestamp('2022-04-26 19:25:00'),\n",
      "    Timestamp('2022-04-26 19:35:00'),\n",
      "    Timestamp('2022-04-26 19:40:00'),\n",
      "    Timestamp('2022-04-26 19:45:00'),\n",
      "    Timestamp('2022-04-26 20:00:00'),\n",
      "    Timestamp('2022-04-27 04:05:00'),\n",
      "    Timestamp('2022-04-27 04:10:00'),\n",
      "    Timestamp('2022-04-27 04:15:00'),\n",
      "    Timestamp('2022-04-27 04:20:00'),\n",
      "    Timestamp('2022-04-27 04:25:00'),\n",
      "    Timestamp('2022-04-27 04:30:00'),\n",
      "    Timestamp('2022-04-27 04:35:00'),\n",
      "    Timestamp('2022-04-27 04:40:00'),\n",
      "    Timestamp('2022-04-27 04:45:00'),\n",
      "    Timestamp('2022-04-27 04:50:00'),\n",
      "    Timestamp('2022-04-27 04:55:00'),\n",
      "    Timestamp('2022-04-27 05:00:00'),\n",
      "    Timestamp('2022-04-27 05:05:00'),\n",
      "    Timestamp('2022-04-27 05:10:00'),\n",
      "    Timestamp('2022-04-27 05:15:00'),\n",
      "    Timestamp('2022-04-27 05:20:00'),\n",
      "    Timestamp('2022-04-27 05:25:00'),\n",
      "    Timestamp('2022-04-27 05:30:00'),\n",
      "    Timestamp('2022-04-27 05:35:00'),\n",
      "    Timestamp('2022-04-27 05:40:00'),\n",
      "    Timestamp('2022-04-27 05:45:00'),\n",
      "    Timestamp('2022-04-27 05:50:00'),\n",
      "    Timestamp('2022-04-27 05:55:00'),\n",
      "    Timestamp('2022-04-27 06:00:00'),\n",
      "    Timestamp('2022-04-27 06:05:00'),\n",
      "    Timestamp('2022-04-27 06:10:00'),\n",
      "    Timestamp('2022-04-27 06:15:00'),\n",
      "    Timestamp('2022-04-27 06:20:00'),\n",
      "    Timestamp('2022-04-27 06:25:00'),\n",
      "    Timestamp('2022-04-27 06:30:00'),\n",
      "    Timestamp('2022-04-27 06:35:00'),\n",
      "    Timestamp('2022-04-27 06:40:00'),\n",
      "    Timestamp('2022-04-27 06:45:00'),\n",
      "    Timestamp('2022-04-27 06:50:00'),\n",
      "    Timestamp('2022-04-27 06:55:00'),\n",
      "    Timestamp('2022-04-27 07:00:00'),\n",
      "    Timestamp('2022-04-27 07:05:00'),\n",
      "    Timestamp('2022-04-27 07:20:00'),\n",
      "    Timestamp('2022-04-27 07:30:00'),\n",
      "    Timestamp('2022-04-27 07:40:00'),\n",
      "    Timestamp('2022-04-27 07:45:00'),\n",
      "    Timestamp('2022-04-27 07:50:00'),\n",
      "    Timestamp('2022-04-27 07:55:00'),\n",
      "    Timestamp('2022-04-27 08:15:00'),\n",
      "    Timestamp('2022-04-27 08:25:00'),\n",
      "    Timestamp('2022-04-27 08:35:00'),\n",
      "    Timestamp('2022-04-27 08:40:00'),\n",
      "    Timestamp('2022-04-27 08:50:00'),\n",
      "    Timestamp('2022-04-27 08:55:00'),\n",
      "    Timestamp('2022-04-27 16:10:00'),\n",
      "    Timestamp('2022-04-27 16:15:00'),\n",
      "    Timestamp('2022-04-27 16:25:00'),\n",
      "    Timestamp('2022-04-27 16:30:00'),\n",
      "    Timestamp('2022-04-27 16:35:00'),\n",
      "    Timestamp('2022-04-27 16:40:00'),\n",
      "    Timestamp('2022-04-27 16:50:00'),\n",
      "    Timestamp('2022-04-27 16:55:00'),\n",
      "    Timestamp('2022-04-27 17:00:00'),\n",
      "    Timestamp('2022-04-27 17:05:00'),\n",
      "    Timestamp('2022-04-27 17:10:00'),\n",
      "    Timestamp('2022-04-27 17:15:00'),\n",
      "    Timestamp('2022-04-27 17:20:00'),\n",
      "    Timestamp('2022-04-27 17:25:00'),\n",
      "    Timestamp('2022-04-27 17:35:00'),\n",
      "    Timestamp('2022-04-27 17:45:00'),\n",
      "    Timestamp('2022-04-27 17:55:00'),\n",
      "    Timestamp('2022-04-27 18:00:00'),\n",
      "    Timestamp('2022-04-27 18:05:00'),\n",
      "    Timestamp('2022-04-27 18:10:00'),\n",
      "    Timestamp('2022-04-27 18:20:00'),\n",
      "    Timestamp('2022-04-27 18:25:00'),\n",
      "    Timestamp('2022-04-27 18:30:00'),\n",
      "    Timestamp('2022-04-27 18:35:00'),\n",
      "    Timestamp('2022-04-27 18:40:00'),\n",
      "    Timestamp('2022-04-27 18:45:00'),\n",
      "    Timestamp('2022-04-27 18:50:00'),\n",
      "    Timestamp('2022-04-27 19:00:00'),\n",
      "    Timestamp('2022-04-27 19:05:00'),\n",
      "    Timestamp('2022-04-27 19:15:00'),\n",
      "    Timestamp('2022-04-27 19:20:00'),\n",
      "    Timestamp('2022-04-27 19:25:00'),\n",
      "    Timestamp('2022-04-27 19:30:00'),\n",
      "    Timestamp('2022-04-27 19:35:00'),\n",
      "    Timestamp('2022-04-27 19:50:00'),\n",
      "    Timestamp('2022-04-27 20:00:00'),\n",
      "    Timestamp('2022-04-28 04:05:00'),\n",
      "    Timestamp('2022-04-28 04:10:00'),\n",
      "    Timestamp('2022-04-28 04:15:00'),\n",
      "    Timestamp('2022-04-28 04:20:00'),\n",
      "    Timestamp('2022-04-28 04:25:00'),\n",
      "    Timestamp('2022-04-28 04:30:00'),\n",
      "    Timestamp('2022-04-28 04:35:00'),\n",
      "    Timestamp('2022-04-28 04:40:00'),\n",
      "    Timestamp('2022-04-28 04:45:00'),\n",
      "    Timestamp('2022-04-28 04:50:00'),\n",
      "    Timestamp('2022-04-28 04:55:00'),\n",
      "    Timestamp('2022-04-28 05:05:00'),\n",
      "    Timestamp('2022-04-28 05:10:00'),\n",
      "    Timestamp('2022-04-28 05:15:00'),\n",
      "    Timestamp('2022-04-28 05:20:00'),\n",
      "    Timestamp('2022-04-28 05:25:00'),\n",
      "    Timestamp('2022-04-28 05:30:00'),\n",
      "    Timestamp('2022-04-28 05:35:00'),\n",
      "    Timestamp('2022-04-28 05:40:00'),\n",
      "    Timestamp('2022-04-28 05:45:00'),\n",
      "    Timestamp('2022-04-28 05:50:00'),\n",
      "    Timestamp('2022-04-28 05:55:00'),\n",
      "    Timestamp('2022-04-28 06:00:00'),\n",
      "    Timestamp('2022-04-28 06:05:00'),\n",
      "    Timestamp('2022-04-28 06:10:00'),\n",
      "    Timestamp('2022-04-28 06:15:00'),\n",
      "    Timestamp('2022-04-28 06:30:00'),\n",
      "    Timestamp('2022-04-28 06:35:00'),\n",
      "    Timestamp('2022-04-28 06:40:00'),\n",
      "    Timestamp('2022-04-28 06:45:00'),\n",
      "    Timestamp('2022-04-28 06:50:00'),\n",
      "    Timestamp('2022-04-28 06:55:00'),\n",
      "    Timestamp('2022-04-28 07:05:00'),\n",
      "    Timestamp('2022-04-28 07:15:00'),\n",
      "    Timestamp('2022-04-28 07:20:00'),\n",
      "    Timestamp('2022-04-28 07:25:00'),\n",
      "    Timestamp('2022-04-28 07:30:00'),\n",
      "    Timestamp('2022-04-28 07:35:00'),\n",
      "    Timestamp('2022-04-28 07:40:00'),\n",
      "    Timestamp('2022-04-28 07:45:00'),\n",
      "    Timestamp('2022-04-28 07:50:00'),\n",
      "    Timestamp('2022-04-28 07:55:00'),\n",
      "    Timestamp('2022-04-28 08:00:00'),\n",
      "    Timestamp('2022-04-28 08:10:00'),\n",
      "    Timestamp('2022-04-28 08:15:00'),\n",
      "    Timestamp('2022-04-28 08:35:00'),\n",
      "    Timestamp('2022-04-28 08:40:00'),\n",
      "    Timestamp('2022-04-28 08:55:00'),\n",
      "    Timestamp('2022-04-28 09:00:00'),\n",
      "    Timestamp('2022-04-28 09:05:00'),\n",
      "    Timestamp('2022-04-28 09:10:00'),\n",
      "    Timestamp('2022-04-28 09:20:00'),\n",
      "    Timestamp('2022-04-28 16:10:00'),\n",
      "    Timestamp('2022-04-28 16:15:00'),\n",
      "    Timestamp('2022-04-28 16:20:00'),\n",
      "    Timestamp('2022-04-28 16:35:00'),\n",
      "    Timestamp('2022-04-28 16:40:00'),\n",
      "    Timestamp('2022-04-28 16:50:00'),\n",
      "    Timestamp('2022-04-28 16:55:00'),\n",
      "    Timestamp('2022-04-28 17:00:00'),\n",
      "    Timestamp('2022-04-28 17:10:00'),\n",
      "    Timestamp('2022-04-28 17:15:00'),\n",
      "    Timestamp('2022-04-28 17:30:00'),\n",
      "    Timestamp('2022-04-28 17:35:00'),\n",
      "    Timestamp('2022-04-28 17:50:00'),\n",
      "    Timestamp('2022-04-28 17:55:00'),\n",
      "    Timestamp('2022-04-28 18:10:00'),\n",
      "    Timestamp('2022-04-28 18:15:00'),\n",
      "    Timestamp('2022-04-28 18:20:00'),\n",
      "    Timestamp('2022-04-28 18:25:00'),\n",
      "    Timestamp('2022-04-28 18:30:00'),\n",
      "    Timestamp('2022-04-28 18:35:00'),\n",
      "    Timestamp('2022-04-28 18:40:00'),\n",
      "    Timestamp('2022-04-28 18:45:00'),\n",
      "    Timestamp('2022-04-28 18:50:00'),\n",
      "    Timestamp('2022-04-28 18:55:00'),\n",
      "    Timestamp('2022-04-28 19:00:00'),\n",
      "    Timestamp('2022-04-28 19:05:00'),\n",
      "    Timestamp('2022-04-28 19:10:00'),\n",
      "    Timestamp('2022-04-28 19:15:00'),\n",
      "    Timestamp('2022-04-28 19:20:00'),\n",
      "    Timestamp('2022-04-28 19:25:00'),\n",
      "    Timestamp('2022-04-28 19:30:00'),\n",
      "    Timestamp('2022-04-28 19:35:00'),\n",
      "    Timestamp('2022-04-28 19:40:00'),\n",
      "    Timestamp('2022-04-28 19:45:00'),\n",
      "    Timestamp('2022-04-28 19:50:00'),\n",
      "    Timestamp('2022-04-28 19:55:00'),\n",
      "    Timestamp('2022-04-29 04:05:00'),\n",
      "    Timestamp('2022-04-29 04:10:00'),\n",
      "    Timestamp('2022-04-29 04:15:00'),\n",
      "    Timestamp('2022-04-29 04:20:00'),\n",
      "    Timestamp('2022-04-29 04:30:00'),\n",
      "    Timestamp('2022-04-29 04:35:00'),\n",
      "    Timestamp('2022-04-29 04:40:00'),\n",
      "    Timestamp('2022-04-29 04:45:00'),\n",
      "    Timestamp('2022-04-29 04:50:00'),\n",
      "    Timestamp('2022-04-29 04:55:00'),\n",
      "    Timestamp('2022-04-29 05:00:00'),\n",
      "    Timestamp('2022-04-29 05:05:00'),\n",
      "    Timestamp('2022-04-29 05:10:00'),\n",
      "    Timestamp('2022-04-29 05:15:00'),\n",
      "    Timestamp('2022-04-29 05:20:00'),\n",
      "    Timestamp('2022-04-29 05:25:00'),\n",
      "    Timestamp('2022-04-29 05:30:00'),\n",
      "    Timestamp('2022-04-29 05:35:00'),\n",
      "    Timestamp('2022-04-29 05:40:00'),\n",
      "    Timestamp('2022-04-29 05:45:00'),\n",
      "    Timestamp('2022-04-29 05:50:00'),\n",
      "    Timestamp('2022-04-29 05:55:00'),\n",
      "    Timestamp('2022-04-29 06:00:00'),\n",
      "    Timestamp('2022-04-29 06:05:00'),\n",
      "    Timestamp('2022-04-29 06:10:00'),\n",
      "    Timestamp('2022-04-29 06:15:00'),\n",
      "    Timestamp('2022-04-29 06:20:00'),\n",
      "    Timestamp('2022-04-29 06:25:00'),\n",
      "    Timestamp('2022-04-29 06:30:00'),\n",
      "    Timestamp('2022-04-29 06:35:00'),\n",
      "    Timestamp('2022-04-29 06:40:00'),\n",
      "    Timestamp('2022-04-29 06:45:00'),\n",
      "    Timestamp('2022-04-29 06:50:00'),\n",
      "    Timestamp('2022-04-29 06:55:00'),\n",
      "    Timestamp('2022-04-29 07:00:00'),\n",
      "    Timestamp('2022-04-29 07:05:00'),\n",
      "    Timestamp('2022-04-29 07:10:00'),\n",
      "    Timestamp('2022-04-29 07:15:00'),\n",
      "    Timestamp('2022-04-29 07:20:00'),\n",
      "    Timestamp('2022-04-29 07:25:00'),\n",
      "    Timestamp('2022-04-29 07:30:00'),\n",
      "    Timestamp('2022-04-29 07:35:00'),\n",
      "    Timestamp('2022-04-29 07:40:00'),\n",
      "    Timestamp('2022-04-29 07:45:00'),\n",
      "    Timestamp('2022-04-29 07:50:00'),\n",
      "    Timestamp('2022-04-29 07:55:00'),\n",
      "    Timestamp('2022-04-29 08:00:00'),\n",
      "    Timestamp('2022-04-29 08:15:00'),\n",
      "    Timestamp('2022-04-29 08:20:00'),\n",
      "    Timestamp('2022-04-29 08:30:00'),\n",
      "    Timestamp('2022-04-29 08:35:00'),\n",
      "    Timestamp('2022-04-29 08:45:00'),\n",
      "    Timestamp('2022-04-29 08:50:00'),\n",
      "    Timestamp('2022-04-29 08:55:00'),\n",
      "    Timestamp('2022-04-29 09:05:00'),\n",
      "    Timestamp('2022-04-29 09:10:00'),\n",
      "    Timestamp('2022-04-29 09:20:00'),\n",
      "    Timestamp('2022-04-29 09:30:00'),\n",
      "    Timestamp('2022-04-29 16:15:00'),\n",
      "    Timestamp('2022-04-29 16:25:00'),\n",
      "    Timestamp('2022-04-29 16:35:00'),\n",
      "    Timestamp('2022-04-29 16:55:00'),\n",
      "    Timestamp('2022-04-29 17:00:00'),\n",
      "    Timestamp('2022-04-29 17:05:00'),\n",
      "    Timestamp('2022-04-29 17:10:00'),\n",
      "    Timestamp('2022-04-29 17:15:00'),\n",
      "    Timestamp('2022-04-29 17:20:00'),\n",
      "    Timestamp('2022-04-29 17:25:00'),\n",
      "    Timestamp('2022-04-29 17:30:00'),\n",
      "    Timestamp('2022-04-29 17:40:00'),\n",
      "    Timestamp('2022-04-29 17:45:00'),\n",
      "    Timestamp('2022-04-29 18:05:00'),\n",
      "    Timestamp('2022-04-29 18:10:00'),\n",
      "    Timestamp('2022-04-29 18:15:00'),\n",
      "    Timestamp('2022-04-29 18:20:00'),\n",
      "    Timestamp('2022-04-29 18:25:00'),\n",
      "    Timestamp('2022-04-29 18:30:00'),\n",
      "    Timestamp('2022-04-29 18:35:00'),\n",
      "    Timestamp('2022-04-29 18:45:00'),\n",
      "    Timestamp('2022-04-29 18:50:00'),\n",
      "    Timestamp('2022-04-29 18:55:00'),\n",
      "    Timestamp('2022-04-29 19:00:00'),\n",
      "    Timestamp('2022-04-29 19:05:00'),\n",
      "    Timestamp('2022-04-29 19:10:00'),\n",
      "    Timestamp('2022-04-29 19:15:00'),\n",
      "    Timestamp('2022-04-29 19:20:00'),\n",
      "    Timestamp('2022-04-29 19:25:00'),\n",
      "    Timestamp('2022-04-29 19:30:00'),\n",
      "    Timestamp('2022-04-29 19:35:00'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Timestamp('2022-04-29 19:40:00'),\n",
      "    Timestamp('2022-04-29 19:45:00'),\n",
      "    Timestamp('2022-04-29 19:50:00'),\n",
      "    Timestamp('2022-04-29 19:55:00'),\n",
      "    Timestamp('2022-04-29 20:00:00'),\n",
      "    Timestamp('2022-05-02 04:05:00'),\n",
      "    Timestamp('2022-05-02 04:10:00'),\n",
      "    Timestamp('2022-05-02 04:15:00'),\n",
      "    Timestamp('2022-05-02 04:20:00'),\n",
      "    Timestamp('2022-05-02 04:25:00'),\n",
      "    Timestamp('2022-05-02 04:30:00'),\n",
      "    Timestamp('2022-05-02 04:35:00'),\n",
      "    Timestamp('2022-05-02 04:40:00'),\n",
      "    Timestamp('2022-05-02 04:45:00'),\n",
      "    Timestamp('2022-05-02 04:50:00'),\n",
      "    Timestamp('2022-05-02 04:55:00'),\n",
      "    Timestamp('2022-05-02 05:00:00'),\n",
      "    Timestamp('2022-05-02 05:05:00'),\n",
      "    Timestamp('2022-05-02 05:10:00'),\n",
      "    Timestamp('2022-05-02 05:15:00'),\n",
      "    Timestamp('2022-05-02 05:20:00'),\n",
      "    Timestamp('2022-05-02 05:25:00'),\n",
      "    Timestamp('2022-05-02 05:30:00'),\n",
      "    Timestamp('2022-05-02 05:35:00'),\n",
      "    Timestamp('2022-05-02 05:40:00'),\n",
      "    Timestamp('2022-05-02 05:45:00'),\n",
      "    Timestamp('2022-05-02 05:50:00'),\n",
      "    Timestamp('2022-05-02 05:55:00'),\n",
      "    Timestamp('2022-05-02 06:00:00'),\n",
      "    Timestamp('2022-05-02 06:05:00'),\n",
      "    Timestamp('2022-05-02 06:10:00'),\n",
      "    Timestamp('2022-05-02 06:15:00'),\n",
      "    Timestamp('2022-05-02 06:20:00'),\n",
      "    Timestamp('2022-05-02 06:25:00'),\n",
      "    Timestamp('2022-05-02 06:30:00'),\n",
      "    Timestamp('2022-05-02 06:35:00'),\n",
      "    Timestamp('2022-05-02 06:40:00'),\n",
      "    Timestamp('2022-05-02 06:45:00'),\n",
      "    Timestamp('2022-05-02 06:50:00'),\n",
      "    Timestamp('2022-05-02 06:55:00'),\n",
      "    Timestamp('2022-05-02 07:00:00'),\n",
      "    Timestamp('2022-05-02 07:05:00'),\n",
      "    Timestamp('2022-05-02 07:20:00'),\n",
      "    Timestamp('2022-05-02 07:30:00'),\n",
      "    Timestamp('2022-05-02 07:45:00'),\n",
      "    Timestamp('2022-05-02 08:00:00'),\n",
      "    Timestamp('2022-05-02 08:05:00'),\n",
      "    Timestamp('2022-05-02 08:30:00'),\n",
      "    Timestamp('2022-05-02 08:40:00'),\n",
      "    Timestamp('2022-05-02 08:45:00'),\n",
      "    Timestamp('2022-05-02 08:50:00'),\n",
      "    Timestamp('2022-05-02 08:55:00'),\n",
      "    Timestamp('2022-05-02 09:00:00'),\n",
      "    Timestamp('2022-05-02 09:05:00'),\n",
      "    Timestamp('2022-05-02 09:10:00'),\n",
      "    Timestamp('2022-05-02 09:25:00'),\n",
      "    Timestamp('2022-05-02 16:20:00'),\n",
      "    Timestamp('2022-05-02 16:25:00'),\n",
      "    Timestamp('2022-05-02 16:30:00'),\n",
      "    Timestamp('2022-05-02 16:45:00'),\n",
      "    Timestamp('2022-05-02 16:50:00'),\n",
      "    Timestamp('2022-05-02 17:00:00'),\n",
      "    Timestamp('2022-05-02 17:05:00'),\n",
      "    Timestamp('2022-05-02 17:15:00'),\n",
      "    Timestamp('2022-05-02 17:20:00'),\n",
      "    Timestamp('2022-05-02 17:25:00'),\n",
      "    Timestamp('2022-05-02 17:30:00'),\n",
      "    Timestamp('2022-05-02 17:35:00'),\n",
      "    Timestamp('2022-05-02 17:40:00'),\n",
      "    Timestamp('2022-05-02 17:45:00'),\n",
      "    Timestamp('2022-05-02 17:50:00'),\n",
      "    Timestamp('2022-05-02 17:55:00'),\n",
      "    Timestamp('2022-05-02 18:00:00'),\n",
      "    Timestamp('2022-05-02 18:05:00'),\n",
      "    Timestamp('2022-05-02 18:10:00'),\n",
      "    Timestamp('2022-05-02 18:15:00'),\n",
      "    Timestamp('2022-05-02 18:25:00'),\n",
      "    Timestamp('2022-05-02 18:30:00'),\n",
      "    Timestamp('2022-05-02 18:35:00'),\n",
      "    Timestamp('2022-05-02 18:40:00'),\n",
      "    Timestamp('2022-05-02 18:45:00'),\n",
      "    Timestamp('2022-05-02 18:50:00'),\n",
      "    Timestamp('2022-05-02 18:55:00'),\n",
      "    Timestamp('2022-05-02 19:00:00'),\n",
      "    Timestamp('2022-05-02 19:05:00'),\n",
      "    Timestamp('2022-05-02 19:10:00'),\n",
      "    Timestamp('2022-05-02 19:15:00'),\n",
      "    Timestamp('2022-05-02 19:20:00'),\n",
      "    Timestamp('2022-05-02 19:30:00'),\n",
      "    Timestamp('2022-05-02 19:35:00'),\n",
      "    Timestamp('2022-05-02 19:40:00'),\n",
      "    Timestamp('2022-05-02 19:45:00'),\n",
      "    Timestamp('2022-05-02 19:50:00'),\n",
      "    Timestamp('2022-05-03 04:05:00'),\n",
      "    Timestamp('2022-05-03 04:10:00'),\n",
      "    Timestamp('2022-05-03 04:15:00'),\n",
      "    Timestamp('2022-05-03 04:20:00'),\n",
      "    Timestamp('2022-05-03 04:25:00'),\n",
      "    Timestamp('2022-05-03 04:30:00'),\n",
      "    Timestamp('2022-05-03 04:35:00'),\n",
      "    Timestamp('2022-05-03 04:40:00'),\n",
      "    Timestamp('2022-05-03 04:45:00'),\n",
      "    Timestamp('2022-05-03 04:50:00'),\n",
      "    Timestamp('2022-05-03 04:55:00'),\n",
      "    Timestamp('2022-05-03 05:00:00'),\n",
      "    Timestamp('2022-05-03 05:05:00'),\n",
      "    Timestamp('2022-05-03 05:10:00'),\n",
      "    Timestamp('2022-05-03 05:15:00'),\n",
      "    Timestamp('2022-05-03 05:20:00'),\n",
      "    Timestamp('2022-05-03 05:25:00'),\n",
      "    Timestamp('2022-05-03 05:30:00'),\n",
      "    Timestamp('2022-05-03 05:35:00'),\n",
      "    Timestamp('2022-05-03 05:40:00'),\n",
      "    Timestamp('2022-05-03 05:45:00'),\n",
      "    Timestamp('2022-05-03 05:50:00'),\n",
      "    Timestamp('2022-05-03 05:55:00'),\n",
      "    Timestamp('2022-05-03 06:00:00'),\n",
      "    Timestamp('2022-05-03 06:05:00'),\n",
      "    Timestamp('2022-05-03 06:10:00'),\n",
      "    Timestamp('2022-05-03 06:15:00'),\n",
      "    Timestamp('2022-05-03 06:20:00'),\n",
      "    Timestamp('2022-05-03 06:25:00'),\n",
      "    Timestamp('2022-05-03 06:30:00'),\n",
      "    Timestamp('2022-05-03 06:35:00'),\n",
      "    Timestamp('2022-05-03 06:40:00'),\n",
      "    Timestamp('2022-05-03 06:45:00'),\n",
      "    Timestamp('2022-05-03 06:50:00'),\n",
      "    Timestamp('2022-05-03 06:55:00'),\n",
      "    Timestamp('2022-05-03 07:00:00'),\n",
      "    Timestamp('2022-05-03 07:05:00'),\n",
      "    Timestamp('2022-05-03 07:10:00'),\n",
      "    Timestamp('2022-05-03 07:15:00'),\n",
      "    Timestamp('2022-05-03 07:20:00'),\n",
      "    Timestamp('2022-05-03 07:25:00'),\n",
      "    Timestamp('2022-05-03 07:30:00'),\n",
      "    Timestamp('2022-05-03 07:35:00'),\n",
      "    Timestamp('2022-05-03 07:40:00'),\n",
      "    Timestamp('2022-05-03 07:45:00'),\n",
      "    Timestamp('2022-05-03 07:50:00'),\n",
      "    Timestamp('2022-05-03 07:55:00'),\n",
      "    Timestamp('2022-05-03 08:00:00'),\n",
      "    Timestamp('2022-05-03 08:05:00'),\n",
      "    Timestamp('2022-05-03 08:10:00'),\n",
      "    Timestamp('2022-05-03 08:15:00'),\n",
      "    Timestamp('2022-05-03 08:25:00'),\n",
      "    Timestamp('2022-05-03 08:30:00'),\n",
      "    Timestamp('2022-05-03 08:35:00'),\n",
      "    Timestamp('2022-05-03 08:40:00'),\n",
      "    Timestamp('2022-05-03 08:45:00'),\n",
      "    Timestamp('2022-05-03 08:50:00'),\n",
      "    Timestamp('2022-05-03 08:55:00'),\n",
      "    Timestamp('2022-05-03 09:00:00'),\n",
      "    Timestamp('2022-05-03 09:05:00'),\n",
      "    Timestamp('2022-05-03 09:10:00'),\n",
      "    Timestamp('2022-05-03 09:15:00'),\n",
      "    Timestamp('2022-05-03 09:20:00'),\n",
      "    Timestamp('2022-05-03 09:25:00'),\n",
      "    Timestamp('2022-05-03 16:10:00'),\n",
      "    Timestamp('2022-05-03 16:25:00'),\n",
      "    Timestamp('2022-05-03 16:35:00'),\n",
      "    Timestamp('2022-05-03 16:40:00')]\n"
     ]
    }
   ],
   "source": [
    "o,n,onn,nno = inspect_transform(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o,n,onn,nno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2022-05-03 17:05:00'),\n",
       " Timestamp('2022-05-03 17:25:00'),\n",
       " Timestamp('2022-05-03 17:45:00'),\n",
       " Timestamp('2022-05-03 18:15:00'),\n",
       " Timestamp('2022-05-03 19:30:00'),\n",
       " Timestamp('2022-05-04 07:05:00'),\n",
       " Timestamp('2022-05-04 07:10:00'),\n",
       " Timestamp('2022-05-04 07:20:00'),\n",
       " Timestamp('2022-05-04 07:50:00'),\n",
       " Timestamp('2022-05-04 08:05:00')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onn[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(set([ts.date() for ts in o]))\n",
    "dates.sort()\n",
    "#dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2022-05-04 07:05:00   2022-05-04 07:05:00\n",
       "2022-05-04 07:10:00   2022-05-04 07:10:00\n",
       "2022-05-04 07:20:00   2022-05-04 07:20:00\n",
       "2022-05-04 07:50:00   2022-05-04 07:50:00\n",
       "2022-05-04 08:05:00   2022-05-04 08:05:00\n",
       "                              ...        \n",
       "2022-05-05 18:10:00   2022-05-05 18:10:00\n",
       "2022-05-05 18:25:00   2022-05-05 18:25:00\n",
       "2022-05-05 18:50:00   2022-05-05 18:50:00\n",
       "2022-05-05 19:05:00   2022-05-05 19:05:00\n",
       "2022-05-05 19:15:00   2022-05-05 19:15:00\n",
       "Name: Date, Length: 207, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.to_series()['2022-05-04':'2022-05-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: datetime64[ns])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.to_series()['2022-05-04':'2022-05-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(files[0],index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set([ts.date() for ts in df.index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(set([ts.date() for ts in df.index]))\n",
    "dates.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = df.index.to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = s[dates[0]:dates[0]+timedelta(days=1)]\n",
    "type(day[0])\n",
    "type(day[0].time())\n",
    "start_times = []\n",
    "end_times   = []\n",
    "for d in dates:\n",
    "    day = s[d:d+timedelta(days=1)]\n",
    "    start_times.append(day[0].time())\n",
    "    end_times.append(day[-1].time())\n",
    "    \n",
    "start_times = pd.Series(start_times)\n",
    "end_times = pd.Series(end_times)\n",
    "\n",
    "print('start times:')\n",
    "print(start_times.value_counts())\n",
    "print('most common start time:',start_times.value_counts().idxmax())\n",
    "print()\n",
    "print('end times:')\n",
    "print(end_times.value_counts())\n",
    "print('most common end time:',end_times.value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "st = start_times.value_counts().idxmax()\n",
    "type(st)\n",
    "st\n",
    "print(st)\n",
    "datetime.time(9,30)\n",
    "print(datetime.time(9,30))\n",
    "datetime.time(16)\n",
    "print(datetime.time(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = pd.Series(start_times)\n",
    "st.value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.index.to_series())\n",
    "si = df.index.to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.infer_frequency(si)\n",
    "tf.infer_frequency(df)\n",
    "#tf.infer_frequency(si.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('alphavantage_demodata.json','r') as f:\n",
    "    json_string = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.loads(json_string)\n",
    "\n",
    "tsjson   = json_data['Time Series (5min)']\n",
    "metadata = json_data['Meta Data']\n",
    "\n",
    "# convert dict of dicts to list of dicts:\n",
    "dfdata = [v for v in tsjson.values()]\n",
    "\n",
    "df = pd.DataFrame(dfdata)                  # list of dicts to dataframe\n",
    "df.index = pd.DatetimeIndex(tsjson.keys()) # dict keys to dataframe index\n",
    "\n",
    "df.columns = ['Open','High','Low','Close','Volume']\n",
    "\n",
    "# convert string columns to numeric:\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col],errors='coerce')\n",
    "    \n",
    "df = df.iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = ditf.DateIlocTransform(df.index)\n",
    "print()\n",
    "print(tf._inferred_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm.count(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '../data/SP500_NOV2019_IDay.csv'\n",
    "df = pd.read_csv(fn,index_col=0,parse_dates=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsf = ditf.TimeSeriesFrequency(dfreq='B',ifreq='T',weekmask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.Timestamp('5/27/21 10')\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = ditf.DateIlocTransform.time_series_index(start=pd.Timestamp('05/27/2021 10:02'),\n",
    "                                              end='05/27/2021 20:01',\n",
    "                                              freq=tsf)#'05/27/21','06/07/21',freq=tsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ix)\n",
    "len(ix)/60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.Timestamp('09:30')\n",
    "t2 = pd.Timestamp('09:29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.time() > t2.time()\n",
    "t1.time() == t2.time()\n",
    "t1.time() < t2.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t1.time().minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSF:\n",
    "    \n",
    "    def __init__(self, topen):\n",
    "        self._topen = pd.Timestamp(topen)\n",
    "        \n",
    "    @property\n",
    "    def topen(self):\n",
    "        return self._topen\n",
    "\n",
    "#     @topen.setter\n",
    "#     def topen(self,new_topen):\n",
    "#         #print('new_topen',new_topen)\n",
    "#         self._topen = pd.Timestamp(new_topen)   \n",
    "#         print('type(self._topen)=',type(self._topen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsf = TSF('09:30')\n",
    "tsf.topen = '09:31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tsf.topen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsf.topen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ix)\n",
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = tf.infer_weekmask(df.index)\n",
    "wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsf = tf.infer_frequency(df.index)\n",
    "tsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ditransform import DateIlocTransform as DIT\n",
    "tf = DIT(df.index)\n",
    "dl = dir(tf)\n",
    "for item in dl:\n",
    "    if item[0:2] != '__':\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsf = ditf.TimeSeriesFrequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ditf.DateIlocTransform(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = t.infer_frequency(df.index)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixtemp = pd.DatetimeIndex([df.index[j] for j in range(0,len(df.index),2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = tf.infer_frequency(ixtemp)\n",
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixt = tf.time_series_index(start=df.index[0],end=df.index[-1],freq=f)\n",
    "ixt.name = 'Generated'\n",
    "s1 = df.index.to_series()\n",
    "s2 = ixt.to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = pd.DataFrame([df.index.to_series(),ixt.to_series()]).T\n",
    "len(xdf)\n",
    "select = xdf[xdf.isna().any(axis=1)]\n",
    "select\n",
    "s1[select.index]\n",
    "#s2[select.index]\n",
    "xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    abc = 12.0\n",
    "    def __init__(self):\n",
    "        self.xyz = 2.0\n",
    "        \n",
    "    @classmethod\n",
    "    def smed(cls,p):\n",
    "        print('abc=',cls.abc)\n",
    "        print('  p=',p)\n",
    "        \n",
    "    @staticmethod\n",
    "    def m1(x):\n",
    "        print('m1: x=',x)\n",
    "        \n",
    "    @staticmethod\n",
    "    def m2(y):\n",
    "        print('m2: y=',y)\n",
    "        c = MyClass\n",
    "        c.m1(y)\n",
    "        \n",
    "    @classmethod\n",
    "    def cm1(cls,x):\n",
    "        print('m1: x=',x)\n",
    "        \n",
    "    @classmethod\n",
    "    def cm2(cls,y):\n",
    "        print('m2: y=',y)\n",
    "        cls.m1(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = MyClass()\n",
    "c.xyz\n",
    "c.abc\n",
    "c.smed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.m2(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.cm2(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf.iloc[40:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(t)\n",
    "t._inferred_frequency\n",
    "t._to_date_series.head(3)\n",
    "t._to_date_series.tail(3)\n",
    "t._to_iloc_series.head(3)\n",
    "t._to_iloc_series.tail(3)\n",
    "t.to_datetime\n",
    "t.to_iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[11:15]\n",
    "for ix in np.arange(12,14,0.1):\n",
    "    d = t.to_datetime(ix)\n",
    "    print(\"%3.1f   %s   %3.1f\" % (ix,d,t.to_iloc(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.index[-4:-1]\n",
    "for ix in np.arange(90.5,93,0.1):\n",
    "    d = t.to_datetime(ix)\n",
    "    print(\"%3.1f   %s\" % (ix,d))\n",
    "    ixchk = t.to_iloc(d)\n",
    "    print(\"%3.1f   %s   %3.1f\" % (ix,d,ixchk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filelist = glob.glob('../data/*.csv')\n",
    "for fn in filelist:\n",
    "    df = pd.read_csv(fn,index_col=0,parse_dates=True)\n",
    "    f = infer_frequency(df)\n",
    "    print(f,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn ='../data/yahoofinance-INTC-19950101-20040412.csv'\n",
    "fn='../data/gbpusd_yf20210401-0407.csv'\n",
    "#fn='../data/SP500_20191106_IDayBollinger.csv'\n",
    "#fn = '../data/jpyusd_barchartdotcom.csv'\n",
    "df = pd.read_csv(fn,index_col=0,parse_dates=True)\n",
    "infer_frequency(df[::-1],trace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdict = {'Open'  :'first',\n",
    "           'High'  :'max',\n",
    "           'Low'   :'min',\n",
    "           'Close' :'last',\n",
    "           'Volume':'sum'\n",
    "          }\n",
    "fn ='../data/yahoofinance-INTC-19950101-20040412.csv'\n",
    "df = pd.read_csv(fn,index_col=0,parse_dates=True)\n",
    "\n",
    "\n",
    "for rs in ['1D','2D','3D','4D','5D','6D','7D','8D','9D','1W','2W','1M','2M','3M','4M','1Q','1Y']:\n",
    "    f = infer_frequency(df.resample(rs).agg(aggdict))\n",
    "    print('rs=',rs,'  f=',f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filelist = glob.glob('../data/*.csv')\n",
    "count = 0\n",
    "import sys\n",
    "for fn in filelist:\n",
    "    df = pd.read_csv(fn,index_col=0,parse_dates=True)\n",
    "    f  = infer_frequency(df)\n",
    "    ix = time_series_index(start=df.index[0],end=df.index[-1],freq=f)\n",
    "    print(ix[[0,1,2,-3,-2,1]])\n",
    "    \n",
    "    so = df.index.to_series(name='Original')\n",
    "    sg = ix.to_series(name='Generated')\n",
    "    comp = pd.merge(so,sg,left_index=True,right_index=True,how='outer')\n",
    "    comp.to_csv('comp.csv')\n",
    "    #print('comp[comp.isnull()]=')\n",
    "    #isn = comp[comp.isnull()]\n",
    "    print(comp.head(18))\n",
    "    print(comp.tail(18))\n",
    "    try:\n",
    "        sd = ix == df.index\n",
    "        sd = pd.Series(sd)\n",
    "        print(sd.value_counts())\n",
    "    except:\n",
    "        e = sys.exc_info()[1]\n",
    "        print(type(e),'('+str(e)+')')\n",
    "        print('generated=',len(ix),' original=',len(df.index))\n",
    "        print('original df.index range:',df.index[0],df.index[-1])        \n",
    "    print(f,fn,'\\n')\n",
    "    count += 1\n",
    "    if count > 0:\n",
    "        print('break')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkdf = pd.DataFrame(dict(date=ix,dayofweek=[d.dayofweek for d in ix]))\n",
    "wkdf.head(4)\n",
    "\n",
    "weekdays = wkdf.groupby('dayofweek').count()\n",
    "weekdays\n",
    "weekdays.iloc[:,0].mean()\n",
    "weekdays.iloc[:,0].max()\n",
    "\n",
    "len(weekdays)\n",
    "\n",
    "cut = weekdays.max()[0] - 10\n",
    "len(weekdays[ weekdays['date'] > cut])\n",
    "\n",
    "cut = weekdays.max()[0] / 2\n",
    "len(weekdays[ weekdays['date'] > cut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '5/1/2021'\n",
    "end = '5/31/2021'\n",
    "#pd.bdate_range(start=start,end=end,freq=bday_freq,weekmask=weekmask)\n",
    "mask=[0,1,2,3,4]\n",
    "\n",
    "weekmask = [day in mask for day in range(7)]\n",
    "weekmask\n",
    "ix1 = pd.bdate_range(start=start,end=end,freq='C',weekmask=weekmask)\n",
    "\n",
    "weekmask='Mon Tue Wed Thu Fri'\n",
    "ix2 = pd.bdate_range(start=start,end=end,freq='C',weekmask=weekmask)\n",
    "\n",
    "all(ix1 == ix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def _lsq_linear(self,dtseries):\n",
    "#         '''\n",
    "#         Calculate `y = mx + b` linear relationship between `date` and\n",
    "#         `iloc` in `dtseries`.  Return slope (m) and y_intercept (b).\n",
    "#         This closed-form linear least squares algorithm was taken from\n",
    "#         https://mmas.github.io/least-squares-fitting-numpy-scipy\n",
    "#         '''\n",
    "#         si = dtseries\n",
    "#         s  = si.dropna() \n",
    "#         if len(s) < 2:\n",
    "#             err = 'NOT enough data for Least Squares'\n",
    "#             if (len(si) > 2):\n",
    "#                 err += ', due to presence of NaNs'\n",
    "#             raise ValueError(err)\n",
    "#         xs = mdates.date2num(s.index.to_pydatetime())\n",
    "#         ys = [y for y in range(len(xs))]\n",
    "#         a  = np.vstack([xs, np.ones(len(xs))]).T\n",
    "#         m, b  = np.dot(np.linalg.inv(np.dot(a.T,a)), np.dot(a.T,ys))\n",
    "#         #x1, x2 = xs[0], xs[-1]\n",
    "#         #y1 = m*x1 + b\n",
    "#         #y2 = m*x2 + b\n",
    "#         #x1, x2 = mdates.num2date(x1), mdates.num2date(x2)\n",
    "#         #return ((x1,y1),(x2,y2))\n",
    "#         return m, b\n",
    "    \n",
    "#     def _ep_linear(self,dtseries):\n",
    "#         d1 = _date_to_mdate(dtseries.index[0])\n",
    "#         d2 = _date_to_mdate(dtseries.index[-1])\n",
    "\n",
    "#         i1 = 0.0\n",
    "#         i2 = len(dtseries) - 1.0\n",
    "\n",
    "#         slope   = (i2 - i1) / (d2 - d1)\n",
    "#         yitrcpt1 = i1 - (slope*d1)\n",
    "#         yitrcpt2 = i2 - (slope*d2)\n",
    "#         if yitrcpt1 != yitrcpt2:\n",
    "#             print('WARNING: yintercepts NOT equal!!!(',yitrcpt1,yitrcpt2,')')\n",
    "#             yitrcpt = (yitrcpt1 + yitrcpt2) / 2.0\n",
    "#         else:\n",
    "#             yitrcpt = yitrcpt1 \n",
    "#         return slope, yitrcpt            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit wkday(ix)\n",
    "%timeit dofwk(ix)\n",
    "%timeit wkday(ix)\n",
    "%timeit dofwk(ix)\n",
    "\n",
    "\n",
    "%timeit dofwk(ix)\n",
    "%timeit wkday(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)\n",
    "len(ix)\n",
    "all(df.index == ix)\n",
    "sd = pd.Series(df.index == ix)\n",
    "sd.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[388:393]\n",
    "ix[388:393]\n",
    "df.iloc[779:784]\n",
    "ix[779:784]\n",
    "df.iloc[-4:]\n",
    "ix[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Some experiments with Pandas inferred frequency:\n",
    "#### As soon as a Holiday date is missing, Pandas inferred frequency fails<br> (only allows regular non-business days, but not holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/yahoofinance-SPY-20200901-20210113.csv',index_col=0,parse_dates=True)\n",
    "df = pd.read_csv('../data/SP500_NOV2019_Hist.csv',index_col=0,parse_dates=True)\n",
    "df.index\n",
    "len(df)\n",
    "df.index[6:18].inferred_freq\n",
    "df.index[6:18]\n",
    "df.index[0:20].inferred_freq\n",
    "df.index[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "bday_us = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "\n",
    "dtixBH = pd.bdate_range('11/1/2019','11/30/2019',freq=bday_us)\n",
    "#dtixBH\n",
    "\n",
    "dtixB  = pd.bdate_range('11/1/2019','11/30/2019',freq='B')\n",
    "#dtixB\n",
    "\n",
    "dtixD  = pd.bdate_range('11/1/2019','11/30/2019',freq='D')\n",
    "#dtixD\n",
    "\n",
    "#is1 = dtixB.intersection(dtixBH)\n",
    "#is2 = dtixBH.intersection(dtixB)\n",
    "#is1\n",
    "#is1 == is2\n",
    "len(dtixBH)\n",
    "len(dtixB)\n",
    "len(dtixD)\n",
    "\n",
    "\n",
    "#dtixBH.to_series()[is1] == dtixBH.to_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sBH = dtixBH.to_series(name='BH')\n",
    "sB  = dtixB.to_series(name='B')\n",
    "sD  = dtixD.to_series(name='D')\n",
    "\n",
    "df  = pd.merge(sB,sBH,left_index=True,right_index=True,how='outer')\n",
    "df  = pd.merge(df,sD,left_index=True,right_index=True,how='outer')\n",
    "\n",
    "df\n",
    "len(sB)\n",
    "len(sBH)\n",
    "len(sD)\n",
    "len(df)\n",
    "for col in df.columns:\n",
    "    print('===',col,'===')\n",
    "    pd.value_counts([ isinstance(d,pd.Timestamp) for d in df[col] ])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts([ isinstance(d,pd.Timestamp) for d in df['BH'] ])\n",
    "pd.value_counts([ isinstance(d,pd.Timestamp) for d in df['B'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtix  = pd.bdate_range('11/1/2019','11/3/2019',freq='T')\n",
    "dtix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "data = [25. + random.random()*25. for j in range(len(dtix))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(data,index=dtix)\n",
    "s\n",
    "#s.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = s.resample('15T').ohlc()\n",
    "sr\n",
    "#sr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [d.weekday() for d in pd.Series([d.date() for d in sr.index]).unique()]\n",
    "# [d.weekday() for d in pd.Series([d.date() for d in sBH.index]).unique()]\n",
    "\n",
    "[d.strftime('%a') for d in pd.Series([d.date() for d in sr.index]).unique()]\n",
    "days = [d.strftime('%a') for d in pd.Series([d.date() for d in sBH.index]).unique()]\n",
    "#days\n",
    "import calendar\n",
    "print(list(calendar.day_abbr))\n",
    "for day in calendar.day_abbr:\n",
    "    print(day,day in days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[d.strftime('%a') for d in pd.Series([d.date() for d in sr.index]).unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(sr.index.values)\n",
    "ix = pd.Index(a)\n",
    "print('ix.inferred_freq=',str(ix.inferred_freq))\n",
    "del a[100]\n",
    "ix = pd.Index(a)\n",
    "print('ix.inferred_freq=',str(ix.inferred_freq))\n",
    "\n",
    "print('ix[0:99].inferred_freq=',str(ix[0:99].inferred_freq))\n",
    "\n",
    "print('ix[99:].inferred_freq=',str(ix[99:].inferred_freq))\n",
    "\n",
    "print('ix[100:].inferred_freq=',str(ix[100:].inferred_freq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix.inferred_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "list(calendar.day_name)\n",
    "list(calendar.day_abbr)\n",
    "print(calendar.calendar(2021))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('===  infer_frequency(df.head(4))  ===')\n",
    "infer_frequency(df.head(4))\n",
    "print('===  infer_frequency(df.head(6).tail(2))  ===')\n",
    "infer_frequency(df.head(6).tail(2))\n",
    "print('===  infer_frequency(df.head(3))  ===')\n",
    "infer_frequency(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design:\n",
    "\n",
    "- It now seems to me, that if we can identify one of the common patterns (listed below) then we can generate datetimes with that pattern to provide a ***more accurate extrapolation*** outside of the range of datetime data provided.\n",
    "  - if we cannot identify a pattern ***then*** we should fall back on linear extrapolation\n",
    "- The common patterns that we will attempt to find are:\n",
    "  - intraday, **one date**, with a regular frequency (hour, minutes, etc.)\n",
    "  - intraday, **multiple dates**, with a regular frequency (hour, minutes, etc.), ***and*** possibly skipping over weekends.\n",
    "    - For both of the above **intraday** case (especially the multiple date case) trading only between Open and Close times.\n",
    "  - daily, 5-day trading week, Mon-Fri\n",
    "  - daily, 5-day trading week, Sun-Thu\n",
    "  - daily, 6-day trading week ??\n",
    "  - weekly  (every Monday, or every Friday)\n",
    "  - Monthly (1st of month or last of month)\n",
    "  - Quaterly (1st of quarter or last of quarter)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Experiments\n",
    "\n",
    "- extrapolation: least squares versus end-to-end linear\n",
    "  - intraday 1m, 15m, 1h, 3h\n",
    "  - daily M-F\n",
    "  - weekly\n",
    "  \n",
    "- extrapolation: known frequency formula\n",
    "  - intraday 1m, 15m, 1h, 3h\n",
    "  - daily M-F\n",
    "  - weekly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls -l ../data/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = ['../data/SP500_NOV2019_Hist.csv',\n",
    "         '../data/SP500_NOV2019_IDayRVol.csv',\n",
    "         '../data/SPY_20110701_20120630_Bollinger.csv',\n",
    "         '../data/yahoofinance-GOOG-20040819-20180120.csv',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with diff value counts in search of a good frequency-inference algorithm\n",
    "\n",
    "- Given a series S, then the following give identical results:\n",
    "  - `diff = (S.shift(-1) - S).shift(1)`\n",
    "  - `diff = S.diff(1)`\n",
    "- The following also give identical results, with each other:\n",
    "  - `diff = S.diff(-1)`\n",
    "  - `diff = (S.shift(1) - S).shift(-1)`\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for file in INPUT:\n",
    "    data = pd.read_csv(file,index_col=0,parse_dates=True)\n",
    "    data.iloc[[0,1,-1],:].style.set_caption(str(data.shape)+' '+file)\n",
    "    dts  = data.index.to_series()\n",
    "    diff = dts.diff(1)\n",
    "    diff.value_counts()\n",
    "    diff.value_counts().idxmax()\n",
    "    diff.value_counts().index[0]\n",
    "    diff.value_counts().idxmax() == diff.value_counts().index[0]\n",
    "    type(diff.value_counts())\n",
    "    diff.value_counts().index\n",
    "    min(diff.value_counts().index)\n",
    "    min(diff.value_counts().index) == diff.value_counts().idxmax()\n",
    "    type(diff.value_counts().index[0])\n",
    "    td = diff.value_counts().keys()[0]\n",
    "    td.days,td.seconds,td.microseconds,td.nanoseconds\n",
    "    type(td.days),type(td.seconds),type(td.microseconds),type(td.nanoseconds)\n",
    "    #for jj in range(9,0,-1):\n",
    "    #    q = round(0.1*jj,1)\n",
    "    #    print('diff.quantile('+str(q)+')=',diff.quantile(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doff = pd.offsets.DateOffset(minutes=1)\n",
    "doff\n",
    "doff.freqstr\n",
    "#dir(doff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.dates as mdates\n",
    "from mplfinance._utils import _date_to_mdate\n",
    "    \n",
    "class DateIlocTransform:\n",
    "    '''Create a transform object that can transform from a date to a DatetimeIndex location, and vis versa.\n",
    "    Requires a Pandas DatetimeIndex upon creation\n",
    "    If `date` does not exactly match a date in the series then interpolate between two dates.\n",
    "    If `date` is outside the range of dates in the series, then extrapolate.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,dtindex):\n",
    "        if not isinstance(dtindex,pd.DatetimeIndex):\n",
    "            raise TypeError('Need `pandas.DatetimeIndex`, but got \"'+str(type(dtindex))+'\"')\n",
    "        if not len(dtindex) > 1:\n",
    "            raise ValueError('`dtindex` must have length of at least 2.')\n",
    "        ixlist = np.linspace(0,len(dtindex),len(dtindex)+1)[0:-1]\n",
    "        self._to_iloc_series = pd.Series(ixlist,index=dtindex)\n",
    "        self._to_date_series = pd.Series(dtindex.values,index=ixlist)\n",
    "        dtseries = dtindex.to_series()\n",
    "        self._lsslope, self._lsyicpt = self._lsq_linear(dtseries)\n",
    "        self._epslope, self._epyicpt = self._ep_linear(dtseries)\n",
    "        \n",
    "\n",
    "    def _lsq_linear(self,dtseries):\n",
    "        '''\n",
    "        Calculate `y = mx + b` linear relationship between `date` and\n",
    "        `iloc` in `dtseries`.  Return slope (m) and y_intercept (b).\n",
    "        This closed-form linear least squares algorithm was taken from\n",
    "        https://mmas.github.io/least-squares-fitting-numpy-scipy\n",
    "        '''\n",
    "        si = dtseries\n",
    "        s  = si.dropna() \n",
    "        if len(s) < 2:\n",
    "            err = 'NOT enough data for Least Squares'\n",
    "            if (len(si) > 2):\n",
    "                err += ', due to presence of NaNs'\n",
    "            raise ValueError(err)\n",
    "        xs = mdates.date2num(s.index.to_pydatetime())\n",
    "        ys = [y for y in range(len(xs))]\n",
    "        a  = np.vstack([xs, np.ones(len(xs))]).T\n",
    "        m, b  = np.dot(np.linalg.inv(np.dot(a.T,a)), np.dot(a.T,ys))\n",
    "        #x1, x2 = xs[0], xs[-1]\n",
    "        #y1 = m*x1 + b\n",
    "        #y2 = m*x2 + b\n",
    "        #x1, x2 = mdates.num2date(x1), mdates.num2date(x2)\n",
    "        #return ((x1,y1),(x2,y2))\n",
    "        return m, b\n",
    "    \n",
    "    def _ep_linear(self,dtseries):\n",
    "        d1 = _date_to_mdate(dtseries.index[0])\n",
    "        d2 = _date_to_mdate(dtseries.index[-1])\n",
    "\n",
    "        i1 = 0.0\n",
    "        i2 = len(dtseries) - 1.0\n",
    "\n",
    "        slope   = (i2 - i1) / (d2 - d1)\n",
    "        yitrcpt1 = i1 - (slope*d1)\n",
    "        yitrcpt2 = i2 - (slope*d2)\n",
    "        if yitrcpt1 != yitrcpt2:\n",
    "            print('WARNING: yintercepts NOT equal!!!(',yitrcpt1,yitrcpt2,')')\n",
    "            yitrcpt = (yitrcpt1 + yitrcpt2) / 2.0\n",
    "        else:\n",
    "            yitrcpt = yitrcpt1 \n",
    "        return slope, yitrcpt\n",
    "    \n",
    "    def to_iloc(self,date,method='ls'):\n",
    "        if method == 'ls':   # Least Squares linear\n",
    "            return self._lsslope*mdates.date2num(date) + self._lsyicpt\n",
    "        elif method == 'ep': # End Point linear\n",
    "            return self._epslope*mdates.date2num(date) + self._epyicpt\n",
    "        elif method == 'in': # INterpolate\n",
    "            #self._to_iloc_series = pd.Series(range(len(dtindex)),index=dtindex)\n",
    "            i1s = self._to_iloc_series.loc[:date]\n",
    "            i1  = i1s[-1] if len(i1s) > 0 else float('nan') # else need to extrapolate\n",
    "            i2s = self._to_iloc_series.loc[date:]\n",
    "            i2  = i2s[ 0] if len(i2s) > 0 else float('nan') # else need to extrapolate\n",
    "            #print('\\ndate,i1,i2=',date,i1,i2)\n",
    "            loc1 = i1\n",
    "            loc2 = i2\n",
    "            d1 = self._to_date_series.iloc[int(round(i1,0))]\n",
    "            d2 = self._to_date_series.iloc[int(round(i2,0))]\n",
    "            #print('date,i1,i2,d1,d2=',date,i1,i2,d1,d2)\n",
    "            loc = ((date-d1)/(d2-d1))*(loc2-loc1) + loc1 if d1 != d2 else loc1\n",
    "            #print('loc1,loc2,loc=',loc1,loc2,loc)\n",
    "            return loc\n",
    "        else:\n",
    "            raise ValueError('Bad value for `method`: ('+str(method)+') ')\n",
    "        return loc2\n",
    "    \n",
    "    def to_datetime(self,iloc,method='ls'):\n",
    "        '''\n",
    "        y = mx + b    \n",
    "        x = (y-b)/m\n",
    "        '''\n",
    "        if method == 'ls':    # Least Squares linear\n",
    "            d = (iloc - self._lsyicpt)/self._lsslope\n",
    "            return mdates.num2date(d).replace(tzinfo=None)\n",
    "        elif method == 'ep':  # End Point linear\n",
    "            d = (iloc - self._epyicpt)/self._epslope\n",
    "            return mdates.num2date(d).replace(tzinfo=None)\n",
    "        elif method == 'in': # INterpolate\n",
    "            #self._to_date_series = pd.Series(dtindex.values,index=range(len(dtindex))) \n",
    "            d1s = self._to_date_series.loc[:iloc]\n",
    "            d1  = d1s.iloc[-1] if len(d1s) > 0 else float('nan') # else should extrapolate\n",
    "            d2s = self._to_date_series.loc[iloc:]\n",
    "            d2  = d2s.iloc[ 0] if len(d2s) > 0 else float('nan') # else should extrapolate\n",
    "            if d1 == d2:\n",
    "                return d1\n",
    "            loc1 = int(round(self._to_iloc_series.loc[d1],0))\n",
    "            loc2 = int(round(self._to_iloc_series.loc[d2],0))\n",
    "            #print('\\nd1,d2=',d1.date().day,d2.date().day,\n",
    "            #      ' iloc,loc1,loc2=',iloc,loc1,loc2)\n",
    "            #print('\\nd1,d2,(d2-d1),type(d2-d1)=',d1,d2,d2-d1,type(d2-d1))\n",
    "            # d1,d2= 8 11  iloc,loc1,loc2= 5.333333333333333 5 6\n",
    "            # d1,d2,(d2-d1)= 2019-11-08 00:00:00 2019-11-11 00:00:00 3 days 00:00:00\n",
    "            # Timestamp('2019-11-08 23:59:59.999999999')\n",
    "            # d = ((iloc-loc1)/(loc2-loc1))*(d2-d1) + d1\n",
    "            d = ((iloc-loc1)*(d2-d1)) + d1\n",
    "            return d.round('s')\n",
    "        else:\n",
    "            raise ValueError('Bad value for `method`: ('+str(method)+') ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in INPUT:\n",
    "    data = pd.read_csv(file,index_col=0,parse_dates=True)\n",
    "    data.iloc[[0,1,-1],:].style.set_caption(str(data.shape)+' '+file)\n",
    "    print(infer_frequency(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggdict = {'Open'  :'first',\n",
    "           'High'  :'max',\n",
    "           'Low'   :'min',\n",
    "           'Close' :'last',\n",
    "           'Volume':'sum'\n",
    "          }\n",
    "f = infer_frequency(data.resample('1W').agg(aggdict))\n",
    "f\n",
    "pd.Timedelta(days=7)\n",
    "f == pd.Timedelta(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.resample('1M').agg(aggdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_frequency(data.resample('1M').agg(aggdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Timedelta('1Month')\n",
    "d1 = data.loc['2004-10',:]\n",
    "d2 = data.resample('1M').agg(aggdict)\n",
    "d3 = data.asfreq('1M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.iloc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are going to develop a transform similar to date_to_iloc() with the following features:\n",
    "- Able to transform both directions\n",
    "- saves the relavant input data to avoid *some* recalculation\n",
    "- implementation as a class will enable saving the input data in the transform object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/SP500_NOV2019_IDayRVol.csv',index_col=0,parse_dates=True)\n",
    "dtindex = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtseries = dtindex.to_series()\n",
    "dtseries['2019-11-08 15:50:01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtseries.describe(datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = dtseries.shift(-1) - dtseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.quantile(0.9981)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Here we experiment with finding gaps in the data, specifically for the example of *intraday* data with specific trading hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../tmp.py\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Construct dummy dataframe\n",
    "dates = pd.to_datetime([\n",
    "    '2016-08-03',\n",
    "    '2016-08-04',\n",
    "    '2016-08-05',\n",
    "    '2016-08-17',\n",
    "    '2016-09-05',\n",
    "    '2016-09-06',\n",
    "    '2016-09-07',\n",
    "    '2016-09-19'])\n",
    "df = pd.DataFrame(dates, columns=['date'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the diff of the first column (drop 1st row since it's undefined)\n",
    "deltas = df['date'].diff()[1:]\n",
    "deltas\n",
    "# Filter diffs (here days > 1, but could be seconds, hours, etc)\n",
    "gaps = deltas[deltas > timedelta(days=1)]\n",
    "gaps\n",
    "# Print results\n",
    "#print(f'{len(gaps)} gaps with average gap duration: {gaps.mean()}')\n",
    "#for i, g in gaps.iteritems():\n",
    "#    gap_start = df['date'][i - 1]\n",
    "#    print(f'Start: {datetime.strftime(gap_start, \"%Y-%m-%d\")} | '\n",
    "#          f'Duration: {str(g.to_pytimedelta())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = pd.read_csv('../data/SP500_NOV2019_IDayRVol.csv',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.iloc[[0,1,2,-2,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = idf.index.to_series().diff()[1:]\n",
    "deltas\n",
    "# Filter diffs (here days > 1, but could be seconds, hours, etc)\n",
    "deltas.value_counts()\n",
    "freq = deltas.value_counts().idxmax()\n",
    "freq\n",
    "gaps = deltas[deltas != freq]\n",
    "gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.head(3)\n",
    "idf.loc['2019-11-06'].index[-1]\n",
    "idf.loc['2019-11-07'].index[ 0]\n",
    "idf.loc['2019-11-07'].index[ 0] - idf.loc['2019-11-06'].index[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datetime index associate with the gap (i.e. with the gap duration)<br> appears to be the ***end time*** of the gap (or rather the start time of the next *non-gap*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/SP500_NOV2019_Hist.csv',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dit = DateIlocTransform(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtindex = df.index\n",
    "ixlist = np.linspace(0,len(dtindex),len(dtindex)+1)[0:-1]\n",
    "to_iloc_series = pd.Series(ixlist,index=dtindex)\n",
    "to_date_series = pd.Series(dtindex.values,index=ixlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in ['ep','ls']:\n",
    "    print('\\n=== method: \"'+method+'\"  =====')\n",
    "    for d in df.index.to_pydatetime():\n",
    "        il = dit.to_iloc(d,method=method)\n",
    "        dt = dit.to_datetime(il,method=method)\n",
    "        err = 'ERR' if d.date().day != dt.date().day else ''\n",
    "        print(\"%6.2f  %2d  %2d  %3s\" % (il,d.date().day,dt.date().day,err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "daterange = pd.date_range(start=df.index[0],end=df.index[-1],freq='D')\n",
    "#for d in df.index.to_pydatetime():\n",
    "print('len(daterange)=',len(daterange))\n",
    "for d in daterange:\n",
    "    il = dit.to_iloc(d,method='in')\n",
    "    #print('il=',il,type(il))\n",
    "    dt = dit.to_datetime(il,method='in')\n",
    "    err = 'ERR' if d.date().day != dt.date().day else ''\n",
    "    print(\"%6.2f  %s  %2d  %2d  %3s\" % (il,d.date(),d.date().day,dt.date().day,err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = 0.333333333333333*pd.Timedelta(days=3)\n",
    "td\n",
    "td.round('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[0]\n",
    "df.index[-1] - df.index[0]\n",
    "(df.index[-1] - df.index[0]).days\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df))/(df.index[-1] - df.index[0]).days\n",
    "(len(df)-1)/(df.index[-1] - df.index[0]).days\n",
    "5/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[19]\n",
    "df.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n==== INTC ====')\n",
    "# df = pd.read_csv('../data/yahoofinance-INTC-19950101-20040412.csv',index_col=0,parse_dates=True)\n",
    "# df.iloc[[0,1,-2,-1]]\n",
    "# len(df)\n",
    "# print('\\n==== GOOG ====')\n",
    "df = pd.read_csv('../data/yahoofinance-GOOG-20040819-20180120.csv',index_col=0,parse_dates=True)\n",
    "df.iloc[[0,1,-2,-1]]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.index[-1] - df.index[0]).days\n",
    "(len(df))/(df.index[-1] - df.index[0]).days\n",
    "(len(df)-1)/(df.index[-1] - df.index[0]).days\n",
    "5/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.index[-1] - df.index[0]).days\n",
    "yrs = ((df.index[-1] - df.index[0]).days - 1) / 365.25\n",
    "hldys = yrs*3\n",
    "((5/7)*365.25 - hldys)/365.25\n",
    "print()\n",
    "4/7\n",
    "6/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df)-1)/(df.index[-1]-df.index[0]).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = df.index.to_series().diff(1)\n",
    "dvc = diff.value_counts()\n",
    "dvc[0]/dvc[1]\n",
    "dvc\n",
    "dvc.keys()\n",
    "dne1 = diff[ diff > pd.Timedelta(days=1) ]\n",
    "len(diff)\n",
    "len(dne1)\n",
    "vc = dne1.value_counts()\n",
    "vc\n",
    "vc[0]/vc[1]\n",
    "vc[0]/vc[1] > 2\n",
    "vc.idxmax().days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = pd.date_range(start='1/1/2001',periods=30,freq='D')\n",
    "dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(dr)-1)/(dr[-1] - dr[0]).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = pd.date_range(start='1/1/2001',periods=30,freq='B')\n",
    "dr\n",
    "\n",
    "bday_Israel = pd.offsets.CustomBusinessDay(weekmask='Sun Mon Tue Wed Thu')\n",
    "drI = pd.date_range(start='1/1/2001',periods=30,freq=bday_Israel)\n",
    "drI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2f = pd.offsets.CustomBusinessDay(weekmask='Mon Tue Wed Thu Fri')\n",
    "drm2f = pd.date_range(start='1/1/2001',periods=30,freq=m2f)\n",
    "drm2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(dr == drm2f)\n",
    "all(dr == drI)\n",
    "dr == drI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drt = pd.date_range(dr[0],dr[-1],freq='B')\n",
    "drt\n",
    "dr == drt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = pd.date_range('1/1/2021',periods=12,freq='BM')\n",
    "dr\n",
    "dr = pd.date_range('1/1/2021',periods=12,freq='W-FRI')\n",
    "dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dr)\n",
    "dr[-1] - dr[0]\n",
    "(len(dr)-1) == (dr[-1]-dr[0]).days/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idr = pd.date_range('1/2/2021 09:30',periods=12,freq='15T')\n",
    "idr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T15  = pd.offsets.Minute(15)\n",
    "BD   = pd.offsets.BDay()\n",
    "TH   = pd.offsets.BusinessHour(start='09:30',end='16:00')\n",
    "do15 = pd.offsets.DateOffset(minutes=15)\n",
    "do15 == T15\n",
    "T15\n",
    "BD\n",
    "TH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.bdate_range('1/1/2021','1/13/2021',freq='15min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.bdate_range('1/1/2021','1/13/2021',freq='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "bday_us = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "pd.bdate_range('1/1/2021','1/13/2021',freq=bday_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bday_me = pd.offsets.CustomBusinessDay(weekmask='Sun Mon Tue Wed Thu')\n",
    "pd.bdate_range('1/1/2021','1/13/2021',freq=bday_me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhours = pd.offsets.BusinessHour(start='09:30',end='16:00')\n",
    "pd.bdate_range('1/1/2021','1/13/2021',freq=bhours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bday_us = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "dtindex = pd.bdate_range('1/1/2021','1/13/2021',freq=bday_us)\n",
    "ixlist  = []\n",
    "for dt in dtindex:\n",
    "    d1 = dt.replace(hour=9,minute=30)\n",
    "    d2 = dt.replace(hour=16,minute=1) # make sure to include 16:00\n",
    "    # Here we must use `date_range()` instead of `bdate_range()`\n",
    "    ixlist.append(pd.date_range(d1,d2,freq='30min'))\n",
    "trading_index = ixlist[0].union_many(ixlist[1:])\n",
    "print(trading_index[range(16)])\n",
    "print('...')\n",
    "print(trading_index[range(63,77)])\n",
    "print('...')\n",
    "print(trading_index[range(-16,0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bday_us = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "dtindex = pd.bdate_range('1/1/2021','1/13/2021',freq=bday_us)\n",
    "octimes = [] # open and close times\n",
    "for dt in dtindex:\n",
    "    octimes.append(dt.replace(hour=9,minute=30))\n",
    "    octimes.append(dt.replace(hour=16,minute=0))\n",
    "\n",
    "for ts in octimes:\n",
    "    print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idr = pd.date_range('1/2/2021 09:30',periods=500,freq='15T')\n",
    "#idr\n",
    "t_hours = idr[idr.indexer_between_time(start_time='09:30',end_time='16:00')]\n",
    "t_hours[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(range(len(idr)),index=idr)\n",
    "ts.index[ts.index.indexer_between_time(start_time='09:30',end_time='16:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = pd.bdate_range('01/01/2021 09:30','01/13/2021 16:00',freq='D')\n",
    "dr\n",
    "dr = pd.bdate_range('01/01/2021 09:30','01/13/2021 16:00',freq='B')\n",
    "dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dr = pd.date_range('01/01/2021 09:30','01/13/2021 16:00',freq=BD)\n",
    "dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr[0]\n",
    "dr[0].replace(hour=16,minute=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for d in dr:\n",
    "    d2 = d.replace(hour=16,minute=1)\n",
    "    indexes.append(pd.date_range(d,d2,freq='15T'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = indexes[0]\n",
    "ix = ix.union_many(indexes[1:])\n",
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for d in ix[0:200]:\n",
    "# for d in ix[20:32]:\n",
    "#    print(d)\n",
    "ix[20:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_time = '16:00'\n",
    "close = pd.Timestamp(close_time)\n",
    "close\n",
    "close.hour\n",
    "close.minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Alias|Description|\n",
    "|---|---|\n",
    "|B    |business day frequency|\n",
    "|C    |custom business day frequency|\n",
    "|D    |calendar day frequency|\n",
    "|W    |weekly frequency|\n",
    "|M    |month end frequency|\n",
    "|SM   |semi-month end frequency (15th and end of month)|\n",
    "|BM   |business month end frequency|\n",
    "|CBM  |custom business month end frequency|\n",
    "|MS   |month start frequency|\n",
    "|SMS  |semi-month start frequency (1st and 15th)|\n",
    "|BMS  |business month start frequency|\n",
    "|CBMS  |custom business month start frequency|\n",
    "|Q     |quarter end frequency|\n",
    "|BQ    |business quarter end frequency|\n",
    "|QS    |quarter start frequency|\n",
    "|BQS   |business quarter start frequency|\n",
    "|A,Y   |year end frequency|\n",
    "|BA,BY |business year end frequency|\n",
    "|AS,YS |year start frequency|\n",
    "|BAS,BYS | business year start frequency|\n",
    "|BH    |business hour frequency|\n",
    "|H     |hourly frequency|\n",
    "|T,min |minutely frequency|\n",
    "\n",
    "|S     |secondly frequency|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='M',weekmask=None)\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='BM',weekmask=None)\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='MS',weekmask=None)\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='BMS',weekmask=None)\n",
    "\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='Q',weekmask=None)\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='BQ',weekmask=None)\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='QS',weekmask=None)\n",
    "pd.bdate_range(start='1/1/2021',end='12/31/2022',freq='BQS',weekmask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.offsets.CustomBusinessDay(calendar=USFederalHolidayCalendar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfreq = TimeSeriesFrequency(dfreq=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.calendar.holidays\n",
    "d.calendar.weekmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trading_day_range(bday_start=None,bday_end=None,bday_freq='B',\n",
    "                      open_time='09:30',close_time='16:00',iday_freq='15T',weekmask=None):\n",
    "\n",
    "    if bday_start is None: bday_start = pd.Timestamp.today()\n",
    "    if bday_end   is None: bday_end = bday_start + pd.Timedelta(days=1)\n",
    "\n",
    "    daily = []\n",
    "    for d in pd.bdate_range(start=bday_start,end=bday_end,freq=bday_freq,weekmask=weekmask):\n",
    "        topen  = pd.Timestamp(open_time)\n",
    "        d1     = d.replace(hour=topen.hour,minute=topen.minute)\n",
    "        tclose = pd.Timestamp(close_time)\n",
    "        d2     = d.replace(hour=tclose.hour,minute=tclose.minute+1)\n",
    "        daily.append(pd.date_range(d1,d2,freq=iday_freq))\n",
    "   \n",
    "    index = daily[0].union_many(daily[1:])\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = trading_day_range()\n",
    "print('len(ix)=',len(ix))\n",
    "print(ix[20:40])\n",
    "print(ix[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trading_day_range(bday_start=None,bday_end=None,day_freq='B',\n",
    "#                       open_time='09:30',close_time='16:00',trade_freq='15T',weekmask=None):\n",
    "\n",
    "#ix1 = trading_day_range('01/01/2021 09:30','01/13/2021 16:00',day_freq='B',trade_freq='30T')#,weekmask='Wed Thu')\n",
    "ix1 = trading_day_range('01/01/2021 09:30','01/13/2021 16:00',bday_freq='C',iday_freq='30T',weekmask='Wed Thu Fri')\n",
    "print('len(ix1)=',len(ix1))\n",
    "print(ix1[20:40])\n",
    "print(ix1[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix2 = pd.bdate_range('01/01/2021 09:30','01/13/2021 16:00',freq='30T')\n",
    "#ix2 = pd.bdate_range('01/01/2021 09:30','01/13/2021 16:00',freq='C',weekmask=\"Mon Tue Wed Thu Fri\")\n",
    "ix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix2 = ix2[ix2.indexer_between_time(start_time='09:30',end_time='16:00')]\n",
    "ix2[20:40]\n",
    "ix2[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(ix1)\n",
    "len(ix2)\n",
    "bdays = pd.bdate_range('01/01/2021 09:30','01/13/2021 16:00',freq='B')\n",
    "\n",
    "\n",
    "ix2list = [d for d in ix2 if pd.Timestamp(d.date()) in bdays]\n",
    "#ix2list\n",
    "ix2n = pd.DatetimeIndex(ix2list)\n",
    "len(ix2n)\n",
    "ix2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(range(10),index=['A','B','C','D','E','F','G','H','I','J'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[['A','C','F']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.DataFrame(range(10),index=pd.date_range('1/1/2021',periods=10))\n",
    "s = pd.DataFrame(range(10),index=pd.date_range('1/1/2021 09:30',periods=10,freq='12H'))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index\n",
    "type(s.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s.loc[['2021-01-01','2021-01-04'],:]\n",
    "s.loc['2021-01-01']\n",
    "#s[['2021-01-01','2021-01-04']]\n",
    "#s['2021-01-01'] + s['2021-01-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['Date'] = [d.date() for d in s.index]\n",
    "s\n",
    "\n",
    "s['Date'][0]\n",
    "type(s['Date'][0])\n",
    "\n",
    "s['Date']\n",
    "s['Date'].isin([datetime.date(2021,1,1),datetime.date(2021,1,4)])\n",
    "\n",
    "s[ s['Date'].isin([datetime.date(2021,1,1),datetime.date(2021,1,4)]) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtix = pd.DatetimeIndex([datetime.date(2021,1,1),datetime.date(2021,1,4)])\n",
    "dtix\n",
    "dtix[0]\n",
    "dtix.to_pydatetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['Date']\n",
    "s['Date'].isin([datetime.date(2021,1,1),datetime.date(2021,1,4)])\n",
    "s['Date'].isin([d.date() for d in dtix.to_pydatetime()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drbd = pd.date_range('01/01/2021 09:30','01/13/2021 16:00',freq=BD)\n",
    "# [d.date() for d in  drbd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dr = pd.date_range('01/01/2021 09:30','01/13/2021 16:00',freq='15T')\n",
    "# sd = pd.Series(range(len(dr)),index=dr)\n",
    "# sd\n",
    "# dlist = [d.date() for d in  drbd] \n",
    "# dlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm, lb = dit._lsq_linear(dtseries)\n",
    "lm, lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em, eb = dit._ep_linear(dtseries)\n",
    "em, eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jj in range(len(dtseries)):\n",
    "    date = dtseries.iloc[jj]\n",
    "    \n",
    "    ly  = lm*mdates.date2num(date) + lb\n",
    "    ily = int(np.round(ly))\n",
    "    \n",
    "    ey  = em*mdates.date2num(date) + eb\n",
    "    iey = int(np.round(ey))\n",
    "    \n",
    "    print(\"%2d  %5.2f  %2d  %5.2f %20s\" % (ily,ly,iey,ey,date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldts = [dtseries[0] + pd.DateOffset(offset) for offset in range(30)]\n",
    "new_dtseries = pd.Series(alldts,index=pd.DatetimeIndex(alldts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eerr = []\n",
    "lerr = []\n",
    "print(\"jj ily  iey   ly     ey     dt  dt(il) dt(ie)\")\n",
    "for jj in range(len(new_dtseries)-1):\n",
    "    date = new_dtseries.iloc[jj]\n",
    "    \n",
    "    ly  = lm*mdates.date2num(date) + lb\n",
    "    ily = int(np.round(ly))\n",
    "    \n",
    "    ey  = em*mdates.date2num(date) + eb\n",
    "    iey = int(np.round(ey))\n",
    "    \n",
    "    ily = 0 if (ily < 0 or ily > 19) else ily\n",
    "    iey = 0 if (iey < 0 or iey > 19) else iey\n",
    "    \n",
    "    err_l = dtseries.iloc[ily].date().day - date.date().day\n",
    "    err_e = dtseries.iloc[iey].date().day - date.date().day\n",
    "    lerr.append(abs(err_l))\n",
    "    eerr.append(abs(err_e))\n",
    "\n",
    "    print(\"%2d  %2d  %2d  %5.2f  %5.2f  %4s  %4s  %4s  %4s  %4s\" % \n",
    "          (jj,ily,iey,ly,ey,date.date().day,dtseries.iloc[ily].date().day,\n",
    "           dtseries.iloc[iey].date().day, err_l, err_e)\n",
    "         )\n",
    "\n",
    "print('\\nsum(lerr)=',sum(lerr),' sum(eerr)=',sum(eerr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lerr = []\n",
    "eerr = []\n",
    "for jj in range(len(dtseries)):\n",
    "    date = dtseries.iloc[jj]\n",
    "    \n",
    "    ly  = lm*mdates.date2num(date) + lb\n",
    "    ily = int(np.round(ly))\n",
    "    \n",
    "    ey  = em*mdates.date2num(date) + eb\n",
    "    iey = int(np.round(ey))\n",
    "    \n",
    "    err_l = dtseries.iloc[ily].date().day - date.date().day\n",
    "    err_e = dtseries.iloc[iey].date().day - date.date().day\n",
    "    \n",
    "    lerr.append(abs(err_l))\n",
    "    eerr.append(abs(err_e))\n",
    "\n",
    "    \n",
    "    print(\"%2d  %5.2f  %2d  %5.2f %6s %6s %6s %6s %6s\" % (ily,ly,iey,ey,date.date().day,\n",
    "                                                  dtseries.iloc[ily].date().day,\n",
    "                                                  dtseries.iloc[iey].date().day,\n",
    "                                                  err_l, err_e))\n",
    "    \n",
    "print('\\nsum(lerr)=',sum(lerr),' sum(eerr)=',sum(eerr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
